{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"0205_BaseModel_large_45.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b8a48c4ca3c42238208a79708522410":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb694fb8e94e47c1a99eaa5e7850767e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_31d98f2b7f7c4feeabc23c0d7110a137","IPY_MODEL_ee133f6e974d402bbf66eedb9077eaea"]}},"bb694fb8e94e47c1a99eaa5e7850767e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31d98f2b7f7c4feeabc23c0d7110a137":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_af1bcaef51e04384863aaae86f6547c8","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":362,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":362,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c45ca9bd5d1048e3821a2a27bffa97aa"}},"ee133f6e974d402bbf66eedb9077eaea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee4f3ac5d55a4cffabdd91c472056528","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 362/362 [00:00&lt;00:00, 14.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84865b79fb1c43a0b4f7e2b3d403824e"}},"af1bcaef51e04384863aaae86f6547c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c45ca9bd5d1048e3821a2a27bffa97aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee4f3ac5d55a4cffabdd91c472056528":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84865b79fb1c43a0b4f7e2b3d403824e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4762ace7c5394d47a2e5a8a4d12303c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bd5d598816bb4163badbdf889c14ee28","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_315ac8f6d15d4b9dac1232e3204a9a2e","IPY_MODEL_cb5afc5b894a46adab88706a651a0308"]}},"bd5d598816bb4163badbdf889c14ee28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"315ac8f6d15d4b9dac1232e3204a9a2e":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_53633d28d18f4e03bafc6c3351095d89","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":1344997306,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1344997306,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b3bbba94be724ec2a2d80a91b7a5c5f6"}},"cb5afc5b894a46adab88706a651a0308":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab4f4f1ad8cc4c9f81251632ce97da4c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 1.34G/1.34G [00:51&lt;00:00, 26.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fce2cc520eb1407cbde4b6ca6c030838"}},"53633d28d18f4e03bafc6c3351095d89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b3bbba94be724ec2a2d80a91b7a5c5f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab4f4f1ad8cc4c9f81251632ce97da4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fce2cc520eb1407cbde4b6ca6c030838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a98013781f704ea5af8083c013f18f28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_553ecc4e21cf48b0b616028559420834","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cff8865ad4d4de3b553261a3730e1bb","IPY_MODEL_afb53619b8264dc6926938fe7b68d655"]}},"553ecc4e21cf48b0b616028559420834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cff8865ad4d4de3b553261a3730e1bb":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_01d7b9fbb08048bd9c2731acd73278be","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87ce5768af6c4a55b8d41128f10597a3"}},"afb53619b8264dc6926938fe7b68d655":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e999fab94fca47eca65335d940cee67d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 232k/232k [00:00&lt;00:00, 867kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e035f28a3d1244b0bf9b496b37c23f18"}},"01d7b9fbb08048bd9c2731acd73278be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"87ce5768af6c4a55b8d41128f10597a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e999fab94fca47eca65335d940cee67d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e035f28a3d1244b0bf9b496b37c23f18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"6T6HUtB5eorj","outputId":"b12731d4-a674-4739-f09f-a3e7a54e3b0e","executionInfo":{"status":"ok","timestamp":1581029054942,"user_tz":-540,"elapsed":30032,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fhYQVdgEwuRZ"},"source":["## やったこと\n","\n","- テキストのクリーニング処理 -> 改善\n","- host, categoryのカテゴリカル変数をエンベディングして入力 -> 改善\n","\n","- epochs=20で、early-stoppingはあまり良くならなかった -> とりあえず速く数を回したいので、epochs=4でやっている\n","\n","\n","- batch_size=8以上にすると、out_of_memoryになる\n","\n","- MSELossを使用 -> 悪化\n","- titleは分けて、別のエンベディングとして入力 -> 悪化\n","\n","\n","\n","- BERTを2つ使う -> gpu不足\n","- クラス分類問題にする（30*num_class） -> 学習が安定しない（nan）\n","- 30個の目的変数それぞれ独立に予測するモデル -> 約30時間必要、あまり精度が出ないように見える -> 関連する目的変数だけをグルーピングしてモデルを分ける必要？"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uvK9IDYaOP_b","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import os, sys, gc, random, multiprocessing, glob, time\n","\n","DATA_DIR = '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/google-quest-challenge'\n","# DATA_DIR = '../input/google-quest-challenge'\n","# DATA_DIR = 'D:/project/ICF_AutoCapsule_disabled/kaggle/google-quest-challenge'\n","# BERT_DIR = 'D:/project/ICF_AutoCapsule_disabled/BERT'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"S4jYDD13OP_o","colab":{}},"source":["# !pip install ../input/sacremoses/sacremoses-master/\n","# !pip install ../input/transformers/transformers-master/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xst4_Y1Xer4Y","outputId":"ef48870e-8edd-4921-d258-bdded4824e24","executionInfo":{"status":"ok","timestamp":1581029066545,"user_tz":-540,"elapsed":41536,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":852}},"source":["!pip install transformers\n","!pip install flashtext"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n","\r\u001b[K     |▊                               | 10kB 30.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 9.4MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 65.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Collecting tokenizers==0.0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 61.8MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 65.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=68e2d337579d7609eef3299c8cc5c7f89975b0af02df99ee96f98bbf2b6ca8eb\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n","Collecting flashtext\n","  Downloading https://files.pythonhosted.org/packages/81/d8/2cd0656eae456d615c2f1efbcae8dfca2cb871a31f34ba8925aba47d5e09/flashtext-2.7.tar.gz\n","Building wheels for collected packages: flashtext\n","  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9299 sha256=7f5aaa16411db2a667195fc9fd8aaa9ad7b170c80c738800ebb0be856060b13f\n","  Stored in directory: /root/.cache/pip/wheels/37/db/d7/fe74f7cb8e5c3afed90fe6f4967c933a6f13d81ab6b3d3128c\n","Successfully built flashtext\n","Installing collected packages: flashtext\n","Successfully installed flashtext-2.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OW9r1DNjOP_z","outputId":"2107c4fb-fff5-4220-f30f-48d367446663","executionInfo":{"status":"ok","timestamp":1581029071526,"user_tz":-540,"elapsed":46479,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":98}},"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils import data\n","from torch.utils.data import DataLoader, Dataset\n","\n","#from ml_stratifiers import MultilabelStratifiedShuffleSplit, MultilabelStratifiedKFold\n","from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n","from sklearn.utils import shuffle\n","from sklearn.preprocessing import LabelEncoder\n","\n","from scipy.stats import spearmanr\n","\n","import transformers\n","from transformers import (\n","    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n","    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n","    get_cosine_schedule_with_warmup,\n",")\n","\n","from tqdm import tqdm\n","print(transformers.__version__)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gQsu1MpOOQAA","colab":{}},"source":["## Make results reproducible .Else noone will believe you .\n","import random\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kegkamk4OQAO","colab":{}},"source":["class PipeLineConfig:\n","    def __init__(self, lr, warmup, epochs, patience, batch_size, seed, name, question_weight,answer_weight,fold,train):\n","        self.lr = lr\n","        self.warmup = warmup\n","        self.epochs = epochs\n","        self.patience = patience\n","        self.batch_size = batch_size\n","        self.seed = seed\n","        self.name = name\n","        self.question_weight = question_weight\n","        self.answer_weight =answer_weight\n","        self.fold = fold\n","        self.train = train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IBzmdbwYOQAY","colab":{}},"source":["config = PipeLineConfig(lr=1e-5, \\\n","                        warmup=0.01, \\\n","                        epochs=4, \\\n","                        patience=3, \\\n","                        batch_size=2, \\\n","                        seed=42, \\\n","                        name='reModel', \\\n","                        question_weight=0.5, \\\n","                        answer_weight=0.5, \\\n","                        fold=5, \\\n","                        train=True\n","                       )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nBjN2cdKOQAh","colab":{}},"source":["seed_everything(config.seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DjOYABYwOQAr","outputId":"6935a0aa-b51a-4f3f-f901-10049c955f57","executionInfo":{"status":"ok","timestamp":1581029071542,"user_tz":-540,"elapsed":46359,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","#device = 'cpu'\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RrECgPr6OQA4","outputId":"15984ad9-a616-4211-de24-324e583135f5","executionInfo":{"status":"ok","timestamp":1581029073896,"user_tz":-540,"elapsed":48676,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n","sub.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qa_id</th>\n","      <th>question_asker_intent_understanding</th>\n","      <th>question_body_critical</th>\n","      <th>question_conversational</th>\n","      <th>question_expect_short_answer</th>\n","      <th>question_fact_seeking</th>\n","      <th>question_has_commonly_accepted_answer</th>\n","      <th>question_interestingness_others</th>\n","      <th>question_interestingness_self</th>\n","      <th>question_multi_intent</th>\n","      <th>question_not_really_a_question</th>\n","      <th>question_opinion_seeking</th>\n","      <th>question_type_choice</th>\n","      <th>question_type_compare</th>\n","      <th>question_type_consequence</th>\n","      <th>question_type_definition</th>\n","      <th>question_type_entity</th>\n","      <th>question_type_instructions</th>\n","      <th>question_type_procedure</th>\n","      <th>question_type_reason_explanation</th>\n","      <th>question_type_spelling</th>\n","      <th>question_well_written</th>\n","      <th>answer_helpful</th>\n","      <th>answer_level_of_information</th>\n","      <th>answer_plausible</th>\n","      <th>answer_relevance</th>\n","      <th>answer_satisfaction</th>\n","      <th>answer_type_instructions</th>\n","      <th>answer_type_procedure</th>\n","      <th>answer_type_reason_explanation</th>\n","      <th>answer_well_written</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","      <td>0.00308</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>46</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","      <td>0.00448</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","      <td>0.00673</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>132</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","      <td>0.01401</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>200</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","      <td>0.02074</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   qa_id  ...  answer_well_written\n","0     39  ...              0.00308\n","1     46  ...              0.00448\n","2     70  ...              0.00673\n","3    132  ...              0.01401\n","4    200  ...              0.02074\n","\n","[5 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FUZFPsyDOQBB","outputId":"a72af638-cc64-4772-9d4c-b56a224340c6","scrolled":true,"executionInfo":{"status":"ok","timestamp":1581029073898,"user_tz":-540,"elapsed":48613,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":549}},"source":["target_columns = sub.columns.values[1:].tolist()\n","target_columns"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['question_asker_intent_understanding',\n"," 'question_body_critical',\n"," 'question_conversational',\n"," 'question_expect_short_answer',\n"," 'question_fact_seeking',\n"," 'question_has_commonly_accepted_answer',\n"," 'question_interestingness_others',\n"," 'question_interestingness_self',\n"," 'question_multi_intent',\n"," 'question_not_really_a_question',\n"," 'question_opinion_seeking',\n"," 'question_type_choice',\n"," 'question_type_compare',\n"," 'question_type_consequence',\n"," 'question_type_definition',\n"," 'question_type_entity',\n"," 'question_type_instructions',\n"," 'question_type_procedure',\n"," 'question_type_reason_explanation',\n"," 'question_type_spelling',\n"," 'question_well_written',\n"," 'answer_helpful',\n"," 'answer_level_of_information',\n"," 'answer_plausible',\n"," 'answer_relevance',\n"," 'answer_satisfaction',\n"," 'answer_type_instructions',\n"," 'answer_type_procedure',\n"," 'answer_type_reason_explanation',\n"," 'answer_well_written']"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BOiPYRDWOQBM","outputId":"7cdfae22-5a66-4468-e39a-70da23e56ae8","executionInfo":{"status":"ok","timestamp":1581029074584,"user_tz":-540,"elapsed":49224,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":610}},"source":["train = pd.read_csv(f'{DATA_DIR}/train.csv')\n","train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qa_id</th>\n","      <th>question_title</th>\n","      <th>question_body</th>\n","      <th>question_user_name</th>\n","      <th>question_user_page</th>\n","      <th>answer</th>\n","      <th>answer_user_name</th>\n","      <th>answer_user_page</th>\n","      <th>url</th>\n","      <th>category</th>\n","      <th>host</th>\n","      <th>question_asker_intent_understanding</th>\n","      <th>question_body_critical</th>\n","      <th>question_conversational</th>\n","      <th>question_expect_short_answer</th>\n","      <th>question_fact_seeking</th>\n","      <th>question_has_commonly_accepted_answer</th>\n","      <th>question_interestingness_others</th>\n","      <th>question_interestingness_self</th>\n","      <th>question_multi_intent</th>\n","      <th>question_not_really_a_question</th>\n","      <th>question_opinion_seeking</th>\n","      <th>question_type_choice</th>\n","      <th>question_type_compare</th>\n","      <th>question_type_consequence</th>\n","      <th>question_type_definition</th>\n","      <th>question_type_entity</th>\n","      <th>question_type_instructions</th>\n","      <th>question_type_procedure</th>\n","      <th>question_type_reason_explanation</th>\n","      <th>question_type_spelling</th>\n","      <th>question_well_written</th>\n","      <th>answer_helpful</th>\n","      <th>answer_level_of_information</th>\n","      <th>answer_plausible</th>\n","      <th>answer_relevance</th>\n","      <th>answer_satisfaction</th>\n","      <th>answer_type_instructions</th>\n","      <th>answer_type_procedure</th>\n","      <th>answer_type_reason_explanation</th>\n","      <th>answer_well_written</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>What am I losing when using extension tubes in...</td>\n","      <td>After playing around with macro photography on...</td>\n","      <td>ysap</td>\n","      <td>https://photo.stackexchange.com/users/1024</td>\n","      <td>I just got extension tubes, so here's the skin...</td>\n","      <td>rfusca</td>\n","      <td>https://photo.stackexchange.com/users/1917</td>\n","      <td>http://photo.stackexchange.com/questions/9169/...</td>\n","      <td>LIFE_ARTS</td>\n","      <td>photo.stackexchange.com</td>\n","      <td>1.000000</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.666667</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.800000</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>What is the distinction between a city and a s...</td>\n","      <td>I am trying to understand what kinds of places...</td>\n","      <td>russellpierce</td>\n","      <td>https://rpg.stackexchange.com/users/8774</td>\n","      <td>It might be helpful to look into the definitio...</td>\n","      <td>Erik Schmidt</td>\n","      <td>https://rpg.stackexchange.com/users/1871</td>\n","      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n","      <td>CULTURE</td>\n","      <td>rpg.stackexchange.com</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.444444</td>\n","      <td>0.444444</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.666667</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>0.0</td>\n","      <td>0.888889</td>\n","      <td>0.888889</td>\n","      <td>0.555556</td>\n","      <td>0.888889</td>\n","      <td>0.888889</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.666667</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Maximum protusion length for through-hole comp...</td>\n","      <td>I'm working on a PCB that has through-hole com...</td>\n","      <td>Joe Baker</td>\n","      <td>https://electronics.stackexchange.com/users/10157</td>\n","      <td>Do you even need grooves?  We make several pro...</td>\n","      <td>Dwayne Reid</td>\n","      <td>https://electronics.stackexchange.com/users/64754</td>\n","      <td>http://electronics.stackexchange.com/questions...</td>\n","      <td>SCIENCE</td>\n","      <td>electronics.stackexchange.com</td>\n","      <td>0.888889</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.666667</td>\n","      <td>0.444444</td>\n","      <td>0.333333</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","      <td>0.0</td>\n","      <td>0.777778</td>\n","      <td>0.777778</td>\n","      <td>0.555556</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>1.000000</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Can an affidavit be used in Beit Din?</td>\n","      <td>An affidavit, from what i understand, is basic...</td>\n","      <td>Scimonster</td>\n","      <td>https://judaism.stackexchange.com/users/5151</td>\n","      <td>Sending an \"affidavit\" it is a dispute between...</td>\n","      <td>Y     e     z</td>\n","      <td>https://judaism.stackexchange.com/users/4794</td>\n","      <td>http://judaism.stackexchange.com/questions/551...</td>\n","      <td>CULTURE</td>\n","      <td>judaism.stackexchange.com</td>\n","      <td>0.888889</td>\n","      <td>0.666667</td>\n","      <td>0.666667</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.444444</td>\n","      <td>0.444444</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.333333</td>\n","      <td>0.833333</td>\n","      <td>1.000000</td>\n","      <td>0.800000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>How do you make a binary image in Photoshop?</td>\n","      <td>I am trying to make a binary image. I want mor...</td>\n","      <td>leigero</td>\n","      <td>https://graphicdesign.stackexchange.com/users/...</td>\n","      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n","      <td>q2ra</td>\n","      <td>https://graphicdesign.stackexchange.com/users/...</td>\n","      <td>http://graphicdesign.stackexchange.com/questio...</td>\n","      <td>LIFE_ARTS</td>\n","      <td>graphicdesign.stackexchange.com</td>\n","      <td>1.000000</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.666667</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.666667</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.800000</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   qa_id  ... answer_well_written\n","0      0  ...            1.000000\n","1      1  ...            0.888889\n","2      2  ...            0.888889\n","3      3  ...            1.000000\n","4      5  ...            1.000000\n","\n","[5 rows x 41 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"khOj2PbNOQBW","outputId":"16a3eefe-24e0-494a-d8d4-23e649bb8262","executionInfo":{"status":"ok","timestamp":1581029074947,"user_tz":-540,"elapsed":49540,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":508}},"source":["test = pd.read_csv(f'{DATA_DIR}/test.csv')\n","test.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qa_id</th>\n","      <th>question_title</th>\n","      <th>question_body</th>\n","      <th>question_user_name</th>\n","      <th>question_user_page</th>\n","      <th>answer</th>\n","      <th>answer_user_name</th>\n","      <th>answer_user_page</th>\n","      <th>url</th>\n","      <th>category</th>\n","      <th>host</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>Will leaving corpses lying around upset my pri...</td>\n","      <td>I see questions/information online about how t...</td>\n","      <td>Dylan</td>\n","      <td>https://gaming.stackexchange.com/users/64471</td>\n","      <td>There is no consequence for leaving corpses an...</td>\n","      <td>Nelson868</td>\n","      <td>https://gaming.stackexchange.com/users/97324</td>\n","      <td>http://gaming.stackexchange.com/questions/1979...</td>\n","      <td>CULTURE</td>\n","      <td>gaming.stackexchange.com</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>46</td>\n","      <td>Url link to feature image in the portfolio</td>\n","      <td>I am new to Wordpress. i have issue with Featu...</td>\n","      <td>Anu</td>\n","      <td>https://wordpress.stackexchange.com/users/72927</td>\n","      <td>I think it is possible with custom fields.\\n\\n...</td>\n","      <td>Irina</td>\n","      <td>https://wordpress.stackexchange.com/users/27233</td>\n","      <td>http://wordpress.stackexchange.com/questions/1...</td>\n","      <td>TECHNOLOGY</td>\n","      <td>wordpress.stackexchange.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>Is accuracy, recoil or bullet spread affected ...</td>\n","      <td>To experiment I started a bot game, toggled in...</td>\n","      <td>Konsta</td>\n","      <td>https://gaming.stackexchange.com/users/37545</td>\n","      <td>You do not have armour in the screenshots. Thi...</td>\n","      <td>Damon Smithies</td>\n","      <td>https://gaming.stackexchange.com/users/70641</td>\n","      <td>http://gaming.stackexchange.com/questions/2154...</td>\n","      <td>CULTURE</td>\n","      <td>gaming.stackexchange.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>132</td>\n","      <td>Suddenly got an I/O error from my external HDD</td>\n","      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n","      <td>robbannn</td>\n","      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n","      <td>Your Western Digital hard drive is disappearin...</td>\n","      <td>HeatfanJohn</td>\n","      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n","      <td>http://raspberrypi.stackexchange.com/questions...</td>\n","      <td>TECHNOLOGY</td>\n","      <td>raspberrypi.stackexchange.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>200</td>\n","      <td>Passenger Name - Flight Booking Passenger only...</td>\n","      <td>I have bought Delhi-London return flights for ...</td>\n","      <td>Amit</td>\n","      <td>https://travel.stackexchange.com/users/29089</td>\n","      <td>I called two persons who work for Saudia (tick...</td>\n","      <td>Nean Der Thal</td>\n","      <td>https://travel.stackexchange.com/users/10051</td>\n","      <td>http://travel.stackexchange.com/questions/4704...</td>\n","      <td>CULTURE</td>\n","      <td>travel.stackexchange.com</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   qa_id  ...                           host\n","0     39  ...       gaming.stackexchange.com\n","1     46  ...    wordpress.stackexchange.com\n","2     70  ...       gaming.stackexchange.com\n","3    132  ...  raspberrypi.stackexchange.com\n","4    200  ...       travel.stackexchange.com\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RUQkeCkGOQBi"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kw_iafZpOQBl","colab":{}},"source":["import re\n","from flashtext import KeywordProcessor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wf7fudYqOQBu","colab":{}},"source":["PUNCTS = {\n","            '》', '〞', '¢', '‹', '╦', '║', '♪', 'Ø', '╩', '\\\\', '★', '＋', 'ï', '<', '?', '％', '+', '„', 'α', '*', '〰', '｟', '¹', '●', '〗', ']', '▾', '■', '〙', '↓', '´', '【', 'ᴵ',\n","            '\"', '）', '｀', '│', '¤', '²', '‡', '¿', '–', '」', '╔', '〾', '%', '¾', '←', '〔', '＿', '’', '-', ':', '‧', '｛', 'β', '（', '─', 'à', 'â', '､', '•', '；', '☆', '／', 'π',\n","            'é', '╗', '＾', '▪', ',', '►', '/', '〚', '¶', '♦', '™', '}', '″', '＂', '『', '▬', '±', '«', '“', '÷', '×', '^', '!', '╣', '▲', '・', '░', '′', '〝', '‛', '√', ';', '】', '▼',\n","            '.', '~', '`', '。', 'ə', '］', '，', '{', '～', '！', '†', '‘', '﹏', '═', '｣', '〕', '〜', '＼', '▒', '＄', '♥', '〛', '≤', '∞', '_', '[', '＆', '→', '»', '－', '＝', '§', '⋅', \n","            '▓', '&', 'Â', '＞', '〃', '|', '¦', '—', '╚', '〖', '―', '¸', '³', '®', '｠', '¨', '‟', '＊', '£', '#', 'Ã', \"'\", '▀', '·', '？', '、', '█', '”', '＃', '⊕', '=', '〟', '½', '』',\n","            '［', '$', ')', 'θ', '@', '›', '＠', '｝', '¬', '…', '¼', '：', '¥', '❤', '€', '−', '＜', '(', '〘', '▄', '＇', '>', '₤', '₹', '∅', 'è', '〿', '「', '©', '｢', '∙', '°', '｜', '¡', \n","            '↑', 'º', '¯', '♫', '#'\n","          }\n","\n","\n","mispell_dict = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\",\n","\"couldnt\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n","\"doesnt\" : \"does not\", \"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\",\n","\"haven't\" : \"have not\", \"havent\" : \"have not\", \"he'd\" : \"he would\", \"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"I would\",\n","\"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\", \"isn't\" : \"is not\", \"it's\" : \"it is\",\n","\"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \n","\"shan't\" : \"shall not\", \"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"shouldnt\" : \"should not\",\n","\"that's\" : \"that is\", \"thats\" : \"that is\", \"there's\" : \"there is\", \"theres\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\",\n","\"they're\" : \"they are\", \"theyre\":  \"they are\", \"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\",\n","\"we've\" : \"we have\", \"what'll\" : \"what will\", \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\", \"where's\" : \"where is\",\n","\"who'd\" : \"who would\", \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\", \"won't\" : \"will not\", \"wouldn't\" : \"would not\", \"you'd\" : \"you would\",\n","\"you'll\" : \"you will\", \"you're\" : \"you are\", \"you've\" : \"you have\", \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\", \"tryin'\":\"trying\"}\n","\n","\n","kp = KeywordProcessor(case_sensitive=True)\n","for k, v in mispell_dict.items():\n","    kp.add_keyword(k, v)\n","\n","def clean_punct(text):\n","    text = str(text)\n","    for punct in PUNCTS:\n","        text = text.replace(punct, ' {} '.format(punct))\n","    return text\n","\n","\n","def preprocessing(text):\n","    text = text.lower()\n","    text = re.sub(r'(\\&lt)|(\\&gt)', ' ', text)\n","    \n","    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' url ', text)\n","    text = kp.replace_keywords(text)\n","    text = clean_punct(text)\n","    text = re.sub(r'\\n\\r', ' ', text)\n","    text = re.sub(r'\\s{2,}', ' ', text)\n","    \n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VLL4EgrdOQCV"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uIq3tUBmjATF","colab":{}},"source":["MAX_LEN = 400\n","\n","class QuestDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, train_mode=True, labeled=True):\n","        self.df = df\n","        self.train_mode = train_mode\n","        self.labeled = labeled\n","        #self.tokenizer = BertTokenizer.from_pretrained(BERT_DIR+'/bert-base-uncased')\n","        #self.tokenizer = BertTokenizer.from_pretrained('../input/bert-base-uncased/')\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","\n","        question_title = row.question_title\n","        question_body = row.question_body\n","        answer_text = row.answer\n","\n","\n","        inputs_q = self.tokenizer.encode_plus(\n","            question_title + \" \" + question_body,\n","            add_special_tokens=True,\n","            max_length=MAX_LEN,\n","        )\n","\n","        inputs_a = self.tokenizer.encode_plus(\n","            answer_text,\n","            add_special_tokens=True,\n","            max_length=MAX_LEN,\n","        )\n","\n","        ids_q = inputs_q[\"input_ids\"]\n","        token_type_ids_q = inputs_q[\"token_type_ids\"]\n","        mask_q = inputs_q[\"attention_mask\"]\n","\n","        ids_a = inputs_a[\"input_ids\"]\n","        token_type_ids_a = inputs_a[\"token_type_ids\"]\n","        mask_a = inputs_a[\"attention_mask\"]\n","        \n","        padding_length_q = MAX_LEN - len(ids_q)\n","        padding_length_a = MAX_LEN - len(ids_a)\n","        \n","        ids_q = ids_q + ([0] * padding_length_q)\n","        mask_q = mask_q + ([0] * padding_length_q)\n","        token_type_ids_q = token_type_ids_q + ([0] * padding_length_q)\n","\n","        ids_a = ids_a + ([0] * padding_length_a)\n","        mask_a = mask_a + ([0] * padding_length_a)\n","        token_type_ids_a = token_type_ids_a + ([0] * padding_length_a)\n","        \n","        if self.labeled:\n","            labels = self.get_label(row)\n","            return {\n","                'ids_q': torch.tensor(ids_q, dtype=torch.long),\n","                'mask_q': torch.tensor(mask_q, dtype=torch.long),\n","                'token_type_ids_q': torch.tensor(token_type_ids_q, dtype=torch.long),\n","                'ids_a': torch.tensor(ids_a, dtype=torch.long),\n","                'mask_a': torch.tensor(mask_a, dtype=torch.long),\n","                'token_type_ids_a': torch.tensor(token_type_ids_a, dtype=torch.long),\n","                'labels': labels, \n","            }\n","        else:\n","            return {\n","                'ids_q': torch.tensor(ids_q, dtype=torch.long),\n","                'mask_q': torch.tensor(mask_q, dtype=torch.long),\n","                'token_type_ids_q': torch.tensor(token_type_ids_q, dtype=torch.long),\n","                'ids_a': torch.tensor(ids_a, dtype=torch.long),\n","                'mask_a': torch.tensor(mask_a, dtype=torch.long),\n","                'token_type_ids_a': torch.tensor(token_type_ids_a, dtype=torch.long)\n","            }\n","\n","\n","    def get_label(self, row):\n","        return torch.tensor(row[target_columns].values.astype(np.float32))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3NXBQo6aOQCc","colab":{}},"source":["def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0):\n","    df = pd.read_csv(f'{DATA_DIR}/train.csv')\n","\n","    # cleaning\n","    df['question_title'] = df['question_title'].apply(lambda x : preprocessing(x))\n","    df['question_body'] = df['question_body'].apply(lambda x : preprocessing(x))\n","    df['answer'] = df['answer'].apply(lambda x : preprocessing(x))\n","    \n","\n","    df = shuffle(df, random_state=1234)\n","    gkf = GroupKFold(n_splits=5).split(X=df.question_body, groups=df.question_body)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf):\n","        if fold == ifold:\n","            df_train = df.iloc[train_idx]\n","            df_val = df.iloc[valid_idx]\n","            break\n","\n","    print('train', df_train.shape)\n","    print('val', df_val.shape)\n","\n","    ds_train = QuestDataset(df_train, train_mode=True)\n","    train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n","    train_loader.num = len(df_train)\n","\n","    ds_val = QuestDataset(df_val, train_mode=False)\n","    val_loader = torch.utils.data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=0, drop_last=False)\n","    val_loader.num = len(df_val)\n","    val_loader.df = df_val\n","\n","    return train_loader, val_loader, df_val.shape[0], valid_idx\n","\n","\n","def get_test_loader(batch_size=4):\n","    df = pd.read_csv(f'{DATA_DIR}/test.csv')\n","\n","    # cleaning\n","    df['question_title'] = df['question_title'].apply(lambda x : preprocessing(x))\n","    df['question_body'] = df['question_body'].apply(lambda x : preprocessing(x))\n","    df['answer'] = df['answer'].apply(lambda x : preprocessing(x))\n","    \n","    ds_test = QuestDataset(df, train_mode=False, labeled=False)\n","    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False)\n","    loader.num = len(df)\n","    \n","    return loader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c7p98IBtOQCl","colab":{}},"source":["class QuestModel(nn.Module):\n","    def __init__(self, n_classes=30):\n","        super(QuestModel, self).__init__()\n","        self.model_name = 'QuestModel'\n","        #self.bert_model = BertModel.from_pretrained(BERT_DIR+'/bert-base-uncased/')\n","        #self.bert_model = BertModel.from_pretrained('../input/bert-base-uncased/')\n","        self.bert_model = BertModel.from_pretrained('bert-large-uncased')\n","        \n","        self.fc_q = nn.Linear(1024, 21)\n","        self.fc_a = nn.Linear(1024+21, 9)\n","\n","    def forward(self, ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a):\n","        layers_q, pool_out_q = self.bert_model(input_ids=ids_q, token_type_ids=token_type_ids_q, attention_mask=mask_q)\n","        layers_a, pool_out_a = self.bert_model(input_ids=ids_a, token_type_ids=token_type_ids_a, attention_mask=mask_a)\n","        \n","        out_q = F.avg_pool1d(layers_q.transpose(1,2), kernel_size=layers_q.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n","        out_a = F.avg_pool1d(layers_a.transpose(1,2), kernel_size=layers_a.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n","\n","        out_q = F.dropout(out_q, p=0.2, training=self.training)\n","        logit_q = self.fc_q(out_q)\n","\n","        out_a = torch.cat([out_a, F.relu(logit_q)], dim=-1)\n","        logit_a = self.fc_a(out_a)\n","\n","        logit = torch.cat([logit_q, logit_a], dim=-1)\n","\n","        return logit\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ffu67MIrOQC4","colab":{}},"source":["def train_model(train_loader, optimizer, criterion, scheduler):\n","    model.train()\n","    avg_loss = 0.    \n","    for idx, batch in enumerate(tqdm(train_loader)):\n","        ids_q = batch['ids_q'].to(device)\n","        mask_q = batch['mask_q'].to(device)\n","        token_type_ids_q = batch['token_type_ids_q'].to(device)\n","        ids_a = batch['ids_a'].to(device)\n","        mask_a = batch['mask_a'].to(device)\n","        token_type_ids_a = batch['token_type_ids_a'].to(device)\n","        labels = batch['labels'].to(device)\n","        \n","        logits = model(ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a)        \n","        loss = criterion(logits, labels)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        avg_loss += loss.item() / len(train_loader)\n","        del ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a, labels\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    return avg_loss\n","\n","def val_model(val_loader, val_length, batch_size=8):\n","    model.eval() # eval mode  \n","    avg_val_loss = 0.\n","    \n","    valid_preds = np.zeros((val_length, len(target_columns)))\n","    original = np.zeros((val_length, len(target_columns)))\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(tqdm(val_loader)):\n","            ids_q = batch['ids_q'].to(device)\n","            mask_q = batch['mask_q'].to(device)\n","            token_type_ids_q = batch['token_type_ids_q'].to(device)\n","            ids_a = batch['ids_a'].to(device)\n","            mask_a = batch['mask_a'].to(device)\n","            token_type_ids_a = batch['token_type_ids_a'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            logits = torch.sigmoid(model(ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a))\n","            \n","            avg_val_loss += criterion(logits, labels).item() / len(val_loader)\n","            valid_preds[idx*batch_size : (idx+1)*batch_size] = logits.detach().cpu().squeeze().numpy()\n","            original[idx*batch_size : (idx+1)*batch_size]    = labels.detach().cpu().squeeze().numpy()\n","        \n","        rho_val = np.mean([spearmanr(original[:, i], valid_preds[:,i]).correlation for i in range(valid_preds.shape[1])])\n","        print('\\r val_spearman-rho: %s' % (str(round(rho_val, 5))), end = 100*' '+'\\n')\n","        \n","        score = 0\n","        for i in range(len(target_columns)):\n","            print(i, spearmanr(original[:,i], valid_preds[:,i]))\n","            score += np.nan_to_num(spearmanr(original[:, i], valid_preds[:, i]).correlation)\n","    \n","    return avg_val_loss, score/len(target_columns)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xz4rSv7VOQDj","outputId":"a8c7c5a8-300f-491c-d9b0-f41c2126563e","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2b8a48c4ca3c42238208a79708522410","bb694fb8e94e47c1a99eaa5e7850767e","31d98f2b7f7c4feeabc23c0d7110a137","ee133f6e974d402bbf66eedb9077eaea","af1bcaef51e04384863aaae86f6547c8","c45ca9bd5d1048e3821a2a27bffa97aa","ee4f3ac5d55a4cffabdd91c472056528","84865b79fb1c43a0b4f7e2b3d403824e","4762ace7c5394d47a2e5a8a4d12303c2","bd5d598816bb4163badbdf889c14ee28","315ac8f6d15d4b9dac1232e3204a9a2e","cb5afc5b894a46adab88706a651a0308","53633d28d18f4e03bafc6c3351095d89","b3bbba94be724ec2a2d80a91b7a5c5f6","ab4f4f1ad8cc4c9f81251632ce97da4c","fce2cc520eb1407cbde4b6ca6c030838","a98013781f704ea5af8083c013f18f28","553ecc4e21cf48b0b616028559420834","7cff8865ad4d4de3b553261a3730e1bb","afb53619b8264dc6926938fe7b68d655","01d7b9fbb08048bd9c2731acd73278be","87ce5768af6c4a55b8d41128f10597a3","e999fab94fca47eca65335d940cee67d","e035f28a3d1244b0bf9b496b37c23f18"]},"executionInfo":{"status":"error","timestamp":1581047201075,"user_tz":-540,"elapsed":1765997,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}}},"source":["cv_list = []\n","# for fold in range(config.fold):\n","for fold in [3,4]:\n","    print('---%d-Fold---'%(fold+1))\n","    \n","    patience = 0\n","    best_loss   = 100.0\n","    best_score      = -1.\n","    best_preds = 0\n","    best_param_loss = None\n","    best_param_score = None\n","\n","    model = QuestModel(n_classes=30).to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, eps=4e-5)\n","    criterion = nn.BCEWithLogitsLoss()\n","    \n","    for epoch in range(config.epochs):\n","        \n","        torch.cuda.empty_cache()\n","        start_time   = time.time()\n","        \n","        train_loader, val_loader, val_length, val_idx = get_train_val_loaders(batch_size=config.batch_size, val_batch_size=config.batch_size, ifold=fold)\n","        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps=config.epochs*len(train_loader))\n","        \n","        loss_train = train_model(train_loader, optimizer, criterion, scheduler)\n","        loss_val, score_val = val_model(val_loader, val_length, batch_size=config.batch_size)\n","        print(f'Epoch {(epoch+1)}, train_loss: {loss_train}, val_loss: {loss_val}, score_val: {score_val}, time: {(time.time()-start_time)}')\n","\n","        if score_val > best_score:\n","            best_score = score_val\n","            best_param_score = model.state_dict()\n","            print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n","            torch.save(best_param_score, '/content/drive/My Drive/Colab Notebooks/GoogleQuest/best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n","        else:\n","            patience += 1\n","            if patience >= config.patience:\n","                del train_loader, val_loader, loss_train, loss_val, score_val\n","                torch.cuda.empty_cache()\n","                gc.collect()\n","                break\n","    \n","        del train_loader, val_loader, loss_train, loss_val, score_val\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        \n","    model.load_state_dict(best_param_score)\n","    print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n","    torch.save(best_param_score, '/content/drive/My Drive/Colab Notebooks/GoogleQuest/best_param_score_{}_{}.pt'.format(config.name ,fold+1))   \n","    cv_list.append(best_score)\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","print('CV_score: ', np.mean(cv_list))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["---4-Fold---\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b8a48c4ca3c42238208a79708522410","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=362, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4762ace7c5394d47a2e5a8a4d12303c2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=1344997306, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","train (4863, 41)\n","val (1216, 41)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a98013781f704ea5af8083c013f18f28","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2431/2431 [55:14<00:00,  1.37s/it]\n","100%|██████████| 608/608 [04:29<00:00,  2.25it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\r val_spearman-rho: 0.37204                                                                                                    \n","0 SpearmanrResult(correlation=0.29322969666975823, pvalue=1.5412434612163549e-25)\n","1 SpearmanrResult(correlation=0.46456288709137156, pvalue=4.001483387052173e-66)\n","2 SpearmanrResult(correlation=0.38327931098878437, pvalue=7.766125515964469e-44)\n","3 SpearmanrResult(correlation=0.27376814642835867, pvalue=2.4022776342582263e-22)\n","4 SpearmanrResult(correlation=0.3171223577641095, pvalue=8.21427737941366e-30)\n","5 SpearmanrResult(correlation=0.4151186156504113, pvalue=7.608175012874866e-52)\n","6 SpearmanrResult(correlation=0.2981085746722296, pvalue=2.2254566844202004e-26)\n","7 SpearmanrResult(correlation=0.47179978213936846, pvalue=2.0307776880073004e-68)\n","8 SpearmanrResult(correlation=0.4785020834050644, pvalue=1.3579873642637972e-70)\n","9 SpearmanrResult(correlation=0.049710569900907775, pvalue=0.08313916325726783)\n","10 SpearmanrResult(correlation=0.4264340687683175, pvalue=6.594357191216905e-55)\n","11 SpearmanrResult(correlation=0.7207005430452774, pvalue=2.184321444290263e-195)\n","12 SpearmanrResult(correlation=0.3190790187486619, pvalue=3.522389120389661e-30)\n","13 SpearmanrResult(correlation=0.11978714730025435, pvalue=2.815325643177082e-05)\n","14 SpearmanrResult(correlation=0.3737713446895796, pvalue=1.3059562215800998e-41)\n","15 SpearmanrResult(correlation=0.41461700083289854, pvalue=1.0335473910147714e-51)\n","16 SpearmanrResult(correlation=0.7513878959568333, pvalue=1.989308676040437e-221)\n","17 SpearmanrResult(correlation=0.3450596344130498, pvalue=2.5108757504139667e-35)\n","18 SpearmanrResult(correlation=0.6320151934864126, pvalue=1.382955551221049e-136)\n","19 SpearmanrResult(correlation=0.049922455731559436, pvalue=0.08183264300004034)\n","20 SpearmanrResult(correlation=0.4112505869947209, pvalue=7.969177616122774e-51)\n","21 SpearmanrResult(correlation=0.26494434104123393, pvalue=5.56806987942781e-21)\n","22 SpearmanrResult(correlation=0.39664376086573583, pvalue=4.3125745239718153e-47)\n","23 SpearmanrResult(correlation=0.19915304219007726, pvalue=2.4196609848782385e-12)\n","24 SpearmanrResult(correlation=0.18831834869844452, pvalue=3.6055708796933054e-11)\n","25 SpearmanrResult(correlation=0.2863045447337731, pvalue=2.2544440545196735e-24)\n","26 SpearmanrResult(correlation=0.7446741886629057, pvalue=2.0634118900265165e-215)\n","27 SpearmanrResult(correlation=0.2944438768655401, pvalue=9.555037977560835e-26)\n","28 SpearmanrResult(correlation=0.6206556253939538, pvalue=2.0990688771765952e-130)\n","29 SpearmanrResult(correlation=0.15684709524484675, pvalue=3.8438078255622495e-08)\n","Epoch 1, train_loss: 0.3886378060663158, val_loss: 0.6212847696519206, score_val: 0.37204039127914806, time: 3591.670685529709\n","best_param_score_reModel_4.pt\n","train (4863, 41)\n","val (1216, 41)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2431/2431 [55:21<00:00,  1.36s/it]\n","100%|██████████| 608/608 [04:30<00:00,  2.24it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\r val_spearman-rho: 0.38297                                                                                                    \n","0 SpearmanrResult(correlation=0.34109157636968446, pvalue=1.6530262295395722e-34)\n","1 SpearmanrResult(correlation=0.5442557496683802, pvalue=1.0457598226103409e-94)\n","2 SpearmanrResult(correlation=0.3972896795894407, pvalue=2.975514423415964e-47)\n","3 SpearmanrResult(correlation=0.26553509175020723, pvalue=4.527876479536324e-21)\n","4 SpearmanrResult(correlation=0.29601115367049435, pvalue=5.137156925590135e-26)\n","5 SpearmanrResult(correlation=0.45519984649106415, pvalue=3.0918555367538957e-63)\n","6 SpearmanrResult(correlation=0.2988836997716854, pvalue=1.6307679668590393e-26)\n","7 SpearmanrResult(correlation=0.4609851983912948, pvalue=5.204399786337575e-65)\n","8 SpearmanrResult(correlation=0.5308564170010538, pvalue=2.3533364552175738e-89)\n","9 SpearmanrResult(correlation=0.04874910216449641, pvalue=0.08928126545021259)\n","10 SpearmanrResult(correlation=0.4585208317531971, pvalue=2.9932656218117457e-64)\n","11 SpearmanrResult(correlation=0.7348547013348535, pvalue=6.035154174508506e-207)\n","12 SpearmanrResult(correlation=0.3624835679466261, pvalue=4.607609137741984e-39)\n","13 SpearmanrResult(correlation=0.13681428341709495, pvalue=1.680295560829754e-06)\n","14 SpearmanrResult(correlation=0.38697117853571866, pvalue=1.0136640594160694e-44)\n","15 SpearmanrResult(correlation=0.4421646976889601, pvalue=2.31131410484047e-59)\n","16 SpearmanrResult(correlation=0.7677576342893857, pvalue=6.113907286959999e-237)\n","17 SpearmanrResult(correlation=0.35182715770406897, pvalue=9.471135433403293e-37)\n","18 SpearmanrResult(correlation=0.6336978595789603, pvalue=1.5963373442937396e-137)\n","19 SpearmanrResult(correlation=0.03731898688444888, pvalue=0.19343918792529863)\n","20 SpearmanrResult(correlation=0.4745930282451392, pvalue=2.553762699162561e-69)\n","21 SpearmanrResult(correlation=0.22783622653161037, pvalue=8.783989271441629e-16)\n","22 SpearmanrResult(correlation=0.4019282123800468, pvalue=2.0210041039279202e-48)\n","23 SpearmanrResult(correlation=0.1501312003980706, pvalue=1.4428546315393718e-07)\n","24 SpearmanrResult(correlation=0.16729382344407145, pvalue=4.380516296523959e-09)\n","25 SpearmanrResult(correlation=0.30907198469019653, pvalue=2.505742021833692e-28)\n","26 SpearmanrResult(correlation=0.7431049275055748, pvalue=4.937873580812801e-214)\n","27 SpearmanrResult(correlation=0.2674893735075415, pvalue=2.2760367419549692e-21)\n","28 SpearmanrResult(correlation=0.6406131791393338, pvalue=1.9391791709048526e-141)\n","29 SpearmanrResult(correlation=0.1556340500748529, pvalue=4.901871356512954e-08)\n","Epoch 2, train_loss: 0.36566647648786815, val_loss: 0.6192356599004643, score_val: 0.38296548066391856, time: 3598.551352739334\n","best_param_score_reModel_4.pt\n","train (4863, 41)\n","val (1216, 41)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2431/2431 [55:20<00:00,  1.36s/it]\n","100%|██████████| 608/608 [04:29<00:00,  2.25it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\r val_spearman-rho: 0.39825                                                                                                    \n","0 SpearmanrResult(correlation=0.310697576267786, pvalue=1.2673306491742604e-28)\n","1 SpearmanrResult(correlation=0.55453341191254, pvalue=5.585180813156924e-99)\n","2 SpearmanrResult(correlation=0.4055857634882172, pvalue=2.351907894107459e-49)\n","3 SpearmanrResult(correlation=0.31341435547541574, pvalue=4.017584982788305e-29)\n","4 SpearmanrResult(correlation=0.3589330000537287, pvalue=2.7793012626209627e-38)\n","5 SpearmanrResult(correlation=0.4523746304805134, pvalue=2.2086628233842676e-62)\n","6 SpearmanrResult(correlation=0.306089910306721, pvalue=8.653732887914635e-28)\n","7 SpearmanrResult(correlation=0.47677116748513143, pvalue=5.0024542418711274e-70)\n","8 SpearmanrResult(correlation=0.5726842146757212, pvalue=6.715972503135064e-107)\n","9 SpearmanrResult(correlation=0.05978373105891882, pvalue=0.03711920999445273)\n","10 SpearmanrResult(correlation=0.47999916324868974, pvalue=4.370004358653656e-71)\n","11 SpearmanrResult(correlation=0.7408058226524591, pvalue=4.96267478629076e-212)\n","12 SpearmanrResult(correlation=0.35592849817867483, pvalue=1.249308410455042e-37)\n","13 SpearmanrResult(correlation=0.15796293087882146, pvalue=3.0683539292114447e-08)\n","14 SpearmanrResult(correlation=0.3845948613163204, pvalue=3.7704331654011667e-44)\n","15 SpearmanrResult(correlation=0.42790240620055164, pvalue=2.589321345833994e-55)\n","16 SpearmanrResult(correlation=0.7706387630674056, pvalue=8.378963313270229e-240)\n","17 SpearmanrResult(correlation=0.3688748028131644, pvalue=1.7120935782804218e-40)\n","18 SpearmanrResult(correlation=0.6533697722750261, pvalue=6.21748251268499e-149)\n","19 SpearmanrResult(correlation=0.05662888869607697, pvalue=0.04835101465375979)\n","20 SpearmanrResult(correlation=0.47916551540920077, pvalue=8.222119263590746e-71)\n","21 SpearmanrResult(correlation=0.29166004363116904, pvalue=2.8497936869545995e-25)\n","22 SpearmanrResult(correlation=0.42448677495345727, pvalue=2.2620433271029898e-54)\n","23 SpearmanrResult(correlation=0.20910296369241277, pvalue=1.761634718151521e-13)\n","24 SpearmanrResult(correlation=0.18457396835567166, pvalue=8.844155553512439e-11)\n","25 SpearmanrResult(correlation=0.31490215778383884, pvalue=2.1307104322421193e-29)\n","26 SpearmanrResult(correlation=0.7451087947942912, pvalue=8.528884437808988e-216)\n","27 SpearmanrResult(correlation=0.3081561350202835, pvalue=3.672064491044549e-28)\n","28 SpearmanrResult(correlation=0.6336254756863656, pvalue=1.7521900126902832e-137)\n","29 SpearmanrResult(correlation=0.14924743173368815, pvalue=1.7099058332990035e-07)\n","Epoch 3, train_loss: 0.35486572628426394, val_loss: 0.6149543008129854, score_val: 0.3982534310530754, time: 3596.9500896930695\n","best_param_score_reModel_4.pt\n","train (4863, 41)\n","val (1216, 41)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2431/2431 [55:23<00:00,  1.37s/it]\n","100%|██████████| 608/608 [04:30<00:00,  2.24it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\r val_spearman-rho: 0.38967                                                                                                    \n","0 SpearmanrResult(correlation=0.3275620123658381, pvalue=8.331222166087382e-32)\n","1 SpearmanrResult(correlation=0.5556995485292233, pvalue=1.789826592404023e-99)\n","2 SpearmanrResult(correlation=0.41085432861000504, pvalue=1.0119659882007953e-50)\n","3 SpearmanrResult(correlation=0.32595545151267075, pvalue=1.7087237447104407e-31)\n","4 SpearmanrResult(correlation=0.3510514349319473, pvalue=1.3846388452487334e-36)\n","5 SpearmanrResult(correlation=0.45182784318197006, pvalue=3.224540841988746e-62)\n","6 SpearmanrResult(correlation=0.31308566986835434, pvalue=4.6195961283551896e-29)\n","7 SpearmanrResult(correlation=0.4789175893099092, pvalue=9.919141637234944e-71)\n","8 SpearmanrResult(correlation=0.5321825606433079, pvalue=7.1226771084165605e-90)\n","9 SpearmanrResult(correlation=0.06907572901364804, pvalue=0.015989562385551045)\n","10 SpearmanrResult(correlation=0.48300629379784116, pvalue=4.4052490163444893e-72)\n","11 SpearmanrResult(correlation=0.7299918672249895, pvalue=6.832840951955504e-203)\n","12 SpearmanrResult(correlation=0.3459775638021073, pvalue=1.6173320351153816e-35)\n","13 SpearmanrResult(correlation=0.1459449493089008, pvalue=3.1972685295710714e-07)\n","14 SpearmanrResult(correlation=0.3871047079242006, pvalue=9.412327841194322e-45)\n","15 SpearmanrResult(correlation=0.4262773881087693, pvalue=7.284091240312324e-55)\n","16 SpearmanrResult(correlation=0.7707254026884989, pvalue=6.861865057257428e-240)\n","17 SpearmanrResult(correlation=0.3611468354948012, pvalue=9.087975511335927e-39)\n","18 SpearmanrResult(correlation=0.6505794853325876, pvalue=2.909074005267999e-147)\n","19 SpearmanrResult(correlation=0.04685830963570227, pvalue=0.10242236580442385)\n","20 SpearmanrResult(correlation=0.46707030511221537, pvalue=6.507918943640019e-67)\n","21 SpearmanrResult(correlation=0.24137993303623315, pvalue=1.4008094606800783e-17)\n","22 SpearmanrResult(correlation=0.40445267357284337, pvalue=4.592646389187648e-49)\n","23 SpearmanrResult(correlation=0.1871103743737741, pvalue=4.8258065254909636e-11)\n","24 SpearmanrResult(correlation=0.13690913214003467, pvalue=1.6524639936341759e-06)\n","25 SpearmanrResult(correlation=0.2937362108043165, pvalue=1.2629134518609844e-25)\n","26 SpearmanrResult(correlation=0.7274750582173654, pvalue=7.909645661314533e-201)\n","27 SpearmanrResult(correlation=0.28445278264274976, pvalue=4.561676567397401e-24)\n","28 SpearmanrResult(correlation=0.6197585406892857, pvalue=6.300342410523561e-130)\n","29 SpearmanrResult(correlation=0.163810846467479, pvalue=9.178234746332193e-09)\n","Epoch 4, train_loss: 0.3459303569445536, val_loss: 0.6148419677230874, score_val: 0.38966602761138575, time: 3599.9104521274567\n","best_param_score_reModel_4.pt\n","---5-Fold---\n","train (4864, 41)\n","val (1215, 41)\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2432/2432 [55:22<00:00,  1.36s/it]\n","100%|█████████▉| 607/608 [04:28<00:00,  2.26it/s]"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-8ad432bb16bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {(epoch+1)}, train_loss: {loss_train}, val_loss: {loss_val}, score_val: {score_val}, time: {(time.time()-start_time)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-ca6f165593c3>\u001b[0m in \u001b[0;36mval_model\u001b[0;34m(val_loader, val_length, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mavg_val_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mvalid_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moriginal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1, 30])) must be the same as input size (torch.Size([30]))"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MpsndIInyZhd","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}