{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"18_reEDA","provenance":[{"file_id":"1GzGzgmnluV_YNFU8idScDd2qBhEwUvJy","timestamp":1579583693270}],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ey70gi19Nsx-","colab_type":"text"},"source":["## TODO\n","- titleのembedding\n","- tokenizer, pretrained-embeddingの利用\n","- modelの中での読み込み"]},{"cell_type":"code","metadata":{"id":"qq1H1Ysqe54Y","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jA3tbCNkNsyE","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import math\n","import random\n","import matplotlib.pyplot as plt\n","import os, sys, gc, random, multiprocessing, glob, time\n","\n","DATA_DIR = '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/google-quest-challenge'\n","#DATA_DIR = '../input/google-quest-challenge'\n","# DATA_DIR = 'D:/project/ICF_AutoCapsule_disabled/kaggle/google-quest-challenge'\n","# BERT_DIR = 'D:/project/ICF_AutoCapsule_disabled/BERT'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7t81rKkTNsyS","colab_type":"code","colab":{}},"source":["# import nltk\n","# nltk.download('averaged_perceptron_tagger')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2NayaMLwxbw0","colab_type":"code","colab":{}},"source":["!pip install nlpaug\n","!pip install transformers\n","!pip install flashtext\n","\n","!pip install swifter"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxSotPQFNsyf","colab_type":"code","colab":{}},"source":["# !pip install ../input/sacremoses/sacremoses-master/\n","# !pip install ../input/transformers/transformers-master/\n","\n","# !pip install ../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\n","# !pip install ../input/glove840b300dtxt/glove.840B.300d.txt\n","\n","# CRAWL_EMBEDDING_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n","\n","\n","GLOVE_EMBEDDING_PATH = '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/glove840b300dtxt/glove.840B.300d.txt'\n","# GLOVE_EMBEDDING_PATH = '../input/glove840b300dtxt/glove.840B.300d.txt'\n","# CRAWL_EMBEDDING_PATH = 'D:/project/ICF_AutoCapsule_disabled/W2V/crawl-300d-2M.vec'\n","# GLOVE_EMBEDDING_PATH = 'D:/project/ICF_AutoCapsule_disabled/W2V/glove.840B.300d.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KTAi6HeWNsyr","colab_type":"code","colab":{}},"source":["import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw\n","import nlpaug.augmenter.sentence as nas\n","import nlpaug.flow as naf\n","\n","from nlpaug.util import Action"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6Wx4vV6Nsy6","colab_type":"code","colab":{}},"source":["import keras\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils import data\n","from torch.utils.data import DataLoader, Dataset\n","\n","#from ml_stratifiers import MultilabelStratifiedShuffleSplit, MultilabelStratifiedKFold\n","from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n","from sklearn.utils import shuffle\n","from sklearn.preprocessing import LabelEncoder\n","\n","from scipy.stats import spearmanr\n","\n","import transformers\n","from transformers import (\n","    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n","    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n","    get_cosine_schedule_with_warmup,\n",")\n","\n","from tqdm import tqdm\n","print(transformers.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NgX5gV1ANszK","colab_type":"code","colab":{}},"source":["## Make results reproducible .Else noone will believe you .\n","import random\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODoIAtR0NszS","colab_type":"code","colab":{}},"source":["class PipeLineConfig:\n","    def __init__(self, lr, warmup, epochs, patience, batch_size, seed, name, question_weight,answer_weight,fold,train):\n","        self.lr = lr\n","        self.warmup = warmup\n","        self.epochs = epochs\n","        self.patience = patience\n","        self.batch_size = batch_size\n","        self.seed = seed\n","        self.name = name\n","        self.question_weight = question_weight\n","        self.answer_weight =answer_weight\n","        self.fold = fold\n","        self.train = train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rT6m-vjhNszd","colab_type":"code","colab":{}},"source":["config = PipeLineConfig(lr=1e-5, \\\n","                        warmup=0.01, \\\n","                        epochs=30, \\\n","                        patience=3, \\\n","                        batch_size=32, \\\n","                        seed=42, \\\n","                        name='lstm', \\\n","                        question_weight=0.5, \\\n","                        answer_weight=0.5, \\\n","                        fold=5, \\\n","                        train=True\n","                       )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMrfn1nTNszs","colab_type":"code","colab":{}},"source":["seed_everything(config.seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oZ2WfJnNsz3","colab_type":"code","colab":{}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","#device = 'cpu'\n","print(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"imoTxeqVNs0C","colab_type":"code","colab":{}},"source":["sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n","sub.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"kxdD-wsxNs0L","colab_type":"code","colab":{}},"source":["target_columns = sub.columns.values[1:].tolist()\n","target_columns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qj0ocgmRNs0U","colab_type":"code","colab":{}},"source":["train = pd.read_csv(f'{DATA_DIR}/train.csv')\n","train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ibdhIwlNs0d","colab_type":"code","colab":{}},"source":["test = pd.read_csv(f'{DATA_DIR}/test.csv')\n","test.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SiFDcIGih9Mj","colab_type":"text"},"source":["## EDA"]},{"cell_type":"code","metadata":{"id":"YOCVRFDriX3l","colab_type":"code","colab":{}},"source":["import seaborn as sns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QS13tinYh89R","colab_type":"code","colab":{}},"source":["for col in target_columns:\n","  sns.distplot(train[col], kde=False)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uQZgYHl1sdD-","colab_type":"text"},"source":["## 文長"]},{"cell_type":"code","metadata":{"id":"xGnqxSf2h8vc","colab_type":"code","colab":{}},"source":["h = 0.95\n","for col in ['question_title', 'question_body', 'answer']:\n","  obj_train = train[col].apply(lambda x: len(x.split(' ')))\n","  obj_test = test[col].apply(lambda x: len(x.split(' ')))\n","  print('train_%s'%col)\n","  print(obj_train.describe())\n","  print('%.2f: '%h, obj_train.quantile(h))\n","  print('test_%s'%col)\n","  print(obj_test.describe())\n","  print('%.2f: '%h, obj_test.quantile(h))\n","\n","  sns.distplot(obj_train, kde=True, color='b', label='train')\n","  sns.distplot(obj_test, kde=True, color='r', label='test')\n","  plt.legend()\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRz5_YFKh8Jh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zPeX067rNs1F","colab_type":"text"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"EnpgnahVNs1L","colab_type":"code","colab":{}},"source":["import re\n","from flashtext import KeywordProcessor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pfvb3jcRNs1U","colab_type":"code","colab":{}},"source":["PUNCTS = {\n","            '》', '〞', '¢', '‹', '╦', '║', '♪', 'Ø', '╩', '\\\\', '★', '＋', 'ï', '<', '?', '％', '+', '„', 'α', '*', '〰', '｟', '¹', '●', '〗', ']', '▾', '■', '〙', '↓', '´', '【', 'ᴵ',\n","            '\"', '）', '｀', '│', '¤', '²', '‡', '¿', '–', '」', '╔', '〾', '%', '¾', '←', '〔', '＿', '’', '-', ':', '‧', '｛', 'β', '（', '─', 'à', 'â', '､', '•', '；', '☆', '／', 'π',\n","            'é', '╗', '＾', '▪', ',', '►', '/', '〚', '¶', '♦', '™', '}', '″', '＂', '『', '▬', '±', '«', '“', '÷', '×', '^', '!', '╣', '▲', '・', '░', '′', '〝', '‛', '√', ';', '】', '▼',\n","            '.', '~', '`', '。', 'ə', '］', '，', '{', '～', '！', '†', '‘', '﹏', '═', '｣', '〕', '〜', '＼', '▒', '＄', '♥', '〛', '≤', '∞', '_', '[', '＆', '→', '»', '－', '＝', '§', '⋅', \n","            '▓', '&', 'Â', '＞', '〃', '|', '¦', '—', '╚', '〖', '―', '¸', '³', '®', '｠', '¨', '‟', '＊', '£', '#', 'Ã', \"'\", '▀', '·', '？', '、', '█', '”', '＃', '⊕', '=', '〟', '½', '』',\n","            '［', '$', ')', 'θ', '@', '›', '＠', '｝', '¬', '…', '¼', '：', '¥', '❤', '€', '−', '＜', '(', '〘', '▄', '＇', '>', '₤', '₹', '∅', 'è', '〿', '「', '©', '｢', '∙', '°', '｜', '¡', \n","            '↑', 'º', '¯', '♫', '#'\n","          }\n","\n","\n","mispell_dict = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\",\n","\"couldnt\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n","\"doesnt\" : \"does not\", \"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\",\n","\"haven't\" : \"have not\", \"havent\" : \"have not\", \"he'd\" : \"he would\", \"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"I would\",\n","\"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\", \"isn't\" : \"is not\", \"it's\" : \"it is\",\n","\"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \n","\"shan't\" : \"shall not\", \"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"shouldnt\" : \"should not\",\n","\"that's\" : \"that is\", \"thats\" : \"that is\", \"there's\" : \"there is\", \"theres\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\",\n","\"they're\" : \"they are\", \"theyre\":  \"they are\", \"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\",\n","\"we've\" : \"we have\", \"what'll\" : \"what will\", \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\", \"where's\" : \"where is\",\n","\"who'd\" : \"who would\", \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\", \"won't\" : \"will not\", \"wouldn't\" : \"would not\", \"you'd\" : \"you would\",\n","\"you'll\" : \"you will\", \"you're\" : \"you are\", \"you've\" : \"you have\", \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\", \"tryin'\":\"trying\"}\n","\n","\n","kp = KeywordProcessor(case_sensitive=True)\n","for k, v in mispell_dict.items():\n","    kp.add_keyword(k, v)\n","\n","def clean_punct(text):\n","    text = str(text)\n","    for punct in PUNCTS:\n","        text = text.replace(punct, ' {} '.format(punct))\n","    return text\n","\n","\n","def preprocessing(text):\n","    text = text.lower()\n","    text = re.sub(r'(\\&lt)|(\\&gt)', ' ', text)\n","    \n","    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' url ', text)\n","    text = kp.replace_keywords(text)\n","    text = clean_punct(text)\n","    text = re.sub(r'\\n\\r', ' ', text)\n","    text = re.sub(r'\\s{2,}', ' ', text)\n","    \n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OH6dCB5GNs1e","colab_type":"code","colab":{}},"source":["# train['question_title'] = train['question_title'].apply(lambda x : preprocessing(x))\n","# train['question_body'] = train['question_body'].apply(lambda x : preprocessing(x))\n","# train['answer'] = train['answer'].apply(lambda x : preprocessing(x))\n","\n","# test['question_title'] = test['question_title'].apply(lambda x : preprocessing(x))\n","# test['question_body'] = test['question_body'].apply(lambda x : preprocessing(x))\n","# test['answer'] = test['answer'].apply(lambda x : preprocessing(x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVqS8PwVNs1y","colab_type":"code","colab":{}},"source":["# # category, host変数を、数値化(LabelEncode)\n","# le_category = LabelEncoder()\n","# le_category.fit(np.concatenate([train.category.values, test.category.values], axis=0))\n","# train['category'] = le_category.transform(train.category)\n","# test['category'] = le_category.transform(test.category)\n","\n","# le_host = LabelEncoder()\n","# le_host.fit(np.concatenate([train.host.values, test.host.values], axis=0))\n","# train['host'] = le_host.transform(train.host)\n","# test['host'] = le_host.transform(test.host)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_13BklkNs19","colab_type":"code","colab":{}},"source":["category_list = ['CULTURE', 'LIFE_ARTS', 'SCIENCE', 'STACKOVERFLOW', 'TECHNOLOGY']\n","\n","host_list = ['academia.stackexchange.com', 'android.stackexchange.com',\n","       'anime.stackexchange.com', 'apple.stackexchange.com',\n","       'askubuntu.com', 'bicycles.stackexchange.com',\n","       'biology.stackexchange.com', 'blender.stackexchange.com',\n","       'boardgames.stackexchange.com', 'chemistry.stackexchange.com',\n","       'christianity.stackexchange.com', 'codereview.stackexchange.com',\n","       'cooking.stackexchange.com', 'crypto.stackexchange.com',\n","       'cs.stackexchange.com', 'dba.stackexchange.com',\n","       'diy.stackexchange.com', 'drupal.stackexchange.com',\n","       'dsp.stackexchange.com', 'electronics.stackexchange.com',\n","       'ell.stackexchange.com', 'english.stackexchange.com',\n","       'expressionengine.stackexchange.com', 'gamedev.stackexchange.com',\n","       'gaming.stackexchange.com', 'gis.stackexchange.com',\n","       'graphicdesign.stackexchange.com', 'judaism.stackexchange.com',\n","       'magento.stackexchange.com', 'math.stackexchange.com',\n","       'mathematica.stackexchange.com', 'mathoverflow.net',\n","       'mechanics.stackexchange.com', 'meta.askubuntu.com',\n","       'meta.christianity.stackexchange.com',\n","       'meta.codereview.stackexchange.com', 'meta.math.stackexchange.com',\n","       'meta.stackexchange.com', 'meta.superuser.com',\n","       'money.stackexchange.com', 'movies.stackexchange.com',\n","       'music.stackexchange.com', 'photo.stackexchange.com',\n","       'physics.stackexchange.com', 'programmers.stackexchange.com',\n","       'raspberrypi.stackexchange.com', 'robotics.stackexchange.com',\n","       'rpg.stackexchange.com', 'salesforce.stackexchange.com',\n","       'scifi.stackexchange.com', 'security.stackexchange.com',\n","       'serverfault.com', 'sharepoint.stackexchange.com',\n","       'softwarerecs.stackexchange.com', 'stackoverflow.com',\n","       'stats.stackexchange.com', 'superuser.com',\n","       'tex.stackexchange.com', 'travel.stackexchange.com',\n","       'unix.stackexchange.com', 'ux.stackexchange.com',\n","       'webapps.stackexchange.com', 'webmasters.stackexchange.com',\n","       'wordpress.stackexchange.com']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9n1Kfav6hTb-","colab_type":"text"},"source":["## 前処理関数"]},{"cell_type":"code","metadata":{"id":"_gIBKSsChSiv","colab_type":"code","colab":{}},"source":["def preprocessing_df(df, train=True, vectolizer=[]):\n","  ################\n","  # cleaning\n","  ################\n","  df['question_title'] = df['question_title'].apply(lambda x : preprocessing(x))\n","  df['question_body'] = df['question_body'].apply(lambda x : preprocessing(x))\n","  df['answer'] = df['answer'].apply(lambda x : preprocessing(x))\n","  \n","  ################\n","  # label encode\n","  ################\n","  le_category = LabelEncoder()\n","  le_category.fit(category_list)\n","  for c in set(df.category):\n","      if c not in category_list:\n","          df.category = df.category.replace(c, np.nan)\n","          df.category = df.category.fillna(train.category.mode()[0])\n","  df.category = le_category.transform(df.category)\n","\n","  \n","  le_host = LabelEncoder()\n","  le_host.fit(host_list)\n","  for c in set(df.host):\n","      if c not in host_list:\n","          df.host = df.host.replace(c, np.nan)\n","          df.host = df.host.fillna(train.host.mode()[0])\n","  df.host = le_host.transform(df.host)\n","\n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUfGrJ5rNs2F","colab_type":"text"},"source":["## DataAugumentation\n","- どの程度の割合で、行うか？\n","- 基本的に、ラベルは変えたくないので、意味合いを変えないようにAugmetationしたい\n","- 全てを水増しすると、データが単純に倍になってしまうので、ある程度ランダムにいくつかだけ増やすもしくは変える、変えない"]},{"cell_type":"code","metadata":{"id":"MVWK_iK-Ns2I","colab_type":"code","colab":{}},"source":["#BERT Augmentator\n","aug_bert = naw.ContextualWordEmbsAug(\n","    #model_path=BERT_DIR+'/bert-base-uncased',\n","    model_path='bert-base-uncased',\n","    device='cuda',\n","    action='insert', #\"substitute\"\n","    aug_p=0.3, # 含まれているwordsの中の何割を変換するか\n","    temperature=0.3 , # 変換を施すかどうかの確率\n","    top_k=10)\n","\n","# text = 'The quick brown fox jumps over the lazy dog .'\n","# print(\"original: \\n\", text)\n","# for _ in range(10):\n","#     augmented_text = aug_bert.augment(text)\n","#     print(augmented_text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgJ4S49Ryoji","colab_type":"code","colab":{}},"source":["aug_bert.augment(train.question_title[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"taAZm0KLyoR-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4Hmt5EWyoGJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWb3DjY_yIr2","colab_type":"code","colab":{}},"source":["import nltk\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jurPJ7Y_Ns2T","colab_type":"code","colab":{}},"source":["# 上位語や下位語で、文字が置換\n","aug_syn = naw.SynonymAug(\n","    aug_src='wordnet', \n","    aug_p=0.3, \n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qe1o4mioNs2c","colab_type":"text"},"source":["## Word Embedding\n","- BERTのtokenizerで、単語は番号付け\n","- 学習済み単語のembeddingと、Tokenizerの番号の対応づけを行う"]},{"cell_type":"code","metadata":{"id":"o-2s-PDuNs2f","colab_type":"code","colab":{}},"source":["def get_coefs(word, *arr):\n","    return word, np.asarray(arr, dtype='float32')\n","\n","def load_embeddings(path):\n","    with open(path, encoding='utf-8') as f:\n","        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n","\n","def build_matrix(word_index, path):\n","    embedding_index = load_embeddings(path)\n","    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n","    unknown_words = []\n","    \n","    for word, i in word_index.items():\n","        try:\n","            embedding_matrix[i] = embedding_index[word]\n","        except KeyError:\n","            unknown_words.append(word)\n","    return embedding_matrix, unknown_words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YI7_8oQ-Ns2n","colab_type":"code","colab":{}},"source":["#Tokenizer = BertTokenizer.from_pretrained(BERT_DIR+'/bert-base-uncased')\n","#Tokenizer = BertTokenizer.from_pretrained('../input/bert-base-uncased/')\n","#Tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokneizerの学習\n","Tokenizer = keras.preprocessing.text.Tokenizer(filters='', lower=False)\n","Tokenizer.fit_on_texts(list(train.question_title) + list(train.question_body) + list(train.answer) \\\n","                        + list(test.question_title) + list(test.question_body) + list(test.answer))\n","\n","import pickle\n","savedir = '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/tokenizer/'\n","os.makedirs(savedir, exist_ok=True)\n","\n","# saving\n","with open(savedir+'tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(Tokenizer, handle)\n","\n","# # loading\n","# with open(savedir+'tokenizer.pickle, 'rb') as handle:\n","#     Tokenizer = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHMJv0n6Ns3V","colab_type":"code","colab":{}},"source":["# crawl_matrix, unknown_words_crawl = build_matrix(Tokenizer.word_index, CRAWL_EMBEDDING_PATH)\n","# print('n unknown words (crawl): ', len(unknown_words_crawl))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xe8ci3KiNs3i","colab_type":"code","colab":{}},"source":["glove_matrix, unknown_words_glove = build_matrix(Tokenizer.word_index, GLOVE_EMBEDDING_PATH)\n","print('n unknown words (glove): ', len(unknown_words_glove))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPZy6X7_Ns35","colab_type":"code","colab":{}},"source":["embedding_matrix = glove_matrix # + crawl_matrix   \n","embedding_matrix.shape\n","\n","#del crawl_matrix\n","del glove_matrix\n","gc.collect()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aeGrWNVcNs4G","colab_type":"text"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"iVHefDOhNs4I","colab_type":"code","colab":{}},"source":["MAX_T_LEN = 17\n","MAX_Q_LEN = 200\n","MAX_A_LEN = 300\n","\n","class QuestDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, train_mode=True, labeled=True):\n","        self.df = df\n","        self.train_mode = train_mode\n","        self.labeled = labeled\n","        self.tokenizer = Tokenizer\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        token_id列\n","        segment_id列\n","        label列\n","        \"\"\"\n","        row = self.df.iloc[index]\n","\n","        question_title = self.tokenizer.texts_to_sequences([row.question_title])\n","        question_body = self.tokenizer.texts_to_sequences([row.question_body])\n","        answer = self.tokenizer.texts_to_sequences([row.answer])\n","\n","        question_title = pad_sequences(question_title, maxlen=MAX_T_LEN, padding='post')\n","        question_body = pad_sequences(question_body, maxlen=MAX_Q_LEN, padding='post')\n","        answer = pad_sequences(answer, maxlen=MAX_A_LEN, padding='post')\n","     \n","        if self.labeled:\n","            labels = self.get_label(row)\n","            return torch.tensor(question_title, dtype=torch.long).squeeze(), torch.tensor(question_body, dtype=torch.long).squeeze(), torch.tensor(answer, dtype=torch.long).squeeze(), torch.tensor(row.category, dtype=torch.long), torch.tensor(row.host, dtype=torch.long), labels\n","        else:\n","            return torch.tensor(question_title, dtype=torch.long).squeeze(), torch.tensor(question_body, dtype=torch.long).squeeze(), torch.tensor(answer, dtype=torch.long).squeeze(), torch.tensor(row.category, dtype=torch.long), torch.tensor(row.host, dtype=torch.long)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","\n","    def get_label(self, row):\n","        #print(row[target_columns].values)\n","        return torch.tensor(row[target_columns].values.astype(np.float32))\n","\n","    def collate_fn(self, batch):\n","        \"\"\"\n","        labelデータを持つモードと、ない完全な推論モードでは、batchのshapeが異なるので(labelが2番目の要素にあるなし)\n","        \"\"\"        \n","        question_title = torch.stack([x[0] for x in batch])\n","        question_body = torch.stack([x[1] for x in batch])\n","        answer = torch.stack([x[2] for x in batch])\n","        \n","        category = torch.stack([x[3] for x in batch])\n","        host = torch.stack([x[4] for x in batch])\n","    \n","        if self.labeled:\n","            labels = torch.stack([x[-1] for x in batch])\n","            return question_title, question_body, answer, category, host, labels\n","        else:\n","            return question_title, question_body, answer, category, host"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SP7OU9XHNs4P","colab_type":"code","colab":{}},"source":["def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0):\n","    df = pd.read_csv(f'{DATA_DIR}/train.csv')\n","        \n","    df = preprocessing_df(df)\n","    \n","    df = shuffle(df, random_state=1234)\n","    gkf = GroupKFold(n_splits=5).split(X=df.question_body, groups=df.question_body)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf):\n","        if fold == ifold:\n","            df_train = df.iloc[train_idx]\n","            df_val = df.iloc[valid_idx]\n","            break\n","\n","    print('train', df_train.shape)\n","    print('val', df_val.shape)\n","\n","    ds_train = QuestDataset(df_train, train_mode=True)\n","    train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=ds_train.collate_fn, drop_last=True)\n","    train_loader.num = len(df_train)\n","\n","    ds_val = QuestDataset(df_val, train_mode=False)\n","    val_loader = torch.utils.data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=0, collate_fn=ds_val.collate_fn, drop_last=False)\n","    val_loader.num = len(df_val)\n","    val_loader.df = df_val\n","\n","    return train_loader, val_loader, df_val.shape[0], valid_idx\n","\n","\n","def get_test_loader(batch_size=4):\n","    df = pd.read_csv(f'{DATA_DIR}/test.csv')\n","    \n","    df = preprocessing_df(df)\n","    \n","    ds_test = QuestDataset(df, train_mode=False, labeled=False)\n","    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=ds_test.collate_fn, drop_last=False)\n","    loader.num = len(df)\n","    \n","    return loader\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmEUraCNNs4W","colab_type":"code","colab":{}},"source":["class SpatialDropout(nn.Dropout2d):\n","    def forward(self, x):\n","        x = x.unsqueeze(2)    # (N, T, 1, K)\n","        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n","        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n","        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n","        x = x.squeeze(2)  # (N, T, K)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftN9RstMNs4c","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","\n","        self.supports_masking = True\n","        self.bias = bias\n","        self.feature_dim = feature_dim\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","\n","        weight = torch.zeros(feature_dim, 1)\n","        nn.init.xavier_uniform_(weight)\n","        self.weight = nn.Parameter(weight)\n","\n","        if bias:\n","            self.b = nn.Parameter(torch.zeros(1))\n","\n","    def forward(self, x, mask=None):\n","\n","        feature_dim = self.feature_dim\n","        step_dim = self.step_dim\n","\n","        eij = torch.mm(\n","            x.contiguous().view(-1, feature_dim), \n","            self.weight\n","        ).view(-1, step_dim)\n","\n","        if self.bias:\n","            eij = eij + self.b\n","\n","        eij = torch.tanh(eij)\n","        a = torch.exp(eij)\n","\n","        if mask is not None:\n","            a = a * mask\n","\n","        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n","\n","        weighted_input = x * torch.unsqueeze(a, -1)\n","        return torch.sum(weighted_input, 1)\n","\n","class SpatialDropout(nn.Module):\n","    def __init__(self,p):\n","        super(SpatialDropout, self).__init__()\n","        self.dropout = nn.Dropout2d(p)\n","        \n","    def forward(self, x):\n","        x = x.permute(0, 2, 1)   # convert to [batch, feature, timestep]\n","        x = self.dropout(x)\n","        x = x.permute(0, 2, 1)   # back to [batch, timestep, feature]\n","        return x\n","\n","class LSTM_Model(nn.Module):\n","    def __init__(self, embedding_matrix, hidden_unit=256, num_layer=1, emb_category=3, emb_host=10):\n","        super(LSTM_Model, self).__init__()\n","        self.num_words = embedding_matrix.shape[0]\n","        self.embedding_size = embedding_matrix.shape[1]\n","      \n","        self.embedding_body = nn.Embedding(self.num_words, self.embedding_size)\n","        self.embedding_body.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding_body.weight.required_grad = False\n","        \n","        self.embedding_answer = nn.Embedding(self.num_words, self.embedding_size)\n","        self.embedding_answer.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding_answer.weight.required_grad = False\n","        \n","        self.embedding_title = nn.Embedding(self.num_words, self.embedding_size)\n","        self.embedding_title.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding_title.weight.required_grad = False\n","        \n","        self.embedding_dropout = SpatialDropout(0.4)\n","        \n","        self.lstm1_body = nn.LSTM(self.embedding_size, hidden_unit, num_layers=num_layer, bidirectional=True, batch_first=True)\n","        self.lstm2_body = nn.LSTM(hidden_unit*2, int(hidden_unit/2), num_layers=num_layer, bidirectional=True, batch_first=True)\n","        \n","        self.lstm1_answer = nn.LSTM(self.embedding_size, hidden_unit, num_layers=num_layer, bidirectional=True, batch_first=True)\n","        self.lstm2_answer = nn.LSTM(hidden_unit*2, int(hidden_unit/2), num_layers=num_layer, bidirectional=True, batch_first=True)\n","        \n","        self.lstm1_title = nn.LSTM(self.embedding_size, hidden_unit, num_layers=num_layer, bidirectional=True, batch_first=True)\n","        self.lstm2_title = nn.LSTM(hidden_unit*2, int(hidden_unit/2), num_layers=num_layer, bidirectional=True, batch_first=True)\n","        \n","        self.attention_body = Attention(hidden_unit, MAX_Q_LEN)\n","        self.attention_answer = Attention(hidden_unit, MAX_A_LEN)\n","        self.attention_title = Attention(hidden_unit, MAX_T_LEN)\n","        \n","        self.category = nn.Embedding(len(category_list), emb_category)\n","        self.host = nn.Embedding(len(host_list), emb_host)\n","        \n","        self.linear_title = nn.Linear(hidden_unit*3, hidden_unit)\n","        self.linear_body = nn.Linear(hidden_unit*3, hidden_unit)\n","        self.linear_answer = nn.Linear(hidden_unit*3, hidden_unit)\n","        \n","        \n","        self.linear_q = nn.Linear(hidden_unit*2+emb_category+emb_host, hidden_unit)\n","        self.linear_a = nn.Linear(hidden_unit+emb_category+emb_host, hidden_unit)\n","\n","        self.linear_q_out = nn.Linear(hidden_unit, hidden_unit//2)\n","        self.linear_a_out = nn.Linear(hidden_unit, hidden_unit//2)\n","\n","        self.linear_out = nn.Linear(hidden_unit, 30)\n","        \n","    def forward(self, title, body, answer, category, host):\n","        \n","        x_body = self.embedding_dropout(self.embedding_body(body))\n","        h_lstm1_body, _ = self.lstm1_body(x_body)\n","        h_lstm2_body, _ = self.lstm2_body(h_lstm1_body)\n","        \n","        x_answer = self.embedding_dropout(self.embedding_answer(answer))\n","        h_lstm1_answer, _ = self.lstm1_answer(x_answer)\n","        h_lstm2_answer, _ = self.lstm2_answer(h_lstm1_answer)\n","        \n","        x_title = self.embedding_dropout(self.embedding_title(title))\n","        h_lstm1_title, _ = self.lstm1_title(x_title)\n","        h_lstm2_title, _ = self.lstm2_title(h_lstm1_title)\n","        \n","        # print(h_lstm1_body.size())\n","        # print(h_lstm2_body.size())\n","\n","        att_body = self.attention_body(h_lstm2_body)\n","        att_answer = self.attention_answer(h_lstm2_answer)\n","        att_title = self.attention_title(h_lstm2_title)\n","        \n","        avg_pool_body = torch.mean(h_lstm2_body, 1)\n","        max_pool_body, _ = torch.max(h_lstm2_body, 1)\n","        \n","        avg_pool_answer = torch.mean(h_lstm2_answer, 1)\n","        max_pool_answer, _ = torch.max(h_lstm2_answer, 1)\n","        \n","        avg_pool_title = torch.mean(h_lstm2_title, 1)\n","        max_pool_title, _ = torch.max(h_lstm2_title, 1)\n","        \n","        body_cat = torch.cat((att_body, avg_pool_body, max_pool_body), 1)\n","        answer_cat = torch.cat((att_answer, avg_pool_answer, max_pool_answer), 1)\n","        title_cat = torch.cat((att_title, avg_pool_title, max_pool_title), 1)\n","        \n","        # print(body_cat.size())\n","        # print(answer_cat.size())\n","        # print(title_cat.size())\n","\n","        category = self.category(category)\n","        host = self.host(host)\n","        \n","        \n","        body_cat = torch.relu(self.linear_body(body_cat))\n","        answer_cat = torch.relu(self.linear_answer(answer_cat))\n","        title_cat = torch.relu(self.linear_title(title_cat))\n","\n","        \n","        hidden_q = torch.relu(self.linear_q(torch.cat((title_cat, body_cat, category, host), 1)))\n","        hidden_a = torch.relu(self.linear_a(torch.cat((answer_cat, category, host), 1)))\n","                                          \n","        q_result = torch.relu(self.linear_q_out(hidden_q))\n","        a_result = torch.relu(self.linear_a_out(hidden_a))\n","        \n","        out = torch.cat([q_result, a_result], 1)\n","        out = self.linear_out(out)\n","  \n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaiLcWO3Ns4o","colab_type":"code","colab":{}},"source":["def train_model(train_loader, optimizer, criterion, scheduler):\n","    model.train()\n","    avg_loss = 0.    \n","    for idx, batch in enumerate(tqdm(train_loader)):\n","        t_train, q_train, a_train, category_train, host_train, labels_train = batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device), batch[5].to(device)\n","        \n","        logits = model(t_train, q_train, a_train, category_train, host_train)        \n","        loss = config.question_weight*criterion(logits[:,0:21], labels_train[:,0:21]) + config.answer_weight*criterion(logits[:,21:30], labels_train[:,21:30])        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        \n","        avg_loss += loss.item() / len(train_loader)\n","        del t_train, q_train, a_train, category_train, host_train, labels_train\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    return avg_loss\n","\n","def val_model(val_loader, val_length, batch_size=8):\n","    model.eval() # eval mode  \n","    avg_val_loss = 0.\n","    \n","    valid_preds = np.zeros((val_length, len(target_columns)))\n","    original = np.zeros((val_length, len(target_columns)))\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(tqdm(val_loader)):\n","            t_val, q_val, a_val, category_val, host_val, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device), batch[5].to(device)\n","            \n","            logits = model(t_val, q_val, a_val, category_val, host_val)\n","            \n","            avg_val_loss += criterion(logits, labels).item() / len(val_loader)\n","            valid_preds[idx*batch_size : (idx+1)*batch_size] = torch.sigmoid(logits).detach().cpu().squeeze().numpy()\n","            original[idx*batch_size : (idx+1)*batch_size]    = labels.detach().cpu().squeeze().numpy()\n","        \n","        score = 0\n","        preds = torch.tensor(valid_preds).numpy()\n","        #preds = torch.sigmoid(torch.tensor(valid_preds)).numpy()\n","        \n","        rho_val = np.mean([spearmanr(original[:, i], preds[:,i]).correlation for i in range(preds.shape[1])])\n","        print('\\r val_spearman-rho: %s' % (str(round(rho_val, 5))), end = 100*' '+'\\n')\n","        \n","        for i in range(len(target_columns)):\n","            print(i, spearmanr(original[:,i], preds[:,i]))\n","            score += np.nan_to_num(spearmanr(original[:, i], preds[:, i]).correlation)\n","    \n","    return avg_val_loss, score/len(target_columns), preds, original"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTqclAv1Ns4x","colab_type":"code","colab":{}},"source":["def calc_spearman(preds, targets):\n","    score = 0\n","    for i in range(targets.shape[1]):\n","        score += np.nan_to_num(spearmanr(targets[:, i], preds[:, i]).correlation)\n","    return score/targets.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJaKhvpGNs45","colab_type":"code","colab":{}},"source":["ACCUM_STEPS = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"oJXzvuMiNs5A","colab_type":"code","colab":{}},"source":["model = LSTM_Model(embedding_matrix=embedding_matrix, hidden_unit=256).to(device)\n","#optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, eps=4e-5)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","#criterion = nn.MSELoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"65sED6lTNs5J","colab_type":"code","colab":{}},"source":["oof = np.zeros((train.shape[0], len(target_columns)))\n","targets = np.zeros((train.shape[0], len(target_columns)))\n","for fold in range(config.fold):\n","    print('---%d-Fold---'%(fold+1))\n","    \n","    patience = 0\n","    best_loss   = 100.0\n","    best_score      = -1.\n","    best_preds = 0\n","    best_param_loss = None\n","    best_param_score = None\n","    \n","    for epoch in range(config.epochs):\n","        \n","        torch.cuda.empty_cache()\n","        start_time   = time.time()\n","        \n","        train_loader, val_loader, val_length, val_idx = get_train_val_loaders(batch_size=config.batch_size, val_batch_size=config.batch_size, ifold=fold)\n","        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps= config.epochs*len(train_loader)//ACCUM_STEPS)\n","        \n","        loss_train = train_model(train_loader, optimizer, criterion, scheduler)\n","        loss_val, score_val, preds, original = val_model(val_loader, val_length, batch_size=config.batch_size)\n","        print(f'Epoch {(epoch+1)}, train_loss: {loss_train}, val_loss: {loss_val}, score_val: {score_val}, time: {(time.time()-start_time)}')\n","        \n","\n","        if score_val > best_score:\n","            best_score = score_val\n","            best_param_score = model.state_dict()\n","            best_preds = preds.copy()\n","            print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n","            torch.save(best_param_score, '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n","        else:\n","            patience += 1\n","            if patience >= config.patience:\n","                del train_loader, val_loader, loss_train, loss_val, score_val, preds\n","                torch.cuda.empty_cache()\n","                gc.collect()\n","                break\n","    \n","        del train_loader, val_loader, loss_train, loss_val, score_val, preds\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        \n","    model.load_state_dict(best_param_score)\n","    print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n","    torch.save(best_param_score, '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/best_param_score_{}_{}.pt'.format(config.name ,fold+1))   \n","    oof[val_idx] = best_preds\n","    targets[val_idx] = original\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","cv_score = calc_spearman(oof, targets)\n","print(cv_score)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aOOdTKUgNs5R","colab_type":"text"},"source":["## Practice"]},{"cell_type":"code","metadata":{"id":"Bs-OfqtpZoKj","colab_type":"code","colab":{}},"source":["import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-rN4R9QQZrer","colab_type":"code","colab":{}},"source":["samples = ['I like an apple.', 'My favorite food is banana.']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yldJHHGyZ1q9","colab_type":"code","colab":{}},"source":["tokenizer = keras.preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts(samples)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FraQQ_ZsaIMe","colab_type":"code","colab":{}},"source":["tokenizer.texts_to_sequences(samples)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIPp8uL_aN-M","colab_type":"code","colab":{}},"source":["# 訓練で含まれていないwordは無視される\n","samples2 = ['You like an apple.', 'Your favorite food is banana.']\n","tokenizer.texts_to_sequences(samples2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYWgBkWraYXw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}