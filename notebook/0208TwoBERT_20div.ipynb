{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "0208TwoBERT_20div.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6T6HUtB5eorj",
        "outputId": "1e0873d5-0c0f-4e0e-f2bd-7fed999edb66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fhYQVdgEwuRZ"
      },
      "source": [
        "## やったこと\n",
        "\n",
        "- テキストのクリーニング処理 -> 改善\n",
        "- host, categoryのカテゴリカル変数をエンベディングして入力 -> 改善\n",
        "\n",
        "- epochs=20で、early-stoppingはあまり良くならなかった -> とりあえず速く数を回したいので、epochs=4でやっている\n",
        "\n",
        "\n",
        "- batch_size=8以上にすると、out_of_memoryになる\n",
        "\n",
        "- MSELossを使用 -> 悪化\n",
        "- titleは分けて、別のエンベディングとして入力 -> 悪化\n",
        "\n",
        "\n",
        "\n",
        "- BERTを2つ使う -> gpu不足\n",
        "- クラス分類問題にする（30*num_class） -> 学習が安定しない（nan）\n",
        "- 30個の目的変数それぞれ独立に予測するモデル -> 約30時間必要、あまり精度が出ないように見える -> 関連する目的変数だけをグルーピングしてモデルを分ける必要？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uvK9IDYaOP_b",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys, gc, random, multiprocessing, glob, time\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/google-quest-challenge'\n",
        "# DATA_DIR = '../input/google-quest-challenge'\n",
        "# DATA_DIR = 'D:/project/ICF_AutoCapsule_disabled/kaggle/google-quest-challenge'\n",
        "# BERT_DIR = 'D:/project/ICF_AutoCapsule_disabled/BERT'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4jYDD13OP_o",
        "colab": {}
      },
      "source": [
        "# !pip install ../input/sacremoses/sacremoses-master/\n",
        "# !pip install ../input/transformers/transformers-master/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xst4_Y1Xer4Y",
        "outputId": "7f32dcb0-7770-4537-d061-ffaa929d695a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install flashtext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: flashtext in /usr/local/lib/python3.6/dist-packages (2.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OW9r1DNjOP_z",
        "outputId": "4fb48361-4075-48ec-8d6a-9eb77762cf8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#from ml_stratifiers import MultilabelStratifiedShuffleSplit, MultilabelStratifiedKFold\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
        "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
        "    get_cosine_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "from tqdm import tqdm\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQsu1MpOOQAA",
        "colab": {}
      },
      "source": [
        "## Make results reproducible .Else noone will believe you .\n",
        "import random\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kegkamk4OQAO",
        "colab": {}
      },
      "source": [
        "class PipeLineConfig:\n",
        "    def __init__(self, lr, warmup, epochs, patience, batch_size, seed, name, question_weight,answer_weight,fold,train):\n",
        "        self.lr = lr\n",
        "        self.warmup = warmup\n",
        "        self.epochs = epochs\n",
        "        self.patience = patience\n",
        "        self.batch_size = batch_size\n",
        "        self.seed = seed\n",
        "        self.name = name\n",
        "        self.question_weight = question_weight\n",
        "        self.answer_weight =answer_weight\n",
        "        self.fold = fold\n",
        "        self.train = train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IBzmdbwYOQAY",
        "colab": {}
      },
      "source": [
        "config = PipeLineConfig(lr=1e-5, \\\n",
        "                        warmup=0.01, \\\n",
        "                        epochs=4, \\\n",
        "                        patience=3, \\\n",
        "                        batch_size=4, \\\n",
        "                        seed=42, \\\n",
        "                        name='twoBERT', \\\n",
        "                        question_weight=0.5, \\\n",
        "                        answer_weight=0.5, \\\n",
        "                        fold=5, \\\n",
        "                        train=True\n",
        "                       )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nBjN2cdKOQAh",
        "colab": {}
      },
      "source": [
        "seed_everything(config.seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DjOYABYwOQAr",
        "outputId": "a001d220-f05d-4296-c3d2-bda4e24f3156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#device = 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RrECgPr6OQA4",
        "outputId": "0e4cf69c-858d-4d6e-c1f3-1e77d9d1d91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
        "sub.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_asker_intent_understanding</th>\n",
              "      <th>question_body_critical</th>\n",
              "      <th>question_conversational</th>\n",
              "      <th>question_expect_short_answer</th>\n",
              "      <th>question_fact_seeking</th>\n",
              "      <th>question_has_commonly_accepted_answer</th>\n",
              "      <th>question_interestingness_others</th>\n",
              "      <th>question_interestingness_self</th>\n",
              "      <th>question_multi_intent</th>\n",
              "      <th>question_not_really_a_question</th>\n",
              "      <th>question_opinion_seeking</th>\n",
              "      <th>question_type_choice</th>\n",
              "      <th>question_type_compare</th>\n",
              "      <th>question_type_consequence</th>\n",
              "      <th>question_type_definition</th>\n",
              "      <th>question_type_entity</th>\n",
              "      <th>question_type_instructions</th>\n",
              "      <th>question_type_procedure</th>\n",
              "      <th>question_type_reason_explanation</th>\n",
              "      <th>question_type_spelling</th>\n",
              "      <th>question_well_written</th>\n",
              "      <th>answer_helpful</th>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <th>answer_plausible</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <th>answer_well_written</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.00308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "      <td>0.00448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "      <td>0.00673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>132</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "      <td>0.01401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "      <td>0.02074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_id  ...  answer_well_written\n",
              "0     39  ...              0.00308\n",
              "1     46  ...              0.00448\n",
              "2     70  ...              0.00673\n",
              "3    132  ...              0.01401\n",
              "4    200  ...              0.02074\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FUZFPsyDOQBB",
        "outputId": "71c66361-4172-4a5e-91fa-f5365494cfaf",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "target_columns = sub.columns.values[1:].tolist()\n",
        "target_columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['question_asker_intent_understanding',\n",
              " 'question_body_critical',\n",
              " 'question_conversational',\n",
              " 'question_expect_short_answer',\n",
              " 'question_fact_seeking',\n",
              " 'question_has_commonly_accepted_answer',\n",
              " 'question_interestingness_others',\n",
              " 'question_interestingness_self',\n",
              " 'question_multi_intent',\n",
              " 'question_not_really_a_question',\n",
              " 'question_opinion_seeking',\n",
              " 'question_type_choice',\n",
              " 'question_type_compare',\n",
              " 'question_type_consequence',\n",
              " 'question_type_definition',\n",
              " 'question_type_entity',\n",
              " 'question_type_instructions',\n",
              " 'question_type_procedure',\n",
              " 'question_type_reason_explanation',\n",
              " 'question_type_spelling',\n",
              " 'question_well_written',\n",
              " 'answer_helpful',\n",
              " 'answer_level_of_information',\n",
              " 'answer_plausible',\n",
              " 'answer_relevance',\n",
              " 'answer_satisfaction',\n",
              " 'answer_type_instructions',\n",
              " 'answer_type_procedure',\n",
              " 'answer_type_reason_explanation',\n",
              " 'answer_well_written']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOiPYRDWOQBM",
        "outputId": "c5730f97-a16d-4284-ef9d-ccd4ff8f38ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>question_user_name</th>\n",
              "      <th>question_user_page</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_user_name</th>\n",
              "      <th>answer_user_page</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>host</th>\n",
              "      <th>question_asker_intent_understanding</th>\n",
              "      <th>question_body_critical</th>\n",
              "      <th>question_conversational</th>\n",
              "      <th>question_expect_short_answer</th>\n",
              "      <th>question_fact_seeking</th>\n",
              "      <th>question_has_commonly_accepted_answer</th>\n",
              "      <th>question_interestingness_others</th>\n",
              "      <th>question_interestingness_self</th>\n",
              "      <th>question_multi_intent</th>\n",
              "      <th>question_not_really_a_question</th>\n",
              "      <th>question_opinion_seeking</th>\n",
              "      <th>question_type_choice</th>\n",
              "      <th>question_type_compare</th>\n",
              "      <th>question_type_consequence</th>\n",
              "      <th>question_type_definition</th>\n",
              "      <th>question_type_entity</th>\n",
              "      <th>question_type_instructions</th>\n",
              "      <th>question_type_procedure</th>\n",
              "      <th>question_type_reason_explanation</th>\n",
              "      <th>question_type_spelling</th>\n",
              "      <th>question_well_written</th>\n",
              "      <th>answer_helpful</th>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <th>answer_plausible</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <th>answer_well_written</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What am I losing when using extension tubes in...</td>\n",
              "      <td>After playing around with macro photography on...</td>\n",
              "      <td>ysap</td>\n",
              "      <td>https://photo.stackexchange.com/users/1024</td>\n",
              "      <td>I just got extension tubes, so here's the skin...</td>\n",
              "      <td>rfusca</td>\n",
              "      <td>https://photo.stackexchange.com/users/1917</td>\n",
              "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>photo.stackexchange.com</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the distinction between a city and a s...</td>\n",
              "      <td>I am trying to understand what kinds of places...</td>\n",
              "      <td>russellpierce</td>\n",
              "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
              "      <td>It might be helpful to look into the definitio...</td>\n",
              "      <td>Erik Schmidt</td>\n",
              "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
              "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>rpg.stackexchange.com</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Maximum protusion length for through-hole comp...</td>\n",
              "      <td>I'm working on a PCB that has through-hole com...</td>\n",
              "      <td>Joe Baker</td>\n",
              "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
              "      <td>Do you even need grooves?  We make several pro...</td>\n",
              "      <td>Dwayne Reid</td>\n",
              "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
              "      <td>http://electronics.stackexchange.com/questions...</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>electronics.stackexchange.com</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Can an affidavit be used in Beit Din?</td>\n",
              "      <td>An affidavit, from what i understand, is basic...</td>\n",
              "      <td>Scimonster</td>\n",
              "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
              "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
              "      <td>Y     e     z</td>\n",
              "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
              "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>judaism.stackexchange.com</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How do you make a binary image in Photoshop?</td>\n",
              "      <td>I am trying to make a binary image. I want mor...</td>\n",
              "      <td>leigero</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
              "      <td>q2ra</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>graphicdesign.stackexchange.com</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_id  ... answer_well_written\n",
              "0      0  ...            1.000000\n",
              "1      1  ...            0.888889\n",
              "2      2  ...            0.888889\n",
              "3      3  ...            1.000000\n",
              "4      5  ...            1.000000\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "khOj2PbNOQBW",
        "outputId": "6d350cb2-ef3b-45ff-be26-c44a3ba94ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>question_user_name</th>\n",
              "      <th>question_user_page</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_user_name</th>\n",
              "      <th>answer_user_page</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>host</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>Will leaving corpses lying around upset my pri...</td>\n",
              "      <td>I see questions/information online about how t...</td>\n",
              "      <td>Dylan</td>\n",
              "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
              "      <td>There is no consequence for leaving corpses an...</td>\n",
              "      <td>Nelson868</td>\n",
              "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
              "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>gaming.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>Url link to feature image in the portfolio</td>\n",
              "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
              "      <td>Anu</td>\n",
              "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
              "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
              "      <td>Irina</td>\n",
              "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
              "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
              "      <td>TECHNOLOGY</td>\n",
              "      <td>wordpress.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
              "      <td>To experiment I started a bot game, toggled in...</td>\n",
              "      <td>Konsta</td>\n",
              "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
              "      <td>You do not have armour in the screenshots. Thi...</td>\n",
              "      <td>Damon Smithies</td>\n",
              "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
              "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>gaming.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>132</td>\n",
              "      <td>Suddenly got an I/O error from my external HDD</td>\n",
              "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
              "      <td>robbannn</td>\n",
              "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
              "      <td>Your Western Digital hard drive is disappearin...</td>\n",
              "      <td>HeatfanJohn</td>\n",
              "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
              "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
              "      <td>TECHNOLOGY</td>\n",
              "      <td>raspberrypi.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200</td>\n",
              "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
              "      <td>I have bought Delhi-London return flights for ...</td>\n",
              "      <td>Amit</td>\n",
              "      <td>https://travel.stackexchange.com/users/29089</td>\n",
              "      <td>I called two persons who work for Saudia (tick...</td>\n",
              "      <td>Nean Der Thal</td>\n",
              "      <td>https://travel.stackexchange.com/users/10051</td>\n",
              "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>travel.stackexchange.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_id  ...                           host\n",
              "0     39  ...       gaming.stackexchange.com\n",
              "1     46  ...    wordpress.stackexchange.com\n",
              "2     70  ...       gaming.stackexchange.com\n",
              "3    132  ...  raspberrypi.stackexchange.com\n",
              "4    200  ...       travel.stackexchange.com\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RUQkeCkGOQBi"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kw_iafZpOQBl",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from flashtext import KeywordProcessor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wf7fudYqOQBu",
        "colab": {}
      },
      "source": [
        "PUNCTS = {\n",
        "            '》', '〞', '¢', '‹', '╦', '║', '♪', 'Ø', '╩', '\\\\', '★', '＋', 'ï', '<', '?', '％', '+', '„', 'α', '*', '〰', '｟', '¹', '●', '〗', ']', '▾', '■', '〙', '↓', '´', '【', 'ᴵ',\n",
        "            '\"', '）', '｀', '│', '¤', '²', '‡', '¿', '–', '」', '╔', '〾', '%', '¾', '←', '〔', '＿', '’', '-', ':', '‧', '｛', 'β', '（', '─', 'à', 'â', '､', '•', '；', '☆', '／', 'π',\n",
        "            'é', '╗', '＾', '▪', ',', '►', '/', '〚', '¶', '♦', '™', '}', '″', '＂', '『', '▬', '±', '«', '“', '÷', '×', '^', '!', '╣', '▲', '・', '░', '′', '〝', '‛', '√', ';', '】', '▼',\n",
        "            '.', '~', '`', '。', 'ə', '］', '，', '{', '～', '！', '†', '‘', '﹏', '═', '｣', '〕', '〜', '＼', '▒', '＄', '♥', '〛', '≤', '∞', '_', '[', '＆', '→', '»', '－', '＝', '§', '⋅', \n",
        "            '▓', '&', 'Â', '＞', '〃', '|', '¦', '—', '╚', '〖', '―', '¸', '³', '®', '｠', '¨', '‟', '＊', '£', '#', 'Ã', \"'\", '▀', '·', '？', '、', '█', '”', '＃', '⊕', '=', '〟', '½', '』',\n",
        "            '［', '$', ')', 'θ', '@', '›', '＠', '｝', '¬', '…', '¼', '：', '¥', '❤', '€', '−', '＜', '(', '〘', '▄', '＇', '>', '₤', '₹', '∅', 'è', '〿', '「', '©', '｢', '∙', '°', '｜', '¡', \n",
        "            '↑', 'º', '¯', '♫', '#'\n",
        "          }\n",
        "\n",
        "\n",
        "mispell_dict = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\",\n",
        "\"couldnt\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n",
        "\"doesnt\" : \"does not\", \"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\", \"havent\" : \"have not\", \"he'd\" : \"he would\", \"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\", \"isn't\" : \"is not\", \"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \n",
        "\"shan't\" : \"shall not\", \"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"shouldnt\" : \"should not\",\n",
        "\"that's\" : \"that is\", \"thats\" : \"that is\", \"there's\" : \"there is\", \"theres\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\", \"theyre\":  \"they are\", \"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\", \"what'll\" : \"what will\", \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\", \"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\", \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\", \"won't\" : \"will not\", \"wouldn't\" : \"would not\", \"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\", \"you're\" : \"you are\", \"you've\" : \"you have\", \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\", \"tryin'\":\"trying\"}\n",
        "\n",
        "\n",
        "kp = KeywordProcessor(case_sensitive=True)\n",
        "for k, v in mispell_dict.items():\n",
        "    kp.add_keyword(k, v)\n",
        "\n",
        "def clean_punct(text):\n",
        "    text = str(text)\n",
        "    for punct in PUNCTS:\n",
        "        text = text.replace(punct, ' {} '.format(punct))\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'(\\&lt)|(\\&gt)', ' ', text)\n",
        "    \n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' url ', text)\n",
        "    text = kp.replace_keywords(text)\n",
        "    text = clean_punct(text)\n",
        "    text = re.sub(r'\\n\\r', ' ', text)\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VLL4EgrdOQCV"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uIq3tUBmjATF",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "class QuestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, train_mode=True, labeled=True):\n",
        "        self.df = df\n",
        "        self.train_mode = train_mode\n",
        "        self.labeled = labeled\n",
        "        #self.tokenizer = BertTokenizer.from_pretrained(BERT_DIR+'/bert-base-uncased')\n",
        "        #self.tokenizer = BertTokenizer.from_pretrained('../input/bert-base-uncased/')\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "\n",
        "        question_title = row.question_title\n",
        "        question_body = row.question_body\n",
        "        answer_text = row.answer\n",
        "\n",
        "\n",
        "        inputs_q = self.tokenizer.encode_plus(\n",
        "            question_title + \" \" + question_body,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "        )\n",
        "\n",
        "        inputs_a = self.tokenizer.encode_plus(\n",
        "            answer_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "        )\n",
        "\n",
        "        ids_q = inputs_q[\"input_ids\"]\n",
        "        token_type_ids_q = inputs_q[\"token_type_ids\"]\n",
        "        mask_q = inputs_q[\"attention_mask\"]\n",
        "\n",
        "        ids_a = inputs_a[\"input_ids\"]\n",
        "        token_type_ids_a = inputs_a[\"token_type_ids\"]\n",
        "        mask_a = inputs_a[\"attention_mask\"]\n",
        "        \n",
        "        padding_length_q = MAX_LEN - len(ids_q)\n",
        "        padding_length_a = MAX_LEN - len(ids_a)\n",
        "        \n",
        "        ids_q = ids_q + ([0] * padding_length_q)\n",
        "        mask_q = mask_q + ([0] * padding_length_q)\n",
        "        token_type_ids_q = token_type_ids_q + ([0] * padding_length_q)\n",
        "\n",
        "        ids_a = ids_a + ([0] * padding_length_a)\n",
        "        mask_a = mask_a + ([0] * padding_length_a)\n",
        "        token_type_ids_a = token_type_ids_a + ([0] * padding_length_a)\n",
        "        \n",
        "        if self.labeled:\n",
        "            labels = self.get_label(row)\n",
        "            return {\n",
        "                'ids_q': torch.tensor(ids_q, dtype=torch.long),\n",
        "                'mask_q': torch.tensor(mask_q, dtype=torch.long),\n",
        "                'token_type_ids_q': torch.tensor(token_type_ids_q, dtype=torch.long),\n",
        "                'ids_a': torch.tensor(ids_a, dtype=torch.long),\n",
        "                'mask_a': torch.tensor(mask_a, dtype=torch.long),\n",
        "                'token_type_ids_a': torch.tensor(token_type_ids_a, dtype=torch.long),\n",
        "                'labels': labels, \n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'ids_q': torch.tensor(ids_q, dtype=torch.long),\n",
        "                'mask_q': torch.tensor(mask_q, dtype=torch.long),\n",
        "                'token_type_ids_q': torch.tensor(token_type_ids_q, dtype=torch.long),\n",
        "                'ids_a': torch.tensor(ids_a, dtype=torch.long),\n",
        "                'mask_a': torch.tensor(mask_a, dtype=torch.long),\n",
        "                'token_type_ids_a': torch.tensor(token_type_ids_a, dtype=torch.long)\n",
        "            }\n",
        "\n",
        "\n",
        "    def get_label(self, row):\n",
        "        return torch.tensor(row[target_columns].values.astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NXBQo6aOQCc",
        "colab": {}
      },
      "source": [
        "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0):\n",
        "    df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
        "\n",
        "    # cleaning\n",
        "    df['question_title'] = df['question_title'].apply(lambda x : preprocessing(x))\n",
        "    df['question_body'] = df['question_body'].apply(lambda x : preprocessing(x))\n",
        "    df['answer'] = df['answer'].apply(lambda x : preprocessing(x))\n",
        "    \n",
        "\n",
        "    df = shuffle(df, random_state=1234)\n",
        "    gkf = GroupKFold(n_splits=5).split(X=df.question_body, groups=df.question_body)\n",
        "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "        if fold == ifold:\n",
        "            df_train = df.iloc[train_idx]\n",
        "            df_val = df.iloc[valid_idx]\n",
        "            break\n",
        "\n",
        "    print('train', df_train.shape)\n",
        "    print('val', df_val.shape)\n",
        "\n",
        "    ds_train = QuestDataset(df_train, train_mode=True)\n",
        "    train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
        "    train_loader.num = len(df_train)\n",
        "\n",
        "    ds_val = QuestDataset(df_val, train_mode=False)\n",
        "    val_loader = torch.utils.data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
        "    val_loader.num = len(df_val)\n",
        "    val_loader.df = df_val\n",
        "\n",
        "    return train_loader, val_loader, df_val.shape[0], valid_idx\n",
        "\n",
        "\n",
        "def get_test_loader(batch_size=4):\n",
        "    df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
        "\n",
        "    # cleaning\n",
        "    df['question_title'] = df['question_title'].apply(lambda x : preprocessing(x))\n",
        "    df['question_body'] = df['question_body'].apply(lambda x : preprocessing(x))\n",
        "    df['answer'] = df['answer'].apply(lambda x : preprocessing(x))\n",
        "    \n",
        "    ds_test = QuestDataset(df, train_mode=False, labeled=False)\n",
        "    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
        "    loader.num = len(df)\n",
        "    \n",
        "    return loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c7p98IBtOQCl",
        "colab": {}
      },
      "source": [
        "# class QuestModel(nn.Module):\n",
        "#     def __init__(self, n_classes=30):\n",
        "#         super(QuestModel, self).__init__()\n",
        "#         self.model_name = 'QuestModel'\n",
        "#         #self.bert_model = BertModel.from_pretrained(BERT_DIR+'/bert-base-uncased/')\n",
        "#         #self.bert_model = BertModel.from_pretrained('../input/bert-base-uncased/')\n",
        "#         self.bert_model_q = BertModel.from_pretrained('bert-base-uncased')\n",
        "#         self.bert_model_a = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#         # self.lstm_q = nn.LSTM(768, 300)\n",
        "#         # self.lstm_a = nn.LSTM(768, 300)\n",
        "        \n",
        "#         self.fc_q1 = nn.Linear(768*2, 12)\n",
        "#         self.fc_q2 = nn.Linear(768*2, 9)\n",
        "        \n",
        "#         self.fc_a = nn.Linear(768*2+21, 9)\n",
        "\n",
        "#     def forward(self, ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a):\n",
        "#         layers_q, pool_out_q = self.bert_model_q(input_ids=ids_q, token_type_ids=token_type_ids_q, attention_mask=mask_q)\n",
        "#         layers_a, pool_out_a = self.bert_model_a(input_ids=ids_a, token_type_ids=token_type_ids_a, attention_mask=mask_a)\n",
        "        \n",
        "#         # #print(layers_q.shape)\n",
        "#         # layers_q, _ = self.lstm_q(layers_q)\n",
        "#         # layers_a, _ = self.lstm_a(layers_a)\n",
        "\n",
        "#         #print(layers_q.shape)\n",
        "#         out_q = F.avg_pool1d(layers_q.transpose(1,2), kernel_size=layers_q.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "#         out_a = F.avg_pool1d(layers_a.transpose(1,2), kernel_size=layers_a.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "#         out = torch.cat([out_q, out_a], dim=-1)\n",
        "#         out = F.dropout(out, p=0.2, training=self.training)\n",
        "\n",
        "#         logit_q1 = self.fc_q1(out)\n",
        "#         logit_q2 = self.fc_q2(out)\n",
        "        \n",
        "#         out_a = torch.cat([out, F.relu(logit_q1)], dim=-1)\n",
        "#         out_a = torch.cat([out_a, F.relu(logit_q2)], dim=-1)\n",
        "#         logit_a = self.fc_a(out_a)\n",
        "\n",
        "#         logit = torch.cat([logit_q1, logit_q2], dim=-1)\n",
        "#         logit = torch.cat([logit, logit_a], dim=-1)\n",
        "\n",
        "#         logit = logit[:, [0,1,2,3,4,5,6,7,8,9,10,11,13,14,15,16,17,18,19,12,20,21,22,23,24,25,26,27,28,29]]\n",
        "\n",
        "#         return logit\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk8burR4Myhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification_v2(nn.Module):\n",
        "    r\"\"\"\n",
        "        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n",
        "    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "            Classification (or regression if config.num_labels==1) loss.\n",
        "        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n",
        "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
        "        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "            of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BertForSequenceClassification_v2, self).__init__()\n",
        "\n",
        "       # config.output_hidden_states=True (make sure)\n",
        "        self.num_labels = 30\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.classifier = nn.Linear(768, 30)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
        "            position_ids=None, head_mask=None, inputs_embeds=None, labels=None, \n",
        "            extra_feats=None):\n",
        "\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids,\n",
        "                            position_ids=position_ids,\n",
        "                            head_mask=head_mask,\n",
        "                            inputs_embeds=inputs_embeds)\n",
        "\n",
        "        # sequence_output = outputs[0]\n",
        "        # pooled_output = outputs[1]\n",
        "\n",
        "        hidden_states = outputs[2] #hidden_states: 12 layers tuples each is of (batch_size, sequence_length, hidden_size) + embedding``\n",
        "        # print(seq[-1].shape, seq[-1][:, 0].shape)\n",
        "\n",
        "        # we are taking zero because in my understanding that's the [CLS] token...\n",
        "        # idea is to pool last 4 layers as well instead of just the last one, since it's too close to the output\n",
        "        # layers, it might not be that efficient as it's more regulated by the o/p's..\n",
        "\n",
        "        h12 = hidden_states[-1][:, 0].reshape((-1, 1, 768))\n",
        "        h11 = hidden_states[-2][:, 0].reshape((-1, 1, 768))\n",
        "        h10 = hidden_states[-3][:, 0].reshape((-1, 1, 768))\n",
        "        h9  = hidden_states[-4][:, 0].reshape((-1, 1, 768))\n",
        "\n",
        "        all_h = torch.cat([h9, h10, h11, h12], 1) #Also don't forget to add the last CLS token seq_op/pooled_op as you wish..\n",
        "        mean_pool = torch.mean(all_h, 1)\n",
        "\n",
        "        pooled_output = self.dropout(mean_pool)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w99ePeh-uech",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuestModel(nn.Module):\n",
        "    def __init__(self, n_classes=30):\n",
        "        super(QuestModel, self).__init__()\n",
        "        self.model_name = 'QuestModel'\n",
        "        #self.bert_model = BertModel.from_pretrained(BERT_DIR+'/bert-base-uncased/')\n",
        "        #self.bert_model = BertModel.from_pretrained('../input/bert-base-uncased/')\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        self.fc_q = nn.Linear(768*20, 21)\n",
        "        self.fc_a = nn.Linear(768*20+21, 9)\n",
        "\n",
        "    def forward(self, ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a):\n",
        "        layers_q, pool_out_q = self.bert_model(input_ids=ids_q, token_type_ids=token_type_ids_q, attention_mask=mask_q)\n",
        "        layers_a, pool_out_a = self.bert_model(input_ids=ids_a, token_type_ids=token_type_ids_a, attention_mask=mask_a)\n",
        "        \n",
        "\n",
        "        # [batch_size, 512, 768]\n",
        "        layers_q1,layers_q2,layers_q3,layers_q4,layers_q5,layers_q6,layers_q7,layers_q8,layers_q9,layers_q10,layers_q11,layers_q12,layers_q13,layers_q14,layers_q15,layers_q16,layers_q17,layers_q18,layers_q19,layers_q20 = layers_q[:, :25, :], layers_q[:, 25:50, :], layers_q[:,50:75, :], layers_q[:, 75:100, :], layers_q[:, 125:150, :], layers_q[:, 150:175, :], layers_q[:, 175:200, :], layers_q[:, 200:225, :], layers_q[:, 225:250, :], layers_q[:, 250:275, :], layers_q[:, 275:300, :], layers_q[:, 300:325, :], layers_q[:, 325:350, :], layers_q[:, 350:375, :], layers_q[:, 375:400, :], layers_q[:, 400:425, :], layers_q[:, 425:450, :], layers_q[:, 450:475, :], layers_q[:, 475:500, :], layers_q[:, 500:512, :]\n",
        "        layers_a1,layers_a2,layers_a3,layers_a4,layers_a5,layers_a6,layers_a7,layers_a8,layers_a9,layers_a10,layers_a11,layers_a12,layers_a13,layers_a14,layers_a15,layers_a16,layers_a17,layers_a18,layers_a19,layers_a20 = layers_a[:, :25, :], layers_a[:, 25:50, :], layers_a[:,50:75, :], layers_a[:, 75:100, :], layers_a[:, 125:150, :], layers_a[:, 150:175, :], layers_a[:, 175:200, :], layers_a[:, 200:225, :], layers_a[:, 225:250, :], layers_a[:, 250:275, :], layers_a[:, 275:300, :], layers_a[:, 300:325, :], layers_a[:, 325:350, :], layers_a[:, 350:375, :], layers_a[:, 375:400, :], layers_a[:, 400:425, :], layers_a[:, 425:450, :], layers_a[:, 450:475, :], layers_a[:, 475:500, :], layers_a[:, 500:512, :]\n",
        "        out_q1 = F.avg_pool1d(layers_q1.transpose(1,2), kernel_size=layers_q1.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a1 = F.avg_pool1d(layers_a1.transpose(1,2), kernel_size=layers_a1.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q2 = F.avg_pool1d(layers_q2.transpose(1,2), kernel_size=layers_q2.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a2 = F.avg_pool1d(layers_a2.transpose(1,2), kernel_size=layers_a2.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q3 = F.avg_pool1d(layers_q3.transpose(1,2), kernel_size=layers_q3.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a3 = F.avg_pool1d(layers_a3.transpose(1,2), kernel_size=layers_a3.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q4 = F.avg_pool1d(layers_q4.transpose(1,2), kernel_size=layers_q4.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a4 = F.avg_pool1d(layers_a4.transpose(1,2), kernel_size=layers_a4.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q5 = F.avg_pool1d(layers_q5.transpose(1,2), kernel_size=layers_q5.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a5 = F.avg_pool1d(layers_a5.transpose(1,2), kernel_size=layers_a5.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q6 = F.avg_pool1d(layers_q6.transpose(1,2), kernel_size=layers_q6.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a6 = F.avg_pool1d(layers_a6.transpose(1,2), kernel_size=layers_a6.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q7 = F.avg_pool1d(layers_q7.transpose(1,2), kernel_size=layers_q7.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a7 = F.avg_pool1d(layers_a7.transpose(1,2), kernel_size=layers_a7.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q8 = F.avg_pool1d(layers_q8.transpose(1,2), kernel_size=layers_q8.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a8 = F.avg_pool1d(layers_a8.transpose(1,2), kernel_size=layers_a8.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q9 = F.avg_pool1d(layers_q9.transpose(1,2), kernel_size=layers_q9.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a9 = F.avg_pool1d(layers_a9.transpose(1,2), kernel_size=layers_a9.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q10 = F.avg_pool1d(layers_q10.transpose(1,2), kernel_size=layers_q10.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a10 = F.avg_pool1d(layers_a10.transpose(1,2), kernel_size=layers_a10.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q11 = F.avg_pool1d(layers_q11.transpose(1,2), kernel_size=layers_q11.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a11 = F.avg_pool1d(layers_a11.transpose(1,2), kernel_size=layers_a11.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q12 = F.avg_pool1d(layers_q12.transpose(1,2), kernel_size=layers_q12.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a12 = F.avg_pool1d(layers_a12.transpose(1,2), kernel_size=layers_a12.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q13 = F.avg_pool1d(layers_q13.transpose(1,2), kernel_size=layers_q13.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a13 = F.avg_pool1d(layers_a13.transpose(1,2), kernel_size=layers_a13.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q14 = F.avg_pool1d(layers_q14.transpose(1,2), kernel_size=layers_q14.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a14 = F.avg_pool1d(layers_a14.transpose(1,2), kernel_size=layers_a14.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q15 = F.avg_pool1d(layers_q15.transpose(1,2), kernel_size=layers_q15.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a15 = F.avg_pool1d(layers_a15.transpose(1,2), kernel_size=layers_a15.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q16 = F.avg_pool1d(layers_q16.transpose(1,2), kernel_size=layers_q16.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a16 = F.avg_pool1d(layers_a16.transpose(1,2), kernel_size=layers_a16.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q17 = F.avg_pool1d(layers_q17.transpose(1,2), kernel_size=layers_q17.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a17 = F.avg_pool1d(layers_a17.transpose(1,2), kernel_size=layers_a17.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q18 = F.avg_pool1d(layers_q18.transpose(1,2), kernel_size=layers_q18.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a18 = F.avg_pool1d(layers_a18.transpose(1,2), kernel_size=layers_a18.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q19 = F.avg_pool1d(layers_q19.transpose(1,2), kernel_size=layers_q19.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a19 = F.avg_pool1d(layers_a19.transpose(1,2), kernel_size=layers_a19.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_q20 = F.avg_pool1d(layers_q20.transpose(1,2), kernel_size=layers_q20.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "        out_a20 = F.avg_pool1d(layers_a20.transpose(1,2), kernel_size=layers_a20.size()[1]).squeeze()  # sequence方向は中央値だけ抽出\n",
        "\n",
        "        out_q = torch.cat([out_q1, out_q2], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q3], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q4], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q5], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q6], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q7], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q8], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q9], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q10], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q11], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q12], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q13], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q14], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q15], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q16], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q17], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q18], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q19], dim=-1)\n",
        "        out_q = torch.cat([out_q, out_q20], dim=-1)\n",
        "        out_q = F.dropout(out_q, p=0.4, training=self.training)\n",
        "        logit_q = self.fc_q(out_q)\n",
        "        \n",
        "\n",
        "        out_a = torch.cat([out_a1, out_a2], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a3], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a4], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a5], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a6], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a7], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a8], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a9], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a10], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a11], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a12], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a13], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a14], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a15], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a16], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a17], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a18], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a19], dim=-1)\n",
        "        out_a = torch.cat([out_a, out_a20], dim=-1)\n",
        "        out_a = F.dropout(out_a, p=0.4, training=self.training)\n",
        "        out_a = torch.cat([out_a, F.relu(logit_q)], dim=-1)\n",
        "        logit_a = self.fc_a(out_a)\n",
        "\n",
        "        logit = torch.cat([logit_q, logit_a], dim=-1)\n",
        "\n",
        "        return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ffu67MIrOQC4",
        "colab": {}
      },
      "source": [
        "def train_model(train_loader, optimizer, criterion, scheduler):\n",
        "    model.train()\n",
        "    avg_loss = 0.    \n",
        "    for idx, batch in enumerate(tqdm(train_loader)):\n",
        "        ids_q = batch['ids_q'].to(device)\n",
        "        mask_q = batch['mask_q'].to(device)\n",
        "        token_type_ids_q = batch['token_type_ids_q'].to(device)\n",
        "        ids_a = batch['ids_a'].to(device)\n",
        "        mask_a = batch['mask_a'].to(device)\n",
        "        token_type_ids_a = batch['token_type_ids_a'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        \n",
        "        logits = model(ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a)        \n",
        "        loss = criterion(logits, labels)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "        del ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a, labels\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return avg_loss\n",
        "\n",
        "def val_model(val_loader, val_length, batch_size=8):\n",
        "    model.eval() # eval mode  \n",
        "    avg_val_loss = 0.\n",
        "    \n",
        "    valid_preds = np.zeros((val_length, len(target_columns)))\n",
        "    original = np.zeros((val_length, len(target_columns)))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(tqdm(val_loader)):\n",
        "            ids_q = batch['ids_q'].to(device)\n",
        "            mask_q = batch['mask_q'].to(device)\n",
        "            token_type_ids_q = batch['token_type_ids_q'].to(device)\n",
        "            ids_a = batch['ids_a'].to(device)\n",
        "            mask_a = batch['mask_a'].to(device)\n",
        "            token_type_ids_a = batch['token_type_ids_a'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = torch.sigmoid(model(ids_q, mask_q, token_type_ids_q, ids_a, mask_a, token_type_ids_a))\n",
        "            \n",
        "            avg_val_loss += criterion(logits, labels).item() / len(val_loader)\n",
        "            valid_preds[idx*batch_size : (idx+1)*batch_size] = logits.detach().cpu().squeeze().numpy()\n",
        "            original[idx*batch_size : (idx+1)*batch_size]    = labels.detach().cpu().squeeze().numpy()\n",
        "        \n",
        "        rho_val = np.mean([spearmanr(original[:, i], valid_preds[:,i]).correlation for i in range(valid_preds.shape[1])])\n",
        "        print('\\r val_spearman-rho: %s' % (str(round(rho_val, 5))), end = 100*' '+'\\n')\n",
        "        \n",
        "        score = 0\n",
        "        for i in range(len(target_columns)):\n",
        "            print(i, spearmanr(original[:,i], valid_preds[:,i]))\n",
        "            score += np.nan_to_num(spearmanr(original[:, i], valid_preds[:, i]).correlation)\n",
        "    \n",
        "    return avg_val_loss, score/len(target_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xz4rSv7VOQDj",
        "outputId": "1bc769b0-86c2-47bc-ea63-9327e5a53115",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "cv_list = []\n",
        "for fold in range(config.fold):\n",
        "    print('---%d-Fold---'%(fold+1))\n",
        "    \n",
        "    patience = 0\n",
        "    best_loss   = 100.0\n",
        "    best_score      = -1.\n",
        "    best_preds = 0\n",
        "    best_param_loss = None\n",
        "    best_param_score = None\n",
        "\n",
        "    model = QuestModel(n_classes=30).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, eps=4e-5)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    for epoch in range(config.epochs):\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        start_time   = time.time()\n",
        "        \n",
        "        train_loader, val_loader, val_length, val_idx = get_train_val_loaders(batch_size=config.batch_size, val_batch_size=config.batch_size, ifold=fold)\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps=config.epochs*len(train_loader))\n",
        "        #scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps=config.epochs*len(train_loader))\n",
        "\n",
        "        loss_train = train_model(train_loader, optimizer, criterion, scheduler)\n",
        "        loss_val, score_val = val_model(val_loader, val_length, batch_size=config.batch_size)\n",
        "        print(f'Epoch {(epoch+1)}, train_loss: {loss_train}, val_loss: {loss_val}, score_val: {score_val}, time: {(time.time()-start_time)}')\n",
        "\n",
        "        if score_val > best_score:\n",
        "            best_score = score_val\n",
        "            best_param_score = model.state_dict()\n",
        "            print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
        "            torch.save(best_param_score, '/content/drive/My Drive/Colab Notebooks/GoogleQuest/best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= config.patience:\n",
        "                del train_loader, val_loader, loss_train, loss_val, score_val\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "                break\n",
        "    \n",
        "        del train_loader, val_loader, loss_train, loss_val, score_val\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        \n",
        "    model.load_state_dict(best_param_score)\n",
        "    print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
        "    torch.save(best_param_score, '/content/drive/My Drive/Colab Notebooks/GoogleQuest/best_param_score_{}_{}.pt'.format(config.name ,fold+1))   \n",
        "    cv_list.append(best_score)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "print('CV_score: ', np.mean(cv_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---1-Fold---\n",
            "train (4863, 41)\n",
            "val (1216, 41)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1215/1215 [19:58<00:00,  1.01it/s]\n",
            "100%|██████████| 304/304 [01:45<00:00,  2.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r val_spearman-rho: 0.38255                                                                                                    \n",
            "0 SpearmanrResult(correlation=0.3799048325364928, pvalue=4.882204998326703e-43)\n",
            "1 SpearmanrResult(correlation=0.6146067852446458, pvalue=3.2423200731762917e-127)\n",
            "2 SpearmanrResult(correlation=0.3971302872298802, pvalue=3.2611299192989267e-47)\n",
            "3 SpearmanrResult(correlation=0.26174830153552464, pvalue=1.6891982243085107e-20)\n",
            "4 SpearmanrResult(correlation=0.36986941798372375, pvalue=1.0187617586705217e-40)\n",
            "5 SpearmanrResult(correlation=0.38578860869164144, pvalue=1.9515920400596954e-44)\n",
            "6 SpearmanrResult(correlation=0.3165133599144484, pvalue=1.067740921666038e-29)\n",
            "7 SpearmanrResult(correlation=0.4292543253282772, pvalue=1.0904632661742551e-55)\n",
            "8 SpearmanrResult(correlation=0.5371094909264099, pvalue=8.015522084530773e-92)\n",
            "9 SpearmanrResult(correlation=0.08498262550999389, pvalue=0.00301932005198514)\n",
            "10 SpearmanrResult(correlation=0.4497550549378904, pvalue=1.3450510014123303e-61)\n",
            "11 SpearmanrResult(correlation=0.7242620778601188, pvalue=3.1556298371409157e-198)\n",
            "12 SpearmanrResult(correlation=0.3514499328701545, pvalue=1.1393717086811515e-36)\n",
            "13 SpearmanrResult(correlation=0.19021233166046408, pvalue=2.2740070520308188e-11)\n",
            "14 SpearmanrResult(correlation=0.3525220141906955, pvalue=6.733934091459752e-37)\n",
            "15 SpearmanrResult(correlation=0.44075330621827324, pvalue=5.932779427620326e-59)\n",
            "16 SpearmanrResult(correlation=0.7794063547910199, pvalue=8.824792664205477e-249)\n",
            "17 SpearmanrResult(correlation=0.3325963233312235, pvalue=8.529666027285312e-33)\n",
            "18 SpearmanrResult(correlation=0.6527629129476826, pvalue=1.4399940590945129e-148)\n",
            "19 SpearmanrResult(correlation=0.07923709750209502, pvalue=0.005699298864601436)\n",
            "20 SpearmanrResult(correlation=0.4991396537710878, pvalue=1.3323101458692875e-77)\n",
            "21 SpearmanrResult(correlation=0.16832010145542717, pvalue=3.5121800311812438e-09)\n",
            "22 SpearmanrResult(correlation=0.4172863345545351, pvalue=2.0123365314135368e-52)\n",
            "23 SpearmanrResult(correlation=0.07931467831345336, pvalue=0.005652040151690153)\n",
            "24 SpearmanrResult(correlation=0.11826530180861378, pvalue=3.5599564642507625e-05)\n",
            "25 SpearmanrResult(correlation=0.2929825185733332, pvalue=1.6983162397127875e-25)\n",
            "26 SpearmanrResult(correlation=0.7185460014901075, pvalue=1.0866347770382742e-193)\n",
            "27 SpearmanrResult(correlation=0.2336541257204878, pvalue=1.5327100577053615e-16)\n",
            "28 SpearmanrResult(correlation=0.625658149002294, pvalue=4.280547069313767e-133)\n",
            "29 SpearmanrResult(correlation=0.19346341501497819, pvalue=1.0193885820698222e-11)\n",
            "Epoch 1, train_loss: 0.3908941300072303, val_loss: 0.6164621036303674, score_val: 0.3825498573638325, time: 1311.8569722175598\n",
            "best_param_score_twoBERT_1.pt\n",
            "train (4863, 41)\n",
            "val (1216, 41)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 912/1215 [15:03<04:59,  1.01it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MpsndIInyZhd",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}