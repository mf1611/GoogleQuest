{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"0205_TFmodel","provenance":[{"file_id":"1DNFMRK9UQsAjXko7bJJZwUh_6niUSHcC","timestamp":1580120807522},{"file_id":"1-4bVyplvvSuyPB6-soncICDgu8K9Oi-6","timestamp":1579230557293}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6T6HUtB5eorj","colab_type":"code","outputId":"664258ea-6c83-4c7a-bca3-46fab19bac0d","executionInfo":{"status":"ok","timestamp":1580860366767,"user_tz":-540,"elapsed":1780,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pF5cVumnixFA","colab_type":"code","colab":{}},"source":["# !pip install ../input/sacremoses/sacremoses-master/\n","# !pip install ../input/transformers/transformers-master/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NNj-byAiw3J","colab_type":"code","outputId":"69308267-16ae-4e08-e6bf-5292a3f2414a","executionInfo":{"status":"ok","timestamp":1580860378616,"user_tz":-540,"elapsed":13548,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install tensorflow-gpu==2.1.0-rc0\n","!pip install transformers\n","!pip install flashtext"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-gpu==2.1.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.1.0rc0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (0.9.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (0.1.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (3.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (1.11.2)\n","Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (2.0.2)\n","Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (2.0.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (1.0.8)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (0.34.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (1.17.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (3.1.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (0.2.2)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0-rc0) (0.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1.0-rc0) (45.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (3.1.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (1.11.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (0.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (0.16.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (2.21.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0-rc0) (2.8.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (4.0.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (0.2.8)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (4.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (1.3.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (3.0.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0-rc0) (3.1.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n","Requirement already satisfied: flashtext in /usr/local/lib/python3.6/dist-packages (2.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xh4GlJboipwn","colab_type":"code","outputId":"a82b8847-f3f9-4b0c-ab28-456c69bc0e18","executionInfo":{"status":"ok","timestamp":1580860381412,"user_tz":-540,"elapsed":16296,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import GroupKFold\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","import os\n","from scipy.stats import spearmanr\n","from math import floor, ceil\n","\n"," # TF2.0をインストールしてから再読み込みが必要\n","from transformers import BertTokenizer, TFBertModel, BertConfig\n","\n","np.set_printoptions(suppress=True)\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2.1.0-rc0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"01z1Ma3WmfQ-","colab_type":"code","colab":{}},"source":["# PATH = '../input/google-quest-challenge/'\n","PATH = '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/google-quest-challenge/'\n","\n","\n","# tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n","\n","#tokenizer = BertTokenizer.from_pretrained(BERT_PATH+'bert-base-uncased-vocab.txt')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"te6a7J2p-k06","colab_type":"code","outputId":"4559b94e-3a6c-4d55-8790-3dfe8c881bca","executionInfo":{"status":"ok","timestamp":1580860381844,"user_tz":-540,"elapsed":16630,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":179}},"source":["MAX_SEQUENCE_LENGTH = 512\n","\n","df_train = pd.read_csv(PATH+'train.csv')\n","df_test = pd.read_csv(PATH+'test.csv')\n","df_sub = pd.read_csv(PATH+'sample_submission.csv')\n","print('train shape =', df_train.shape)\n","print('test shape =', df_test.shape)\n","\n","output_categories = list(df_train.columns[11:])\n","input_categories = list(df_train.columns[[1,2,5]])\n","print('\\noutput categories:\\n\\t', output_categories)\n","print('\\ninput categories:\\n\\t', input_categories)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train shape = (6079, 41)\n","test shape = (476, 11)\n","\n","output categories:\n","\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n","\n","input categories:\n","\t ['question_title', 'question_body', 'answer']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ESrdYHugmnVh","colab_type":"code","colab":{}},"source":["def _convert_to_transformer_inputs(title, question, answer, tokenizer, max_sequence_length):\n","    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n","    \n","    def return_id(str1, str2, truncation_strategy, length):\n","\n","        inputs = tokenizer.encode_plus(str1, str2,\n","            add_special_tokens=True,\n","            max_length=length,\n","            truncation_strategy=truncation_strategy)\n","        \n","        input_ids =  inputs[\"input_ids\"]\n","        input_masks = [1] * len(input_ids)\n","        input_segments = inputs[\"token_type_ids\"]\n","        padding_length = length - len(input_ids)\n","        padding_id = tokenizer.pad_token_id\n","        input_ids = input_ids + ([padding_id] * padding_length)\n","        input_masks = input_masks + ([0] * padding_length)\n","        input_segments = input_segments + ([0] * padding_length)\n","        \n","        return [input_ids, input_masks, input_segments]\n","    \n","    input_ids_q, input_masks_q, input_segments_q = return_id(\n","        str1=title + ' ' + question, str2=None, truncation_strategy ='longest_first', length=max_sequence_length)\n","    \n","    input_ids_a, input_masks_a, input_segments_a = return_id(\n","        str1=answer, str2=None, truncation_strategy='longest_first', length=max_sequence_length)\n","    \n","    return [input_ids_q, input_masks_q, input_segments_q,\n","            input_ids_a, input_masks_a, input_segments_a]\n","\n","def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n","    input_ids_q, input_masks_q, input_segments_q = [], [], []\n","    input_ids_a, input_masks_a, input_segments_a = [], [], []\n","    for _, instance in tqdm(df[columns].iterrows()):\n","        t, q, a = instance.question_title, instance.question_body, instance.answer\n","\n","        ids_q, masks_q, segments_q, ids_a, masks_a, segments_a = \\\n","        _convert_to_transformer_inputs(t, q, a, tokenizer, max_sequence_length)\n","        \n","        input_ids_q.append(ids_q)\n","        input_masks_q.append(masks_q)\n","        input_segments_q.append(segments_q)\n","\n","        input_ids_a.append(ids_a)\n","        input_masks_a.append(masks_a)\n","        input_segments_a.append(segments_a)\n","        \n","    return [np.asarray(input_ids_q, dtype=np.int32), \n","            np.asarray(input_masks_q, dtype=np.int32), \n","            np.asarray(input_segments_q, dtype=np.int32),\n","            np.asarray(input_ids_a, dtype=np.int32), \n","            np.asarray(input_masks_a, dtype=np.int32), \n","            np.asarray(input_segments_a, dtype=np.int32)]\n","\n","def compute_output_arrays(df, columns):\n","    return np.asarray(df[columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhJTYetMnG13","colab_type":"code","colab":{}},"source":["def compute_spearmanr_ignore_nan(trues, preds):\n","    rhos = []\n","    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n","        rhos.append(spearmanr(tcol, pcol).correlation)\n","    return np.nanmean(rhos)\n","\n","def create_model():\n","    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n","    a_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n","    \n","    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n","    a_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n","    \n","    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n","    a_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n","    \n","    config = BertConfig() # print(config) to see settings\n","    config.output_hidden_states = False # Set to True to obtain hidden states\n","    # caution: when using e.g. XLNet, XLNetConfig() will automatically use xlnet-large config\n","    \n","    \n","    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n","    # bert_model = TFBertModel.from_pretrained(\n","    #     BERT_PATH+'bert-base-uncased-tf_model.h5', config=config)\n","    \n","    # if config.output_hidden_states = True, obtain hidden states via bert_model(...)[-1]\n","    q_embedding = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)[0]\n","    a_embedding = bert_model(a_id, attention_mask=a_mask, token_type_ids=a_atn)[0]\n","    \n","    x_q = tf.keras.layers.GlobalAveragePooling1D()(q_embedding)\n","    x_a = tf.keras.layers.GlobalAveragePooling1D()(a_embedding)\n","    \n","    # x_q = tf.keras.layers.Dense(21, activation='relu')(x_q)\n","    # x_q = tf.keras.layers.Dropout(0.2)(x_q)\n","\n","    # x_a = tf.keras.layers.Concatenate()([x_q, x_a])\n","    # x_a = tf.keras.layers.Dense(9, activation='relu')(x_a)\n","    \n","    # x = tf.keras.layers.Concatenate()([x_q, x_a])\n","    # x = tf.keras.layers.Dense(30, activation='sigmoid')(x)\n","\n","    x_q1 = tf.keras.layers.Dense(1, activation='sigmoid')(x_q)\n","    x_a30 = tf.keras.layers.Dense(1, activation='sigmoid')(x_a)\n","\n","    x = tf.keras.layers.Concatenate()([x_q, x_a])\n","\n","    x_q = tf.keras.layers.Concatenate()([x_q1, x])\n","    x_q = tf.keras.layers.Dense(20, activation='sigmoid')(x_q)\n","\n","    x_a = tf.keras.layers.Concatenate()([x_a30, x])    \n","    x_a = tf.keras.layers.Dense(8, activation='sigmoid')(x_a)\n","    x = tf.keras.layers.Concatenate()([x_q, x_a])\n","    x = tf.keras.layers.Concatenate()([x_q1, x])\n","    x = tf.keras.layers.Concatenate()([x, x_a30])\n","\n","    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn, a_id, a_mask, a_atn,], outputs=x)\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mW9NRH_fnJkn","colab_type":"code","outputId":"df0841c5-5939-4cd8-aa12-10ec33017ffe","executionInfo":{"status":"ok","timestamp":1580860423963,"user_tz":-540,"elapsed":58604,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["outputs = compute_output_arrays(df_train, output_categories)\n","inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6079it [00:37, 164.09it/s]\n","476it [00:02, 164.97it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"of426LbpnJ3R","colab_type":"code","outputId":"5f44b3ff-940d-4702-ae4b-1699f18a99ad","executionInfo":{"status":"ok","timestamp":1580142644017,"user_tz":-540,"elapsed":276742,"user":{"displayName":"m f","photoUrl":"","userId":"10272771420966758066"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"source":["gkf = GroupKFold(n_splits=5).split(X=df_train.question_body, groups=df_train.question_body)\n","\n","valid_preds = []\n","test_preds = []\n","for fold, (train_idx, valid_idx) in enumerate(gkf):\n","      print(f'---fold {(fold+1)}----')\n","\n","      train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n","      train_outputs = outputs[train_idx]\n","\n","      valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n","      valid_outputs = outputs[valid_idx]\n","      \n","      K.clear_session()\n","      model = create_model()\n","      optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n","      model.compile(loss='binary_crossentropy', optimizer=optimizer)\n","      model.fit(train_inputs, train_outputs, epochs=4, batch_size=6)\n","      model.save_weights(f'/content/drive/My Drive/Colab Notebooks/GoogleQuest/tfbert-{fold}.h5')\n","      valid_preds.append(model.predict(valid_inputs))\n","      test_preds.append(model.predict(test_inputs))\n","      \n","      rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_preds[-1])\n","      print('validation score = ', rho_val)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["---fold 1----\n","Train on 4863 samples\n","Epoch 1/4\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n","4863/4863 [==============================] - 1265s 260ms/sample - loss: 0.3876\n","Epoch 2/4\n","4863/4863 [==============================] - 1240s 255ms/sample - loss: 0.3600\n","Epoch 3/4\n","4863/4863 [==============================] - 1239s 255ms/sample - loss: 0.3457\n","Epoch 4/4\n","4863/4863 [==============================] - 1239s 255ms/sample - loss: 0.3311\n","validation score =  0.3782190419381019\n","---fold 2----\n","Train on 4863 samples\n","Epoch 1/4\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n","4863/4863 [==============================] - 1264s 260ms/sample - loss: 0.3883\n","Epoch 2/4\n","1590/4863 [========>.....................] - ETA: 13:55 - loss: 0.3605"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MVrp7QY4nKCp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aggbTtiDnKNE","colab_type":"code","colab":{}},"source":["# models = []\n","# for i in range(5):\n","#     model_path = f'../input/tfbert/tfbert-{i}.h5'\n","#     #print(model_path)\n","#     model = bert_model()\n","#     model.load_weights(model_path)\n","#     #model = load_model(model_path, custom_objects={'KerasLayer':hub.KerasLayer}) \n","#     #reloaded_model = tf.keras.experimental.load_from_saved_model('path_to_my_model.h5', custom_objects={'KerasLayer':hub.KerasLayer})\n","#     models.append(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bhaxNvPTVd3","colab_type":"code","colab":{}},"source":["# test_predictions = []\n","# for model in models:\n","#     test_predictions.append(model.predict(test_inputs, batch_size=8)) # model.predict(self.test_inputs, batch_size=self.batch_size)\n","    \n","# final_predictions = np.mean(test_predictions, axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzWlV8CeTa5K","colab_type":"code","colab":{}},"source":["# df_sub.iloc[:, 1:] = final_predictions\n","# df_sub.to_csv('submission.csv', index=False)\n","# df_sub.head()"],"execution_count":0,"outputs":[]}]}