{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"100_fork_TF","provenance":[{"file_id":"1Bx7i8QbYTalH7ahP9KTQXGBwpB_BadrF","timestamp":1580005643557},{"file_id":"1DNFMRK9UQsAjXko7bJJZwUh_6niUSHcC","timestamp":1579998215289},{"file_id":"1-4bVyplvvSuyPB6-soncICDgu8K9Oi-6","timestamp":1579230557293}],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6T6HUtB5eorj","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvK9IDYaOP_b","colab_type":"code","colab":{}},"source":["DATA_DIR = '/content/drive/My Drive/Colab Notebooks/GoogleQuest/input/google-quest-challenge'\n","# DATA_DIR = '../input/google-quest-challenge'\n","# DATA_DIR = 'D:/project/ICF_AutoCapsule_disabled/kaggle/google-quest-challenge'\n","# BERT_DIR = 'D:/project/ICF_AutoCapsule_disabled/BERT'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4jYDD13OP_o","colab_type":"code","colab":{}},"source":["# !pip install ../input/sacremoses/sacremoses-master/\n","# !pip install ../input/transformers/transformers-master/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xst4_Y1Xer4Y","colab_type":"code","colab":{}},"source":["!pip install transformers\n","!pip install flashtext"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1wUm_cJrcSi","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import GroupKFold\n","import math\n","import matplotlib.pyplot as plt\n","import os, sys, gc, random, multiprocessing, glob, time\n","from tqdm import tqdm_notebook as tqdm\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","# import bert_tokenization as tokenization\n","import tensorflow.keras.backend as K\n","\n","from transformers import *\n","from tensorflow.keras.models import load_model\n","\n","np.set_printoptions(suppress=True)\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EH-iC221rvtm","colab_type":"code","colab":{}},"source":["BERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n","tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n","MAX_SEQUENCE_LENGTH = 512\n","\n","df_train = pd.read_csv(DATA_DIR+'/train.csv')\n","df_test = pd.read_csv(DATA_DIR+'/test.csv')\n","df_sub = pd.read_csv(DATA_DIR+'/sample_submission.csv')\n","print('train shape =', df_train.shape)\n","print('test shape =', df_test.shape)\n","\n","output_categories = list(df_train.columns[11:])\n","input_categories = list(df_train.columns[[1,2,5]])\n","print('\\noutput categories:\\n\\t', output_categories)\n","print('\\ninput categories:\\n\\t', input_categories)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I7Oa5UEMrvcv","colab_type":"code","colab":{}},"source":["def _convert_to_transformer_inputs(title, question, answer, tokenizer, max_sequence_length):\n","    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n","    \n","    def return_id(str1, str2, truncation_strategy, length):\n","\n","        inputs = tokenizer.encode_plus(str1, str2,\n","            add_special_tokens=True,\n","            max_length=length,\n","            truncation_strategy=truncation_strategy)\n","        \n","        input_ids =  inputs[\"input_ids\"]\n","        input_masks = [1] * len(input_ids)\n","        input_segments = inputs[\"token_type_ids\"]\n","        padding_length = length - len(input_ids)\n","        padding_id = tokenizer.pad_token_id\n","        input_ids = input_ids + ([padding_id] * padding_length)\n","        input_masks = input_masks + ([0] * padding_length)\n","        input_segments = input_segments + ([0] * padding_length)\n","        \n","        return [input_ids, input_masks, input_segments]\n","    \n","    input_ids_q, input_masks_q, input_segments_q = return_id(\n","        title + ' ' + question, None, 'longest_first', max_sequence_length)\n","    \n","    input_ids_a, input_masks_a, input_segments_a = return_id(\n","        answer, None, 'longest_first', max_sequence_length)\n","    \n","    return [input_ids_q, input_masks_q, input_segments_q,\n","            input_ids_a, input_masks_a, input_segments_a]\n","\n","def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n","    input_ids_q, input_masks_q, input_segments_q = [], [], []\n","    input_ids_a, input_masks_a, input_segments_a = [], [], []\n","    for _, instance in tqdm(df[columns].iterrows()):\n","        t, q, a = instance.question_title, instance.question_body, instance.answer\n","\n","        ids_q, masks_q, segments_q, ids_a, masks_a, segments_a = \\\n","        _convert_to_transformer_inputs(t, q, a, tokenizer, max_sequence_length)\n","        \n","        input_ids_q.append(ids_q)\n","        input_masks_q.append(masks_q)\n","        input_segments_q.append(segments_q)\n","\n","        input_ids_a.append(ids_a)\n","        input_masks_a.append(masks_a)\n","        input_segments_a.append(segments_a)\n","        \n","    return [np.asarray(input_ids_q, dtype=np.int32), \n","            np.asarray(input_masks_q, dtype=np.int32), \n","            np.asarray(input_segments_q, dtype=np.int32),\n","            np.asarray(input_ids_a, dtype=np.int32), \n","            np.asarray(input_masks_a, dtype=np.int32), \n","            np.asarray(input_segments_a, dtype=np.int32)]\n","\n","def compute_output_arrays(df, columns):\n","    return np.asarray(df[columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qsDGnlbrvP6","colab_type":"code","colab":{}},"source":["def compute_spearmanr(trues, preds):\n","    rhos = []\n","    for col_trues, col_pred in zip(trues.T, preds.T):\n","        rhos.append(\n","            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n","    return np.mean(rhos)\n","\n","\n","class CustomCallback(tf.keras.callbacks.Callback):\n","    \n","    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n","\n","        self.valid_inputs = valid_data[0]\n","        self.valid_outputs = valid_data[1]\n","        self.test_inputs = test_data\n","        \n","        self.batch_size = batch_size\n","        self.fold = fold\n","        \n","    def on_train_begin(self, logs={}):\n","        self.valid_predictions = []\n","        self.test_predictions = []\n","        \n","    def on_epoch_end(self, epoch, logs={}):\n","        self.valid_predictions.append(\n","            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n","        \n","        rho_val = compute_spearmanr(\n","            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n","        \n","        print(\"\\nvalidation rho: %.4f\" % rho_val)\n","        \n","        if self.fold is not None:\n","            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')\n","        \n","        self.test_predictions.append(\n","            self.model.predict(self.test_inputs, batch_size=self.batch_size)\n","        )\n","\n","def bert_model():\n","    \n","    input_word_ids = tf.keras.layers.Input(\n","        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n","    input_masks = tf.keras.layers.Input(\n","        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n","    input_segments = tf.keras.layers.Input(\n","        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n","    \n","    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n","    \n","    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n","    \n","    x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n","    x = tf.keras.layers.Dropout(0.2)(x)\n","    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n","\n","    model = tf.keras.models.Model(\n","        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n","    \n","    return model    \n","        \n","def train_and_predict(model, train_data, valid_data, test_data, \n","                      learning_rate, epochs, batch_size, loss_function, fold):\n","        \n","    custom_callback = CustomCallback(\n","        valid_data=(valid_data[0], valid_data[1]), \n","        test_data=test_data,\n","        batch_size=batch_size,\n","        fold=None)\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    model.compile(loss=loss_function, optimizer=optimizer)\n","    model.fit(train_data[0], train_data[1], epochs=epochs, \n","              batch_size=batch_size, callbacks=[custom_callback])\n","    \n","    return custom_callback"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-ezn34DrvAU","colab_type":"code","colab":{}},"source":["outputs = compute_output_arrays(df_train, output_categories)\n","inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","# test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ON0cVnVruk-","colab_type":"code","colab":{}},"source":["gkf = GroupKFold(n_splits=5).split(X=df_train.question_body, groups=df_train.question_body) ############## originaln_splits=5\n","\n","valid_preds = []\n","test_preds = []\n","for fold, (train_idx, valid_idx) in enumerate(gkf):\n","    \n","    # will actually only do 2 folds (out of 5) to manage < 2h\n","    if fold in [0, 5]:\n","\n","        train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n","        train_outputs = outputs[train_idx]\n","\n","        valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n","        valid_outputs = outputs[valid_idx]\n","        \n","        K.clear_session()\n","        model = bert_model()\n","        optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n","        model.compile(loss='binary_crossentropy', optimizer=optimizer)\n","        model.fit(train_inputs, train_outputs, epochs=3, batch_size=6)\n","        model.save_weights(f'/content/drive/My Drive/Colab Notebooks/GoogleQuest/bertTF-{fold}.h5')\n","        valid_preds.append(model.predict(valid_inputs))\n","        test_preds.append(model.predict(test_inputs))\n","        \n","        rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_preds[-1])\n","        print('validation score = ', rho_val)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZG92b4hgtg7J","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}