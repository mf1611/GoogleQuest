{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, gc, random, multiprocessing, glob, time\n",
    "\n",
    "#DATA_DIR = '../input/google-quest-challenge'\n",
    "DATA_DIR = 'D:/project/ICF_AutoCapsule_disabled/kaggle/google-quest-challenge'\n",
    "BERT_DIR = 'D:/project/ICF_AutoCapsule_disabled/BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ../input/sacremoses/sacremoses-master/\n",
    "# !pip install ../input/transformers/transformers-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#from ml_stratifiers import MultilabelStratifiedShuffleSplit, MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
    "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make results reproducible .Else noone will believe you .\n",
    "import random\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = sptr(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLineConfig:\n",
    "    def __init__(self, lr, warmup, epochs, patience, batch_size, seed, name, question_weight,answer_weight,fold,train):\n",
    "        self.lr = lr\n",
    "        self.warmup = warmup\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.name = name\n",
    "        self.question_weight = question_weight\n",
    "        self.answer_weight =answer_weight\n",
    "        self.fold = fold\n",
    "        self.train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PipeLineConfig(lr=1e-5, \\\n",
    "                        warmup=0.01, \\\n",
    "                        epochs=6, \\\n",
    "                        patience=3, \\\n",
    "                        batch_size=8, \\\n",
    "                        seed=42, \\\n",
    "                        name='test', \\\n",
    "                        question_weight=0.8, \\\n",
    "                        answer_weight=0.2, \\\n",
    "                        fold=3, \\\n",
    "                        train=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                              0.00308                 0.00308   \n",
       "1     46                              0.00448                 0.00448   \n",
       "2     70                              0.00673                 0.00673   \n",
       "3    132                              0.01401                 0.01401   \n",
       "4    200                              0.02074                 0.02074   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                  0.00308                       0.00308   \n",
       "1                  0.00448                       0.00448   \n",
       "2                  0.00673                       0.00673   \n",
       "3                  0.01401                       0.01401   \n",
       "4                  0.02074                       0.02074   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.00308                                0.00308   \n",
       "1                0.00448                                0.00448   \n",
       "2                0.00673                                0.00673   \n",
       "3                0.01401                                0.01401   \n",
       "4                0.02074                                0.02074   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.00308                        0.00308   \n",
       "1                          0.00448                        0.00448   \n",
       "2                          0.00673                        0.00673   \n",
       "3                          0.01401                        0.01401   \n",
       "4                          0.02074                        0.02074   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0                0.00308  ...                0.00308         0.00308   \n",
       "1                0.00448  ...                0.00448         0.00448   \n",
       "2                0.00673  ...                0.00673         0.00673   \n",
       "3                0.01401  ...                0.01401         0.01401   \n",
       "4                0.02074  ...                0.02074         0.02074   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                      0.00308           0.00308           0.00308   \n",
       "1                      0.00448           0.00448           0.00448   \n",
       "2                      0.00673           0.00673           0.00673   \n",
       "3                      0.01401           0.01401           0.01401   \n",
       "4                      0.02074           0.02074           0.02074   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0              0.00308                   0.00308                0.00308   \n",
       "1              0.00448                   0.00448                0.00448   \n",
       "2              0.00673                   0.00673                0.00673   \n",
       "3              0.01401                   0.01401                0.01401   \n",
       "4              0.02074                   0.02074                0.02074   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.00308              0.00308  \n",
       "1                         0.00448              0.00448  \n",
       "2                         0.00673              0.00673  \n",
       "3                         0.01401              0.01401  \n",
       "4                         0.02074              0.02074  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_asker_intent_understanding',\n",
       " 'question_body_critical',\n",
       " 'question_conversational',\n",
       " 'question_expect_short_answer',\n",
       " 'question_fact_seeking',\n",
       " 'question_has_commonly_accepted_answer',\n",
       " 'question_interestingness_others',\n",
       " 'question_interestingness_self',\n",
       " 'question_multi_intent',\n",
       " 'question_not_really_a_question',\n",
       " 'question_opinion_seeking',\n",
       " 'question_type_choice',\n",
       " 'question_type_compare',\n",
       " 'question_type_consequence',\n",
       " 'question_type_definition',\n",
       " 'question_type_entity',\n",
       " 'question_type_instructions',\n",
       " 'question_type_procedure',\n",
       " 'question_type_reason_explanation',\n",
       " 'question_type_spelling',\n",
       " 'question_well_written',\n",
       " 'answer_helpful',\n",
       " 'answer_level_of_information',\n",
       " 'answer_plausible',\n",
       " 'answer_relevance',\n",
       " 'answer_satisfaction',\n",
       " 'answer_type_instructions',\n",
       " 'answer_type_procedure',\n",
       " 'answer_type_reason_explanation',\n",
       " 'answer_well_written']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = sub.columns.values[1:].tolist()\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  ...  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
       "\n",
       "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0              1.000000        1.000000                     0.666667   \n",
       "1              0.888889        0.888889                     0.555556   \n",
       "2              0.777778        0.777778                     0.555556   \n",
       "3              0.888889        0.833333                     0.333333   \n",
       "4              1.000000        1.000000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          1.000000          1.000000             0.800000   \n",
       "1          0.888889          0.888889             0.666667   \n",
       "2          1.000000          1.000000             0.666667   \n",
       "3          0.833333          1.000000             0.800000   \n",
       "4          1.000000          1.000000             0.800000   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                       1.0               0.000000   \n",
       "1                       0.0               0.000000   \n",
       "2                       0.0               0.333333   \n",
       "3                       0.0               0.000000   \n",
       "4                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "#MAX_Q_LEN = 250\n",
    "#MAX_A_LEN = 259\n",
    "SEP_TOKEN_ID = 102 # bert-base-uncasedにおけるvocabの'[SEP']が、102番目という意味\n",
    "\n",
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train_mode=True, labeled=True):\n",
    "        self.df = df\n",
    "        self.train_mode = train_mode\n",
    "        self.labeled = labeled\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(BERT_DIR+'/bert-base-uncased')\n",
    "        #self.tokenizer = BertTokenizer.from_pretrained('../input/bert-base-uncased/')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        token_id列\n",
    "        segment_id列\n",
    "        label列\n",
    "        \"\"\"\n",
    "        row = self.df.iloc[index]\n",
    "        token_ids, seg_ids = self.get_token_ids(row)\n",
    "        if self.labeled:\n",
    "            labels = self.get_label(row)\n",
    "            return token_ids, seg_ids, labels\n",
    "        else:\n",
    "            return token_ids, seg_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "#     def select_tokens(self, tokens, max_num):\n",
    "#         if len(tokens) <= max_num:\n",
    "#             return tokens\n",
    "#         if self.train_mode:\n",
    "#             num_remove = len(tokens) - max_num\n",
    "#             remove_start = random.randint(0, len(tokens)-num_remove-1)\n",
    "#             return tokens[:remove_start] + tokens[remove_start + num_remove:]\n",
    "#         else:\n",
    "#             return tokens[:max_num//2] + tokens[-(max_num - max_num//2):]\n",
    "\n",
    "    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "        \"\"\"\n",
    "        title. question, answerそれぞれのセンテンスを、tokenizeする\n",
    "        max_lengthに足りない分は、\n",
    "        \"\"\"\n",
    "        t = self.tokenizer.tokenize(title)\n",
    "        q = self.tokenizer.tokenize(question)\n",
    "        a = self.tokenizer.tokenize(answer)\n",
    "\n",
    "        t_len = len(t)\n",
    "        q_len = len(q)\n",
    "        a_len = len(a)\n",
    "\n",
    "        if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "\n",
    "            if t_max_len > t_len:\n",
    "                \"\"\"\n",
    "                titleが短い場合、\n",
    "                最大長に足りない長さを、半分ずつqとaに加える\n",
    "                \"\"\"\n",
    "                t_new_len = t_len\n",
    "                a_max_len = a_max_len + math.floor((t_max_len - t_len)/2) # 切り捨て\n",
    "                q_max_len = q_max_len + math.ceil((t_max_len - t_len)/2) # 切り上げ\n",
    "            else:\n",
    "                \"\"\"\n",
    "                titleが長い場合、最大長で切る\n",
    "                \"\"\"\n",
    "                t_new_len = t_max_len\n",
    "\n",
    "            if a_max_len > a_len:\n",
    "                \"\"\"\n",
    "                answerに加えても短い場合、\n",
    "                最大長に足りない長さを、qに加える\n",
    "                \"\"\"\n",
    "                a_new_len = a_len \n",
    "                q_new_len = q_max_len + (a_max_len - a_len)\n",
    "            elif q_max_len > q_len:\n",
    "                a_new_len = a_max_len + (q_max_len - q_len)\n",
    "                q_new_len = q_len\n",
    "            else:\n",
    "                a_new_len = a_max_len\n",
    "                q_new_len = q_max_len\n",
    "\n",
    "\n",
    "            if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "                raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                                 % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "\n",
    "            t = t[:t_new_len]\n",
    "            q = q[:q_new_len]\n",
    "            a = a[:a_new_len]\n",
    "\n",
    "        return t, q, a\n",
    "        \n",
    "    def get_token_ids(self, row):\n",
    "        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n",
    "        \n",
    "        # BERTの入力タイプに変換([CLS]と[SEP]をつないで、１つのsetentenceに)\n",
    "        tokens = ['[CLS]'] + t_tokens + ['[SEP]'] + q_tokens + ['[SEP]'] + a_tokens + ['[SEP]']\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        if len(token_ids) < MAX_LEN:\n",
    "            \"\"\"0で後ろからpadding\"\"\"\n",
    "            token_ids += [0] * (MAX_LEN - len(token_ids))\n",
    "        ids = torch.tensor(token_ids)\n",
    "        seg_ids = self.get_seg_ids(ids)  # segment_embを区別するindex\n",
    "        return ids, seg_ids\n",
    "    \n",
    "    def get_seg_ids(self, ids):\n",
    "        \"\"\"\n",
    "        いくつめの文かを区別するsegment_idを、各文字に振る\n",
    "        \"\"\"\n",
    "        seg_ids = torch.zeros_like(ids) # [max_len]のtorch_tensor\n",
    "        seg_idx = 0\n",
    "        first_sep = True\n",
    "        for i, e in enumerate(ids):\n",
    "            seg_ids[i] = seg_idx\n",
    "            if e == SEP_TOKEN_ID: # [SEP]の場合\n",
    "                if first_sep:\n",
    "                    first_sep = False\n",
    "                else:\n",
    "                    seg_idx = 1\n",
    "        pad_idx = torch.nonzero(ids == 0)  # bert-base_uncasedのvocabで、[PAD]は0番目であるので、PADの部分のindexだけ抽出\n",
    "        seg_ids[pad_idx] = 0\n",
    "\n",
    "        return seg_ids\n",
    "\n",
    "    def get_label(self, row):\n",
    "        #print(row[target_columns].values)\n",
    "        return torch.tensor(row[target_columns].values.astype(np.float32))\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        labelデータを持つモードと、ない完全な推論モードでは、batchのshapeが異なるので(labelが2番目の要素にあるなし)\n",
    "        \"\"\"\n",
    "        token_ids = torch.stack([x[0] for x in batch])\n",
    "        seg_ids = torch.stack([x[1] for x in batch])\n",
    "    \n",
    "        if self.labeled:\n",
    "            labels = torch.stack([x[2] for x in batch])\n",
    "            return token_ids, seg_ids, labels\n",
    "        else:\n",
    "            return token_ids, seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0):\n",
    "    df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    df = shuffle(df, random_state=1234)\n",
    "    gkf = GroupKFold(n_splits=5).split(X=df.question_body, groups=df.question_body)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "        if fold == ifold:\n",
    "            df_train = df.iloc[train_idx]\n",
    "            df_val = df.iloc[valid_idx]\n",
    "            break\n",
    "\n",
    "    print('train', df_train.shape)\n",
    "    print('val', df_val.shape)\n",
    "\n",
    "    ds_train = QuestDataset(df_train, train_mode=True)\n",
    "    train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=ds_train.collate_fn, drop_last=True)\n",
    "    train_loader.num = len(df_train)\n",
    "\n",
    "    ds_val = QuestDataset(df_val, train_mode=False)\n",
    "    val_loader = torch.utils.data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=0, collate_fn=ds_val.collate_fn, drop_last=False)\n",
    "    val_loader.num = len(df_val)\n",
    "    val_loader.df = df_val\n",
    "\n",
    "    return train_loader, val_loader, df_val.shape[0]\n",
    "\n",
    "\n",
    "def get_test_loader(batch_size=4):\n",
    "    df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "    df_test = QuestDataset(df, train_mode=False, labeled=False)\n",
    "    loader = torch.utils.data.DataLoader(df_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=ds_test.collate_fn, drop_last=False)\n",
    "    loader.num = len(df)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "\n",
    "# def test_train_loader():\n",
    "#     loader, _ = get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=1)\n",
    "#     for ids, seg_ids, labels in loader:\n",
    "#         print(ids)\n",
    "#         print(seg_ids.numpy())\n",
    "#         print(labels)\n",
    "#         break\n",
    "# def test_test_loader():\n",
    "#     loader = get_test_loader(4)\n",
    "#     for ids, seg_ids in loader:\n",
    "#         print(ids)\n",
    "#         print(seg_ids)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, n_classes=30):\n",
    "        super(QuestModel, self).__init__()\n",
    "        self.model_name = 'QuestModel'\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_DIR+'/bert-base-uncased/')\n",
    "        #self.bert_model = BertModel.from_pretrained('../input/bert-base-uncased/')    \n",
    "        self.fc = nn.Linear(768, n_classes)\n",
    "\n",
    "    def forward(self, ids, seg_ids):\n",
    "        attention_mask = (ids > 0)  # ids==0([PAD])部分だけFalseとなるので、そこだけattention_weightを0に\n",
    "        layers, pool_out = self.bert_model(input_ids=ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n",
    "        #print(layers[-1][0].size())\n",
    "        #print(pool_out.size())\n",
    "\n",
    "        #out = F.dropout(layers[-1][:, 0, :], p=0.2, training=self.training)\n",
    "        out =  F.dropout(pool_out, p=0.2, training=self.training)\n",
    "        logit = self.fc(out)\n",
    "        return logit # 単に30種類の出力値を算出\n",
    "    \n",
    "def test_model():\n",
    "    \"\"\"確認用、バッチサイズ2\"\"\"\n",
    "    x = torch.tensor([[1,2,3,4,5,0, 0], [1,2,3,4,5, 0, 0]])\n",
    "    seg_ids = torch.tensor([[0,0,0,0,0, 0, 0], [0,0,0,0,0, 0, 0]])\n",
    "    model = QuestModel()\n",
    "\n",
    "    y = model(x, seg_ids)\n",
    "    print(y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30])\n",
      "tensor([[ 3.9142e-01, -1.3947e-02,  5.2440e-01,  7.0391e-01,  3.6601e-02,\n",
      "         -2.1076e-01, -2.0742e-01,  3.8842e-01, -3.6691e-01,  3.9539e-02,\n",
      "          1.1247e-01, -1.7837e-01, -2.8799e-01,  1.8482e-01,  3.0477e-01,\n",
      "         -4.5973e-01,  3.3056e-01, -1.4741e-01,  4.4749e-02,  2.1768e-01,\n",
      "          4.1020e-01,  8.8369e-02,  3.2358e-01,  3.7427e-01,  3.9418e-01,\n",
      "          5.1816e-04, -2.7123e-01,  4.2593e-01, -9.0014e-02,  9.4861e-01],\n",
      "        [ 4.6783e-01, -3.0907e-02,  5.7824e-01,  4.3496e-01,  9.0965e-02,\n",
      "         -2.3794e-01, -1.4856e-01,  1.3355e-01, -2.2786e-01,  3.1250e-01,\n",
      "         -4.0960e-01, -2.1083e-01, -3.8161e-01, -6.3352e-02,  6.0217e-01,\n",
      "         -5.3606e-01,  3.0912e-01, -1.1719e-02,  9.1177e-02,  3.0557e-01,\n",
      "          9.0634e-01,  1.8659e-02,  2.4406e-01,  3.0113e-01,  4.8014e-01,\n",
      "          2.4510e-01, -2.3487e-01,  5.5336e-01, -8.4923e-02,  5.2944e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    avg_loss = 0.    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        ids_train, seg_ids_train, label_ids_train = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "        \n",
    "        logits = model(ids_train, seg_ids_train)\n",
    "        #logits = torch.sigmoid(model(ids_train, seg_ids_train))\n",
    "        \n",
    "        loss = config.question_weight*criterion(logits[:,0:21], label_ids_train[:,0:21]) + config.answer_weight*criterion(logits[:,21:30], label_ids_train[:,21:30])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        del ids_train, seg_ids_train, label_ids_train\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return avg_loss\n",
    "\n",
    "def val_model(val_loader, val_length, batch_size=8):\n",
    "    model.eval() # eval mode  \n",
    "    avg_val_loss = 0.\n",
    "    \n",
    "    valid_preds = np.zeros((val_length, len(target_columns)))\n",
    "    original = np.zeros((val_length, len(target_columns)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            ids_val, seg_ids_val, label_ids_val = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "            \n",
    "            logits = torch.sigmoid(model(ids_val, seg_ids_val))\n",
    "            \n",
    "            avg_val_loss += criterion(logits, labels).item() / len(val_loader)\n",
    "            valid_preds[idx*batch_size : (idx+1)*batch_size] = logits.detach().cpu().squeeze().numpy()\n",
    "            original[idx*batch_size : (idx+1)*batch_size]    = labels.detach().cpu().squeeze().numpy()\n",
    "        \n",
    "        score = 0\n",
    "        preds = torch.tensor(valid_preds).numpy()\n",
    "        #preds = torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "        \n",
    "        # np.save(\"preds.npy\", preds)\n",
    "        # np.save(\"actuals.npy\", original)\n",
    "        \n",
    "        rho_val = np.mean([spearmanr(original[:, i], preds[:,i]).correlation for i in range(preds.shape[1])])\n",
    "        print('\\r val_spearman-rho: %s' % (str(round(rho_val, 5))), end = 100*' '+'\\n')\n",
    "        \n",
    "        for i in range(len(target_columns)):\n",
    "            print(i, spearmanr(original[:,i], preds[:,i]))\n",
    "            score += np.nan_to_num(spearmanr(original[:, i], preds[:, i]).correlation)\n",
    "    \n",
    "    return avg_val_loss, score/len(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4863, 41)\n",
      "val (1216, 41)\n",
      "3\n",
      "tensor([[  101,  9765, 22835,  ..., 19761,  3064,   102],\n",
      "        [  101,  2339,  2024,  ...,     0,     0,     0],\n",
      "        [  101, 19998,  7367,  ...,  1013,  1007,   102],\n",
      "        [  101,  1000,  8112,  ...,     0,     0,     0]])\n",
      "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "tensor([[1.0000, 0.4444, 0.0000, 0.5000, 1.0000, 0.5000, 0.4444, 0.4444, 0.3333,\n",
      "         0.0000, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3333, 0.3333,\n",
      "         0.0000, 0.0000, 0.8889, 0.7778, 0.7778, 0.7778, 0.7778, 0.7333, 0.3333,\n",
      "         0.6667, 0.3333, 0.8889],\n",
      "        [1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.6667, 0.5556, 0.0000,\n",
      "         0.0000, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.5556, 1.0000, 0.8889, 0.7333, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000],\n",
      "        [0.7778, 0.3333, 0.3333, 0.5000, 0.0000, 0.0000, 0.6667, 0.4444, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3333, 0.0000, 0.8889, 1.0000, 0.6667, 0.8889, 1.0000, 0.8000, 0.0000,\n",
      "         0.3333, 1.0000, 1.0000],\n",
      "        [1.0000, 0.7778, 0.0000, 1.0000, 0.6667, 1.0000, 0.6667, 0.7778, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.7778, 1.0000, 1.0000, 0.9333, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, val_length = get_train_val_loaders()\n",
    "for n, d in enumerate(train_loader):\n",
    "    if n ==0:\n",
    "        print(len(d))\n",
    "        print(d[0])\n",
    "        print(d[1])\n",
    "        print(d[2])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUM_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = QuestModel(n_classes=30).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, eps=4e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---1-Fold---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                         | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4863, 41)\n",
      "val (1216, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 4.00 GiB total capacity; 805.93 MiB already allocated; 23.77 MiB free; 38.07 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-7e902a48325f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cosine_schedule_with_warmup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarmup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_training_steps\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mACCUM_STEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {(epoch+1)}, train_loss: {loss_train}, val_loss: {loss_val}, score_val: {score}, time: {(time.time()-start_time)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-eea7ab804bb5>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_loader, optimizer, criterion, scheduler)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mids_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_ids_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_ids_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_ids_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m#logits = torch.sigmoid(model(ids_train, seg_ids_train))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-c479072d6b85>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ids, seg_ids)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ids==0([PAD])部分だけFalseとなるので、そこだけattention_weightを0に\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseg_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#print(layers[-1][0].size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#print(pool_out.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    738\u001b[0m                                        \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m                                        \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                                        encoder_attention_mask=encoder_extended_attention_mask)\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mlayer_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[0mself_attention_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add self attentions if we output attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mself_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add attentions if we output them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;31m# Mask heads if we want to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\0000011306852\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m    804\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[0;32m    805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 4.00 GiB total capacity; 805.93 MiB already allocated; 23.77 MiB free; 38.07 MiB cached)"
     ]
    }
   ],
   "source": [
    "for fold in range(config.fold):\n",
    "    print('---%d-Fold---'%(fold+1))\n",
    "    \n",
    "    patience = 0\n",
    "    best_loss   = 100.0\n",
    "    best_score      = -1.\n",
    "    best_param_loss = None\n",
    "    best_param_score = None\n",
    "    \n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        start_time   = time.time()\n",
    "        \n",
    "        train_loader, val_loader, val_length = get_train_val_loaders(batch_size=config.batch_size, val_batch_size=config.batch_size, ifold=fold)\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps= config.epochs*len(train_loader)//ACCUM_STEPS)\n",
    "        \n",
    "        loss_train = train_model(train_loader, optimizer, criterion, scheduler)\n",
    "        loss_val, score_val = val_model(val_loader, val_length, batch_size=config.batch_size)\n",
    "        print(f'Epoch {(epoch+1)}, train_loss: {loss_train}, val_loss: {loss_val}, score_val: {score_val}, time: {(time.time()-start_time)}')\n",
    "        \n",
    "#         if loss_val < best_loss:\n",
    "#             patience = 0\n",
    "#             best_loss = loss_val \n",
    "#             best_param_loss = model.state_dict()\n",
    "\n",
    "        if score_val > best_score:\n",
    "            best_score = score_val\n",
    "            best_param_score = model.state_dict()\n",
    "            print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "            torch.save(best_param_score, 'best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= config.patience:\n",
    "                break\n",
    "        \n",
    "        del train_loader, val_loader, loss_train, loss_val, score_val\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    model.load_state_dict(best_param_score)\n",
    "    print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "    torch.save(best_param_score, 'best_param_score_{}_{}.pt'.format(config.name ,fold+1))   \n",
    "    \n",
    "    del train_loader, val_loader, loss_train, loss_val, score_val\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_file):\n",
    "    model = QuestModel()\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model = model.cuda()\n",
    "    #model = DataParallel(model)\n",
    "    return model\n",
    "\n",
    "def create_models():\n",
    "    models = []\n",
    "    for fold in range(config.fold):\n",
    "        model = create_model(f'../input/models/best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, test_loader):\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for ids, seg_ids in tqdm(test_loader, total=test_loader.num // test_loader.batch_size):\n",
    "            ids, seg_ids = ids.cuda(), seg_ids.cuda()\n",
    "            scores = []\n",
    "            for model in models:\n",
    "                outputs = torch.sigmoid(model(ids, seg_ids)).cpu()\n",
    "                scores.append(outputs)\n",
    "            all_scores.append(torch.mean(torch.stack(scores), 0))\n",
    "\n",
    "    all_scores = torch.cat(all_scores, 0).numpy()\n",
    "    \n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_test_loader(batch_size=32)\n",
    "models = create_models()\n",
    "\n",
    "preds = predict(models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[target_columns] = preds\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 過去ログ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, lengths, labels = None):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        if labels is not None:\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            self.labels = None\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        input_ids       = self.inputs[0][idx]\n",
    "        input_masks     = self.inputs[1][idx]\n",
    "        input_segments  = self.inputs[2][idx]\n",
    "        lengths         = self.lengths[idx]\n",
    "        if self.labels is not None: # targets\n",
    "            labels = self.labels[idx]\n",
    "            return input_ids, input_masks, input_segments, labels, lengths\n",
    "        return input_ids, input_masks, input_segments, lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, optimizer, criterion, scheduler,config):\n",
    "    \n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "   # tk0 = tqdm(enumerate(train_loader),total =len(train_loader))\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        input_ids, input_masks, input_segments, labels, _ = batch\n",
    "        input_ids, input_masks, input_segments, labels = input_ids.to(device), input_masks.to(device), input_segments.to(device), labels.to(device)            \n",
    "        \n",
    "        output_train = model(input_ids = input_ids.long(),\n",
    "                             labels = None,\n",
    "                             attention_mask = input_masks,\n",
    "                             token_type_ids = input_segments,\n",
    "                            )\n",
    "        logits = output_train[0] #output preds\n",
    "\n",
    "        loss = config.question_weight*criterion(logits[:,0:21], labels[:,0:21]) + config.answer_weight*criterion(logits[:,21:30], labels[:,21:30])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        del input_ids, input_masks, input_segments, labels\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return avg_loss\n",
    "\n",
    "def val_model(val_loader, val_shape, batch_size=8):\n",
    "\n",
    "    avg_val_loss = 0.\n",
    "    model.eval() # eval mode\n",
    "    \n",
    "    valid_preds = np.zeros((val_shape, len(target_cols)))\n",
    "    original = np.zeros((val_shape, len(target_cols)))\n",
    "    \n",
    "    #tk0 = tqdm(enumerate(val_loader))\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            input_ids, input_masks, input_segments, labels, _ = batch\n",
    "            input_ids, input_masks, input_segments, labels = input_ids.to(device), input_masks.to(device), input_segments.to(device), labels.to(device)            \n",
    "            \n",
    "            output_val = model(input_ids = input_ids.long(),\n",
    "                             labels = None,\n",
    "                             attention_mask = input_masks,\n",
    "                             token_type_ids = input_segments,\n",
    "                            )\n",
    "            logits = output_val[0] #output preds\n",
    "            \n",
    "            avg_val_loss += criterion(logits, labels).item() / len(val_loader)\n",
    "            valid_preds[idx*batch_size : (idx+1)*batch_size] = logits.detach().cpu().squeeze().numpy()\n",
    "            original[idx*batch_size : (idx+1)*batch_size]    = labels.detach().cpu().squeeze().numpy()\n",
    "        \n",
    "        score = 0\n",
    "        preds = torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "        \n",
    "        # np.save(\"preds.npy\", preds)\n",
    "        # np.save(\"actuals.npy\", original)\n",
    "        \n",
    "        rho_val = np.mean([spearmanr(original[:, i], preds[:,i]).correlation for i in range(preds.shape[1])])\n",
    "        print('\\r val_spearman-rho: %s' % (str(round(rho_val, 5))), end = 100*' '+'\\n')\n",
    "        \n",
    "        for i in range(len(target_cols)):\n",
    "            print(i, spearmanr(original[:,i], preds[:,i]))\n",
    "            score += np.nan_to_num(spearmanr(original[:, i], preds[:, i]).correlation)\n",
    "    return avg_val_loss, score/len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model, test_loader, batch_size=32):\n",
    "    \n",
    "    test_preds = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    model.eval();\n",
    "    tk0 = tqdm(enumerate(test_loader))\n",
    "    for idx, x_batch in tk0:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids = x_batch[0].to(device), \n",
    "                            labels = None, \n",
    "                            attention_mask = x_batch[1].to(device),\n",
    "                            token_type_ids = x_batch[2].to(device),\n",
    "                           )\n",
    "            predictions = outputs[0]\n",
    "            test_preds[idx*batch_size : (idx+1)*batch_size] = predictions.detach().cpu().squeeze().numpy()\n",
    "\n",
    "    output = torch.sigmoid(torch.tensor(test_preds)).numpy()        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"D:/project/ICF_AutoCapsule_disabled/BERT/bert-base-uncased/vocab.txt\", do_lower_case=True)\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True, proxies={'https://s3.amazonaws.com':'http://proxygate2.nic.nec.co.jp:8080'})\n",
    "input_categories = list(train.columns[[1,2,5]]); input_categories\n",
    "\n",
    "bert_model_config = 'D:/project/ICF_AutoCapsule_disabled/BERT/bert-base-uncased/bert_config.json'\n",
    "bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "bert_config.num_labels = len(target_columns)\n",
    "\n",
    "\n",
    "bert_model = 'bert-base-cased'\n",
    "do_lower_case = 'uncased' in bert_model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "output_model_file = 'bert_pytorch.bin'\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "test_inputs = compute_input_arays(test, input_categories, tokenizer, max_sequence_length=512)\n",
    "lengths_test = np.argmax(test_inputs[0] == 0, axis=1)\n",
    "lengths_test[lengths_test == 0] = test_inputs[0].shape[1]\n",
    "\n",
    "print(do_lower_case, bert_model, device, output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "NUM_FOLDS = config.fold  # change this\n",
    "SEED = config.seed\n",
    "BATCH_SIZE = 8\n",
    "epochs = config.epochs   # change this\n",
    "ACCUM_STEPS = 1\n",
    "\n",
    "kf = KFold(n_splits = NUM_FOLDS, random_state = SEED)\n",
    "\n",
    "test_set = QuestDataset(inputs=test_inputs, lengths=lengths_test, labels=None)\n",
    "test_loader  = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "result = np.zeros((len(test), len(target_columns)))\n",
    "\n",
    "y_train = train[target_columns].values # dummy\n",
    "\n",
    "print(bcolors.FAIL, f\"For Every Fold, Train {epochs} Epochs\", bcolors.ENDC)\n",
    "\n",
    "\n",
    "if config.train :\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train.values, y_train)):\n",
    "\n",
    "        print(bcolors.HEADER, \"Current Fold:\", fold, bcolors.ENDC)\n",
    "\n",
    "        train_df, val_df = train.iloc[train_index], train.iloc[val_index]\n",
    "        print(\"Train and Valid Shapes are\", train_df.shape, val_df.shape)\n",
    "    \n",
    "        print(bcolors.HEADER, \"Preparing train datasets....\", bcolors.ENDC)\n",
    "    \n",
    "        inputs_train = compute_input_arays(train_df, input_categories, tokenizer, max_sequence_length=512)\n",
    "        outputs_train = compute_output_arrays(train_df, columns = target_columns)\n",
    "        outputs_train = torch.tensor(outputs_train, dtype=torch.float32)\n",
    "        lengths_train = np.argmax(inputs_train[0] == 0, axis=1)\n",
    "        lengths_train[lengths_train == 0] = inputs_train[0].shape[1]\n",
    "    \n",
    "        print(bcolors.HEADER, \"Preparing Valid datasets....\", bcolors.ENDC)\n",
    "    \n",
    "        inputs_valid = compute_input_arays(val_df, input_categories, tokenizer, max_sequence_length=512)\n",
    "        outputs_valid = compute_output_arrays(val_df, columns = target_columns)\n",
    "        outputs_valid = torch.tensor(outputs_valid, dtype=torch.float32)\n",
    "        lengths_valid = np.argmax(inputs_valid[0] == 0, axis=1)\n",
    "        lengths_valid[lengths_valid == 0] = inputs_valid[0].shape[1]\n",
    "    \n",
    "        print(bcolors.HEADER, \"Preparing Dataloaders Datasets....\", bcolors.ENDC)\n",
    "\n",
    "        train_set    = QuestDataset(inputs=inputs_train, lengths=lengths_train, labels=outputs_train)\n",
    "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "        valid_set    = QuestDataset(inputs=inputs_valid, lengths=lengths_valid, labels=outputs_valid)\n",
    "        valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "    \n",
    "        model = BertForSequenceClassification.from_pretrained('D:/project/ICF_AutoCapsule_disabled/BERT/bert-base-uncased/', config=bert_config);\n",
    "        model.zero_grad();\n",
    "        model.to(device);\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train();\n",
    "    \n",
    "        i = 0\n",
    "        best_avg_loss   = 100.0\n",
    "        best_score      = -1.\n",
    "        best_param_loss = None\n",
    "        best_param_score = None\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, eps=4e-5)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps= epochs*len(train_loader)//ACCUM_STEPS)\n",
    "        print(\"Training....\")\n",
    "    \n",
    "        for epoch in range(config.epochs):\n",
    "        \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "            start_time   = time.time()\n",
    "            avg_loss     = train_model(train_loader, optimizer, criterion, scheduler,config)\n",
    "            avg_val_loss, score = val_model(valid_loader, val_shape=val_df.shape[0])\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            print(bcolors.OKGREEN, 'Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t score={:.6f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, epochs, avg_loss, avg_val_loss, score, elapsed_time),\n",
    "            bcolors.ENDC\n",
    "            )\n",
    "\n",
    "            if best_avg_loss > avg_val_loss:\n",
    "                i = 0\n",
    "                best_avg_loss = avg_val_loss \n",
    "                best_param_loss = model.state_dict()\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                best_param_score = model.state_dict()\n",
    "                print('best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "                torch.save(best_param_score, DATA_DIR+'best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "            \n",
    "        model.load_state_dict(best_param_score)\n",
    "        result += predict_result(model, test_loader)\n",
    "        print('best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "        torch.save(best_param_score, DATA_DIR+'best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "        \n",
    "        result /= NUM_FOLDS\n",
    "        \n",
    "    del train_df, val_df, model, optimizer, criterion, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "    del valid_loader, train_loader, valid_set, train_set\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the colab pretrained model , same setting as experiement 1 for uncased . \n",
    "## I had to break and load as dataset . Thats why this weird way of loading weights . \n",
    "result = np.zeros((len(test), len(target_columns)))\n",
    "#good_folds = [2,3,4,6,8]## Taking only the folds for which the val_spearman was more than 0.381 \n",
    "for i in range(1,9):\n",
    "    model = BertForSequenceClassification.from_pretrained('D:/project/ICF_AutoCapsule_disabled/BERT/bert-base-uncased/', config=bert_config);\n",
    "    model.zero_grad();\n",
    "    model.to(device);\n",
    "    if i < 5 :\n",
    "        model.load_state_dict(torch.load(DATA_DIR+'/best_param_score_uncased_1_{i}.pt'))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(DATA_DIR+'/best_param_score_uncased_1_{i}.pt'))\n",
    "        \n",
    "    result += predict_result(model, test_loader)\n",
    "    \n",
    "for i in range(1,5):\n",
    "    model = BertForSequenceClassification.from_pretrained('D:/project/ICF_AutoCapsule_disabled/BERT/bert-base-uncased/', config=bert_config);\n",
    "    model.zero_grad();\n",
    "    model.to(device);\n",
    "    model.load_state_dict(torch.load(DATA_DIR+'/best_param_score_uncased_4_{i}.pt'))\n",
    "\n",
    "    result += predict_result(model, test_loader)   \n",
    "    \n",
    "    \n",
    "result/=12 ##  12 folds used out of 12 folds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
