{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, gc, random, multiprocessing, glob, time\n",
    "\n",
    "DATA_DIR = '../input/google-quest-challenge'\n",
    "# DATA_DIR = 'D:/project/ICF_AutoCapsule_disabled/kaggle/google-quest-challenge'\n",
    "# BERT_DIR = 'D:/project/ICF_AutoCapsule_disabled/BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ../input/sacremoses/sacremoses-master/\n",
    "# !pip install ../input/transformers/transformers-master/\n",
    "\n",
    "# !pip install ../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\n",
    "# !pip install ../input/glove840b300dtxt/glove.840B.300d.txt\n",
    "\n",
    "# CRAWL_EMBEDDING_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n",
    "# GLOVE_EMBEDDING_PATH = '../input/glove840b300dtxt/glove.840B.300d.txt'\n",
    "# CRAWL_EMBEDDING_PATH = 'D:/project/ICF_AutoCapsule_disabled/W2V/crawl-300d-2M.vec'\n",
    "# GLOVE_EMBEDDING_PATH = 'D:/project/ICF_AutoCapsule_disabled/W2V/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as naf\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#from ml_stratifiers import MultilabelStratifiedShuffleSplit, MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
    "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make results reproducible .Else noone will believe you .\n",
    "import random\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLineConfig:\n",
    "    def __init__(self, lr, warmup, epochs, patience, batch_size, seed, name, question_weight,answer_weight,fold,train):\n",
    "        self.lr = lr\n",
    "        self.warmup = warmup\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.name = name\n",
    "        self.question_weight = question_weight\n",
    "        self.answer_weight =answer_weight\n",
    "        self.fold = fold\n",
    "        self.train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PipeLineConfig(lr=1e-5, \\\n",
    "                        warmup=0.01, \\\n",
    "                        epochs=4, \\\n",
    "                        patience=3, \\\n",
    "                        batch_size=8, \\\n",
    "                        seed=42, \\\n",
    "                        name='remodel0115', \\\n",
    "                        question_weight=0.5, \\\n",
    "                        answer_weight=0.5, \\\n",
    "                        fold=5, \\\n",
    "                        train=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                              0.00308                 0.00308   \n",
       "1     46                              0.00448                 0.00448   \n",
       "2     70                              0.00673                 0.00673   \n",
       "3    132                              0.01401                 0.01401   \n",
       "4    200                              0.02074                 0.02074   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                  0.00308                       0.00308   \n",
       "1                  0.00448                       0.00448   \n",
       "2                  0.00673                       0.00673   \n",
       "3                  0.01401                       0.01401   \n",
       "4                  0.02074                       0.02074   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.00308                                0.00308   \n",
       "1                0.00448                                0.00448   \n",
       "2                0.00673                                0.00673   \n",
       "3                0.01401                                0.01401   \n",
       "4                0.02074                                0.02074   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.00308                        0.00308   \n",
       "1                          0.00448                        0.00448   \n",
       "2                          0.00673                        0.00673   \n",
       "3                          0.01401                        0.01401   \n",
       "4                          0.02074                        0.02074   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0                0.00308  ...                0.00308         0.00308   \n",
       "1                0.00448  ...                0.00448         0.00448   \n",
       "2                0.00673  ...                0.00673         0.00673   \n",
       "3                0.01401  ...                0.01401         0.01401   \n",
       "4                0.02074  ...                0.02074         0.02074   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                      0.00308           0.00308           0.00308   \n",
       "1                      0.00448           0.00448           0.00448   \n",
       "2                      0.00673           0.00673           0.00673   \n",
       "3                      0.01401           0.01401           0.01401   \n",
       "4                      0.02074           0.02074           0.02074   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0              0.00308                   0.00308                0.00308   \n",
       "1              0.00448                   0.00448                0.00448   \n",
       "2              0.00673                   0.00673                0.00673   \n",
       "3              0.01401                   0.01401                0.01401   \n",
       "4              0.02074                   0.02074                0.02074   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.00308              0.00308  \n",
       "1                         0.00448              0.00448  \n",
       "2                         0.00673              0.00673  \n",
       "3                         0.01401              0.01401  \n",
       "4                         0.02074              0.02074  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_asker_intent_understanding',\n",
       " 'question_body_critical',\n",
       " 'question_conversational',\n",
       " 'question_expect_short_answer',\n",
       " 'question_fact_seeking',\n",
       " 'question_has_commonly_accepted_answer',\n",
       " 'question_interestingness_others',\n",
       " 'question_interestingness_self',\n",
       " 'question_multi_intent',\n",
       " 'question_not_really_a_question',\n",
       " 'question_opinion_seeking',\n",
       " 'question_type_choice',\n",
       " 'question_type_compare',\n",
       " 'question_type_consequence',\n",
       " 'question_type_definition',\n",
       " 'question_type_entity',\n",
       " 'question_type_instructions',\n",
       " 'question_type_procedure',\n",
       " 'question_type_reason_explanation',\n",
       " 'question_type_spelling',\n",
       " 'question_well_written',\n",
       " 'answer_helpful',\n",
       " 'answer_level_of_information',\n",
       " 'answer_plausible',\n",
       " 'answer_relevance',\n",
       " 'answer_satisfaction',\n",
       " 'answer_type_instructions',\n",
       " 'answer_type_procedure',\n",
       " 'answer_type_reason_explanation',\n",
       " 'answer_well_written']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = sub.columns.values[1:].tolist()\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  ...  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
       "\n",
       "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0              1.000000        1.000000                     0.666667   \n",
       "1              0.888889        0.888889                     0.555556   \n",
       "2              0.777778        0.777778                     0.555556   \n",
       "3              0.888889        0.833333                     0.333333   \n",
       "4              1.000000        1.000000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          1.000000          1.000000             0.800000   \n",
       "1          0.888889          0.888889             0.666667   \n",
       "2          1.000000          1.000000             0.666667   \n",
       "3          0.833333          1.000000             0.800000   \n",
       "4          1.000000          1.000000             0.800000   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                       1.0               0.000000   \n",
       "1                       0.0               0.000000   \n",
       "2                       0.0               0.333333   \n",
       "3                       0.0               0.000000   \n",
       "4                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from flashtext import KeywordProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTS = {\n",
    "            '》', '〞', '¢', '‹', '╦', '║', '♪', 'Ø', '╩', '\\\\', '★', '＋', 'ï', '<', '?', '％', '+', '„', 'α', '*', '〰', '｟', '¹', '●', '〗', ']', '▾', '■', '〙', '↓', '´', '【', 'ᴵ',\n",
    "            '\"', '）', '｀', '│', '¤', '²', '‡', '¿', '–', '」', '╔', '〾', '%', '¾', '←', '〔', '＿', '’', '-', ':', '‧', '｛', 'β', '（', '─', 'à', 'â', '､', '•', '；', '☆', '／', 'π',\n",
    "            'é', '╗', '＾', '▪', ',', '►', '/', '〚', '¶', '♦', '™', '}', '″', '＂', '『', '▬', '±', '«', '“', '÷', '×', '^', '!', '╣', '▲', '・', '░', '′', '〝', '‛', '√', ';', '】', '▼',\n",
    "            '.', '~', '`', '。', 'ə', '］', '，', '{', '～', '！', '†', '‘', '﹏', '═', '｣', '〕', '〜', '＼', '▒', '＄', '♥', '〛', '≤', '∞', '_', '[', '＆', '→', '»', '－', '＝', '§', '⋅', \n",
    "            '▓', '&', 'Â', '＞', '〃', '|', '¦', '—', '╚', '〖', '―', '¸', '³', '®', '｠', '¨', '‟', '＊', '£', '#', 'Ã', \"'\", '▀', '·', '？', '、', '█', '”', '＃', '⊕', '=', '〟', '½', '』',\n",
    "            '［', '$', ')', 'θ', '@', '›', '＠', '｝', '¬', '…', '¼', '：', '¥', '❤', '€', '−', '＜', '(', '〘', '▄', '＇', '>', '₤', '₹', '∅', 'è', '〿', '「', '©', '｢', '∙', '°', '｜', '¡', \n",
    "            '↑', 'º', '¯', '♫', '#'\n",
    "          }\n",
    "\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\",\n",
    "\"couldnt\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n",
    "\"doesnt\" : \"does not\", \"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\", \"havent\" : \"have not\", \"he'd\" : \"he would\", \"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\", \"isn't\" : \"is not\", \"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \n",
    "\"shan't\" : \"shall not\", \"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"shouldnt\" : \"should not\",\n",
    "\"that's\" : \"that is\", \"thats\" : \"that is\", \"there's\" : \"there is\", \"theres\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\", \"theyre\":  \"they are\", \"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\", \"what'll\" : \"what will\", \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\", \"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\", \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\", \"won't\" : \"will not\", \"wouldn't\" : \"would not\", \"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\", \"you're\" : \"you are\", \"you've\" : \"you have\", \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\", \"tryin'\":\"trying\"}\n",
    "\n",
    "\n",
    "kp = KeywordProcessor(case_sensitive=True)\n",
    "for k, v in mispell_dict.items():\n",
    "    kp.add_keyword(k, v)\n",
    "\n",
    "def clean_punct(text):\n",
    "    text = str(text)\n",
    "    for punct in PUNCTS:\n",
    "        text = text.replace(punct, ' {} '.format(punct))\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'(\\&lt)|(\\&gt)', ' ', text)\n",
    "    \n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' url ', text)\n",
    "    text = kp.replace_keywords(text)\n",
    "    text = clean_punct(text)\n",
    "    text = re.sub(r'\\n\\r', ' ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['question_title'] = train['question_title'].apply(lambda x : preprocessing(x))\n",
    "# train['question_body'] = train['question_body'].apply(lambda x : preprocessing(x))\n",
    "# train['answer'] = train['answer'].apply(lambda x : preprocessing(x))\n",
    "\n",
    "# test['question_title'] = test['question_title'].apply(lambda x : preprocessing(x))\n",
    "# test['question_body'] = test['question_body'].apply(lambda x : preprocessing(x))\n",
    "# test['answer'] = test['answer'].apply(lambda x : preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # category, host変数を、数値化(LabelEncode)\n",
    "# le_category = LabelEncoder()\n",
    "# le_category.fit(np.concatenate([train.category.values, test.category.values], axis=0))\n",
    "# train['category'] = le_category.transform(train.category)\n",
    "# test['category'] = le_category.transform(test.category)\n",
    "\n",
    "# le_host = LabelEncoder()\n",
    "# le_host.fit(np.concatenate([train.host.values, test.host.values], axis=0))\n",
    "# train['host'] = le_host.transform(train.host)\n",
    "# test['host'] = le_host.transform(test.host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = ['CULTURE', 'LIFE_ARTS', 'SCIENCE', 'STACKOVERFLOW', 'TECHNOLOGY']\n",
    "\n",
    "host_list = ['academia.stackexchange.com', 'android.stackexchange.com',\n",
    "       'anime.stackexchange.com', 'apple.stackexchange.com',\n",
    "       'askubuntu.com', 'bicycles.stackexchange.com',\n",
    "       'biology.stackexchange.com', 'blender.stackexchange.com',\n",
    "       'boardgames.stackexchange.com', 'chemistry.stackexchange.com',\n",
    "       'christianity.stackexchange.com', 'codereview.stackexchange.com',\n",
    "       'cooking.stackexchange.com', 'crypto.stackexchange.com',\n",
    "       'cs.stackexchange.com', 'dba.stackexchange.com',\n",
    "       'diy.stackexchange.com', 'drupal.stackexchange.com',\n",
    "       'dsp.stackexchange.com', 'electronics.stackexchange.com',\n",
    "       'ell.stackexchange.com', 'english.stackexchange.com',\n",
    "       'expressionengine.stackexchange.com', 'gamedev.stackexchange.com',\n",
    "       'gaming.stackexchange.com', 'gis.stackexchange.com',\n",
    "       'graphicdesign.stackexchange.com', 'judaism.stackexchange.com',\n",
    "       'magento.stackexchange.com', 'math.stackexchange.com',\n",
    "       'mathematica.stackexchange.com', 'mathoverflow.net',\n",
    "       'mechanics.stackexchange.com', 'meta.askubuntu.com',\n",
    "       'meta.christianity.stackexchange.com',\n",
    "       'meta.codereview.stackexchange.com', 'meta.math.stackexchange.com',\n",
    "       'meta.stackexchange.com', 'meta.superuser.com',\n",
    "       'money.stackexchange.com', 'movies.stackexchange.com',\n",
    "       'music.stackexchange.com', 'photo.stackexchange.com',\n",
    "       'physics.stackexchange.com', 'programmers.stackexchange.com',\n",
    "       'raspberrypi.stackexchange.com', 'robotics.stackexchange.com',\n",
    "       'rpg.stackexchange.com', 'salesforce.stackexchange.com',\n",
    "       'scifi.stackexchange.com', 'security.stackexchange.com',\n",
    "       'serverfault.com', 'sharepoint.stackexchange.com',\n",
    "       'softwarerecs.stackexchange.com', 'stackoverflow.com',\n",
    "       'stats.stackexchange.com', 'superuser.com',\n",
    "       'tex.stackexchange.com', 'travel.stackexchange.com',\n",
    "       'unix.stackexchange.com', 'ux.stackexchange.com',\n",
    "       'webapps.stackexchange.com', 'webmasters.stackexchange.com',\n",
    "       'wordpress.stackexchange.com']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataAugumentation\n",
    "- どの程度の割合で、行うか？\n",
    "- 基本的に、ラベルは変えたくないので、意味合いを変えないようにAugmetationしたい\n",
    "- 全てを水増しすると、データが単純に倍になってしまうので、ある程度ランダムにいくつかだけ増やすもしくは変える、変えない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: \n",
      " The quick brown fox jumps over the lazy dog .\n",
      "the quick brown - fox jumps back over to the lazy dog .\n",
      "the quick , brown fox jumps over to the lazy little dog .\n",
      "the quick brown - fox jumps over to the lazy white dog .\n",
      "then the quick thinking brown fox jumps all over the lazy dog .\n",
      "the quick talking brown - fox jumps over the little lazy dog .\n",
      "the quick brown fox jumps back over to the little lazy dog .\n",
      "in the quick , brown - fox jumps over the lazy dog .\n",
      "the big quick , brown fox jumps over the little lazy dog .\n",
      "the quick brown - fox jumps all over the little lazy dog .\n",
      "the quick talking brown fox immediately jumps over to the lazy dog .\n"
     ]
    }
   ],
   "source": [
    "#BERT Augmentator\n",
    "aug_bert = naw.ContextualWordEmbsAug(\n",
    "    #model_path=BERT_DIR+'/bert-base-uncased',\n",
    "    model_path='bert-base-uncased',\n",
    "    device='cuda',\n",
    "    action='insert', #\"substitute\"\n",
    "    aug_p=0.3, # 含まれているwordsの中の何割を変換するか\n",
    "    temperature=0.3 , # 変換を施すかどうかの確率\n",
    "    top_k=10)\n",
    "\n",
    "# text = 'The quick brown fox jumps over the lazy dog .'\n",
    "# print(\"original: \\n\", text)\n",
    "# for _ in range(10):\n",
    "#     augmented_text = aug_bert.augment(text)\n",
    "#     print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上位語や下位語で、文字が置換\n",
    "aug_syn = naw.SynonymAug(\n",
    "    aug_src='wordnet', \n",
    "    aug_p=0.3, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "#MAX_Q_LEN = 250\n",
    "#MAX_A_LEN = 259\n",
    "SEP_TOKEN_ID = 102 # bert-base-uncasedにおけるvocabの'[SEP']が、102番目という意味\n",
    "\n",
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train_mode=True, labeled=True):\n",
    "        self.df = df\n",
    "        self.train_mode = train_mode\n",
    "        self.labeled = labeled\n",
    "        #self.tokenizer = BertTokenizer.from_pretrained(BERT_DIR+'/bert-base-uncased')\n",
    "        #self.tokenizer = BertTokenizer.from_pretrained('../input/bert-base-uncased/')\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        token_id列\n",
    "        segment_id列\n",
    "        label列\n",
    "        \"\"\"\n",
    "        row = self.df.iloc[index]\n",
    "        token_ids, seg_ids = self.get_token_ids(row)\n",
    "        if self.labeled:\n",
    "            labels = self.get_label(row)\n",
    "            return token_ids, seg_ids, torch.tensor(row.category), torch.tensor(row.host), labels\n",
    "        else:\n",
    "            return token_ids, seg_ids, torch.tensor(row.category), torch.tensor(row.host)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "#     def select_tokens(self, tokens, max_num):\n",
    "#         if len(tokens) <= max_num:\n",
    "#             return tokens\n",
    "#         if self.train_mode:\n",
    "#             num_remove = len(tokens) - max_num\n",
    "#             remove_start = random.randint(0, len(tokens)-num_remove-1)\n",
    "#             return tokens[:remove_start] + tokens[remove_start + num_remove:]\n",
    "#         else:\n",
    "#             return tokens[:max_num//2] + tokens[-(max_num - max_num//2):]\n",
    "\n",
    "    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "        \"\"\"\n",
    "        title. question, answerそれぞれのセンテンスを、tokenizeする\n",
    "        max_lengthに足りない分は、\n",
    "        \"\"\"\n",
    "        t = self.tokenizer.tokenize(title)\n",
    "        q = self.tokenizer.tokenize(question)\n",
    "        a = self.tokenizer.tokenize(answer)\n",
    "\n",
    "        t_len = len(t)\n",
    "        q_len = len(q)\n",
    "        a_len = len(a)\n",
    "\n",
    "        if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "\n",
    "            if t_max_len > t_len:\n",
    "                \"\"\"\n",
    "                titleが短い場合、\n",
    "                最大長に足りない長さを、半分ずつqとaに加える\n",
    "                \"\"\"\n",
    "                t_new_len = t_len\n",
    "                a_max_len = a_max_len + math.floor((t_max_len - t_len)/2) # 切り捨て\n",
    "                q_max_len = q_max_len + math.ceil((t_max_len - t_len)/2) # 切り上げ\n",
    "            else:\n",
    "                \"\"\"\n",
    "                titleが長い場合、最大長で切る\n",
    "                \"\"\"\n",
    "                t_new_len = t_max_len\n",
    "\n",
    "            if a_max_len > a_len:\n",
    "                \"\"\"\n",
    "                answerに加えても短い場合、\n",
    "                最大長に足りない長さを、qに加える\n",
    "                \"\"\"\n",
    "                a_new_len = a_len \n",
    "                q_new_len = q_max_len + (a_max_len - a_len)\n",
    "            elif q_max_len > q_len:\n",
    "                a_new_len = a_max_len + (q_max_len - q_len)\n",
    "                q_new_len = q_len\n",
    "            else:\n",
    "                a_new_len = a_max_len\n",
    "                q_new_len = q_max_len\n",
    "\n",
    "\n",
    "            if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "                raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                                 % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "\n",
    "            t = t[:t_new_len]\n",
    "            q = q[:q_new_len]\n",
    "            a = a[:a_new_len]\n",
    "\n",
    "        return t, q, a\n",
    "        \n",
    "    def get_token_ids(self, row):\n",
    "        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n",
    "        \n",
    "        # BERTの入力タイプに変換([CLS]と[SEP]をつないで、１つのsetentenceに)\n",
    "        tokens = ['[CLS]'] + t_tokens + ['[SEP]'] + q_tokens + ['[SEP]'] + a_tokens + ['[SEP]']\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        if len(token_ids) < MAX_LEN:\n",
    "            \"\"\"0で後ろからpadding\"\"\"\n",
    "            token_ids += [0] * (MAX_LEN - len(token_ids))\n",
    "        ids = torch.tensor(token_ids)\n",
    "        seg_ids = self.get_seg_ids(ids)  # segment_embを区別するindex\n",
    "        return ids, seg_ids\n",
    "    \n",
    "    def get_seg_ids(self, ids):\n",
    "        \"\"\"\n",
    "        いくつめの文かを区別するsegment_idを、各文字に振る\n",
    "        \"\"\"\n",
    "        seg_ids = torch.zeros_like(ids) # [max_len]のtorch_tensor\n",
    "        seg_idx = 0\n",
    "        first_sep = True\n",
    "        for i, e in enumerate(ids):\n",
    "            seg_ids[i] = seg_idx\n",
    "            if e == SEP_TOKEN_ID: # [SEP]の場合\n",
    "                if first_sep:\n",
    "                    first_sep = False\n",
    "                else:\n",
    "                    seg_idx = 1\n",
    "        pad_idx = torch.nonzero(ids == 0)  # bert-base_uncasedのvocabで、[PAD]は0番目であるので、PADの部分のindexだけ抽出\n",
    "        seg_ids[pad_idx] = 0\n",
    "\n",
    "        return seg_ids\n",
    "\n",
    "    def get_label(self, row):\n",
    "        #print(row[target_columns].values)\n",
    "        return torch.tensor(row[target_columns].values.astype(np.float32))\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        labelデータを持つモードと、ない完全な推論モードでは、batchのshapeが異なるので(labelが2番目の要素にあるなし)\n",
    "        \"\"\"\n",
    "        token_ids = torch.stack([x[0] for x in batch])\n",
    "        seg_ids = torch.stack([x[1] for x in batch])\n",
    "        category = torch.stack([x[2] for x in batch])\n",
    "        host = torch.stack([x[3] for x in batch])\n",
    "    \n",
    "        if self.labeled:\n",
    "            labels = torch.stack([x[-1] for x in batch])\n",
    "            return token_ids, seg_ids, category, host, labels\n",
    "        else:\n",
    "            return token_ids, seg_ids, category, host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0):\n",
    "    df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    \n",
    "    # cleaning\n",
    "    df['question_title'] = df['question_title'].apply(lambda x : preprocessing(x))\n",
    "    df['question_body'] = df['question_body'].apply(lambda x : preprocessing(x))\n",
    "    df['answer'] = df['answer'].apply(lambda x : preprocessing(x))\n",
    "        \n",
    "    # label encode\n",
    "    le_category = LabelEncoder()\n",
    "    le_category.fit(category_list)\n",
    "    for c in set(df.category):\n",
    "        if c not in category_list:\n",
    "            df.category = df.category.replace(c, np.nan)\n",
    "            df.category = df.category.fillna(train.category.mode()[0])\n",
    "    df.category = le_category.transform(df.category)\n",
    "    \n",
    "    le_host = LabelEncoder()\n",
    "    le_host.fit(host_list)\n",
    "    for c in set(df.host):\n",
    "        if c not in host_list:\n",
    "            df.host = df.host.replace(c, np.nan)\n",
    "            df.host = df.host.fillna(train.host.mode()[0])\n",
    "    df.host = le_host.transform(df.host)\n",
    "    \n",
    "    \n",
    "    df = shuffle(df, random_state=1234)\n",
    "    gkf = GroupKFold(n_splits=5).split(X=df.question_body, groups=df.question_body)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "        if fold == ifold:\n",
    "            df_train = df.iloc[train_idx]\n",
    "            df_val = df.iloc[valid_idx]\n",
    "            break\n",
    "\n",
    "    print('train', df_train.shape)\n",
    "    print('val', df_val.shape)\n",
    "\n",
    "    ds_train = QuestDataset(df_train, train_mode=True)\n",
    "    train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=ds_train.collate_fn, drop_last=True)\n",
    "    train_loader.num = len(df_train)\n",
    "\n",
    "    ds_val = QuestDataset(df_val, train_mode=False)\n",
    "    val_loader = torch.utils.data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=0, collate_fn=ds_val.collate_fn, drop_last=False)\n",
    "    val_loader.num = len(df_val)\n",
    "    val_loader.df = df_val\n",
    "\n",
    "    return train_loader, val_loader, df_val.shape[0], valid_idx\n",
    "\n",
    "\n",
    "def get_test_loader(batch_size=4):\n",
    "    df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "    \n",
    "    # cleaning\n",
    "    df['question_title'] = df['question_title'].apply(lambda x : preprocessing(x))\n",
    "    df['question_body'] = df['question_body'].apply(lambda x : preprocessing(x))\n",
    "    df['answer'] = df['answer'].apply(lambda x : preprocessing(x))\n",
    "        \n",
    "    # label encode\n",
    "    le_category = LabelEncoder()\n",
    "    le_category.fit(category_list)\n",
    "    for c in set(df.category):\n",
    "        if c not in category_list:\n",
    "            df.category = df.category.replace(c, np.nan)\n",
    "            df.category = df.category.fillna(train.category.mode()[0])\n",
    "    df.category = le_category.transform(df.category)\n",
    "    \n",
    "    le_host = LabelEncoder()\n",
    "    le_host.fit(host_list)\n",
    "    for c in set(df.host):\n",
    "        if c not in host_list:\n",
    "            df.host = df.host.replace(c, np.nan)\n",
    "            df.host = df.host.fillna(train.host.mode()[0])\n",
    "    df.host = le_host.transform(df.host)\n",
    "    \n",
    "    \n",
    "    ds_test = QuestDataset(df, train_mode=False, labeled=False)\n",
    "    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=ds_test.collate_fn, drop_last=False)\n",
    "    loader.num = len(df)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "\n",
    "# def test_train_loader():\n",
    "#     loader, _ = get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=1)\n",
    "#     for ids, seg_ids, labels in loader:\n",
    "#         print(ids)\n",
    "#         print(seg_ids.numpy())\n",
    "#         print(labels)\n",
    "#         break\n",
    "# def test_test_loader():\n",
    "#     loader = get_test_loader(4)\n",
    "#     for ids, seg_ids in loader:\n",
    "#         print(ids)\n",
    "#         print(seg_ids)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, n_classes=30):\n",
    "        super(QuestModel, self).__init__()\n",
    "        self.model_name = 'QuestModel'\n",
    "#         self.bert_model1 = BertModel.from_pretrained(BERT_DIR+'/bert-base-uncased/')\n",
    "#         self.bert_model2 = BertModel.from_pretrained(BERT_DIR+'/bert-base-uncased/')\n",
    "        \n",
    "        #self.bert_model = BertModel.from_pretrained('../input/bert-base-uncased/')\n",
    "        \n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        #self.bert_model2 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #self.emb_title = nn.Embedding(MAX_TITLE_LEN, 10)\n",
    "        \n",
    "        self.emb_category = nn.Embedding(len(category_list), 3)\n",
    "        self.emb_host = nn.Embedding(len(host_list), 10)\n",
    "        \n",
    "        self.fc = nn.Linear(768+3+10, n_classes)\n",
    "\n",
    "    def forward(self, ids, seg_ids, category, host):\n",
    "        \n",
    "        attention_mask = (ids > 0)  # ids==0([PAD])部分だけFalseとなるので、そこだけattention_weightを0に\n",
    "        layers, pool_out = self.bert_model(input_ids=ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        out = F.avg_pool1d(layers.transpose(1,2), kernel_size=layers.size()[1]).squeeze()\n",
    "        \n",
    "#         emb_title = self.emb_title(ids_title)\n",
    "#         emb_title = F.max_pool1d(emb_title.transpose(1,2), kernel_size=emb_title.size()[1]).squeeze()\n",
    "        \n",
    "        emb_category = self.emb_category(category)\n",
    "        emb_host = self.emb_host(host)\n",
    "\n",
    "        #out = torch.cat([out, emb_title], dim=-1)\n",
    "        out = torch.cat([out, emb_category], dim=-1)\n",
    "        out = torch.cat([out, emb_host], dim=-1)\n",
    "        \n",
    "        out = F.dropout(out, p=0.2, training=self.training)\n",
    "        logit = self.fc(out)\n",
    "        return torch.sigmoid(logit) # 単に30種類の出力値を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    avg_loss = 0.    \n",
    "    for idx, batch in enumerate(tqdm(train_loader)):\n",
    "        ids_train, seg_ids_train, category_train, host_train, label_ids_train = batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device)\n",
    "        \n",
    "        #print(host_train)\n",
    "        \n",
    "        logits = model(ids_train, seg_ids_train, category_train, host_train)\n",
    "        #logits = torch.sigmoid(model(ids_train, seg_ids_train))\n",
    "        \n",
    "        loss = config.question_weight*criterion(logits[:,0:21], label_ids_train[:,0:21]) + config.answer_weight*criterion(logits[:,21:30], label_ids_train[:,21:30])\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        del ids_train, seg_ids_train, label_ids_train\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return avg_loss\n",
    "\n",
    "def val_model(val_loader, val_length, batch_size=8):\n",
    "    model.eval() # eval mode  \n",
    "    avg_val_loss = 0.\n",
    "    \n",
    "    valid_preds = np.zeros((val_length, len(target_columns)))\n",
    "    original = np.zeros((val_length, len(target_columns)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(tqdm(val_loader)):\n",
    "            ids, seg_ids, category_val, host_val, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device)\n",
    "            \n",
    "            logits = model(ids, seg_ids, category_val, host_val)\n",
    "            \n",
    "            avg_val_loss += criterion(logits, labels).item() / len(val_loader)\n",
    "            valid_preds[idx*batch_size : (idx+1)*batch_size] = torch.sigmoid(logits).detach().cpu().squeeze().numpy()\n",
    "            original[idx*batch_size : (idx+1)*batch_size]    = labels.detach().cpu().squeeze().numpy()\n",
    "        \n",
    "        score = 0\n",
    "        preds = torch.tensor(valid_preds).numpy()\n",
    "        #preds = torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "        \n",
    "        rho_val = np.mean([spearmanr(original[:, i], preds[:,i]).correlation for i in range(preds.shape[1])])\n",
    "        print('\\r val_spearman-rho: %s' % (str(round(rho_val, 5))), end = 100*' '+'\\n')\n",
    "        \n",
    "        for i in range(len(target_columns)):\n",
    "            print(i, spearmanr(original[:,i], preds[:,i]))\n",
    "            score += np.nan_to_num(spearmanr(original[:, i], preds[:, i]).correlation, nan=0)\n",
    "    \n",
    "    return avg_val_loss, score/len(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spearman(pred, target):\n",
    "    score = 0\n",
    "    for i in range(len(target)):\n",
    "        #print(i, spearmanr(target[:,i], preds[:,i]))\n",
    "        score += np.nan_to_num(spearmanr(target[:, i], pred[:, i]).correlation, nan=0.5)\n",
    "    return score/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUM_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = QuestModel(n_classes=30).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, eps=4e-5)\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for fold in range(config.fold):\n",
    "    print('---%d-Fold---'%(fold+1))\n",
    "    \n",
    "    patience = 0\n",
    "    best_loss   = 100.0\n",
    "    best_score      = -1.\n",
    "    best_param_loss = None\n",
    "    best_param_score = None\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        start_time   = time.time()\n",
    "        \n",
    "        train_loader, val_loader, val_length, val_idx = get_train_val_loaders(batch_size=config.batch_size, val_batch_size=config.batch_size, ifold=fold)\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps= config.epochs*len(train_loader)//ACCUM_STEPS)\n",
    "        \n",
    "        loss_train = train_model(train_loader, optimizer, criterion, scheduler)\n",
    "        loss_val, score_val = val_model(val_loader, val_length, batch_size=config.batch_size)\n",
    "        print(f'Epoch {(epoch+1)}, train_loss: {loss_train}, val_loss: {loss_val}, score_val: {score_val}, time: {(time.time()-start_time)}')\n",
    "        \n",
    "\n",
    "        if score_val > best_score:\n",
    "            best_score = score_val\n",
    "            best_param_score = model.state_dict()\n",
    "            print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "            torch.save(best_param_score, 'best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= config.patience:\n",
    "                del train_loader, val_loader, loss_train, loss_val, score_val\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                break\n",
    "    \n",
    "        del train_loader, val_loader, loss_train, loss_val, score_val\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    \n",
    "    model.load_state_dict(best_param_score)\n",
    "    print('best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "    torch.save(best_param_score, 'best_param_score_{}_{}.pt'.format(config.name ,fold+1))\n",
    "    score_list.append(best_score)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "#     train_loader, val_loader, val_length, val_idx = get_train_val_loaders(batch_size=config.batch_size, val_batch_size=config.batch_size, ifold=fold)\n",
    "#     valid_preds = np.zeros((val_length, len(target_columns)))\n",
    "#     for idx, batch in enumerate(val_loader):\n",
    "#         ids_val, seg_ids_val, label_ids_val = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "#         logits = torch.sigmoid(model(ids_val, seg_ids_val))\n",
    "#         valid_preds[idx*confug.batch_size : (idx+1)*confug.batch_size] = logits.detach().cpu().squeeze().numpy()\n",
    "#     oof[val_idx] = valid_preds\n",
    "    \n",
    "# cv_score = calc_spearman(train[target_columns].values, oof)\n",
    "\n",
    "print(np.mean(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
